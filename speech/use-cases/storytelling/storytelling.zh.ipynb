{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# 使用文字轉語音和 Gemini 講述一個多角色的故事\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/doggy8088/generative-ai/blob/main/speech/use-cases/storytelling/storytelling.zh.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory 標誌\"><br>在 Colab 中執行\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2Fdoggy8088%2Fgenerative-ai%2Fmain%2Fspeech%2Fuse-cases%2Fstorytelling%2Fstorytelling.zh.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise 標誌\"><br>在 Colab Enterprise 中執行\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/doggy8088/generative-ai/blob/main/speech/use-cases/storytelling/storytelling.zh.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI 標誌\"><br>在 Vertex AI Workbench 中開啟\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/doggy8088/generative-ai/blob/main/speech/use-cases/storytelling/storytelling.zh.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg\" alt=\"GitHub 標誌\"><br>在 GitHub 上查看\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "---\n",
        "\n",
        "* 作者：霍特·斯基納\n",
        "* 建立日期：2024 年 1 月\n",
        "\n",
        "---\n",
        "\n",
        "## 概觀\n",
        "\n",
        "此筆記本示範如何使用 [Text-to-Speech API](https://cloud.google.com/text-to-speech) 朗讀一個故事，讓每個角色都有不同的聲音。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d975e698c9a4"
      },
      "source": [
        "### 目標\n",
        "\n",
        "本教學課程使用下列 Google Cloud AI 服務與資源：\n",
        "\n",
        "- [Cloud 文字轉語音 API](https://cloud.google.com/text-to-speech/docs)\n",
        "- Cloud 儲存空間\n",
        "\n",
        "執行步驟包含：\n",
        "\n",
        "- 分析劇本格式中的輸入故事文字。(「角色：台詞」) \n",
        "- 為每個角色指定一種聲音。\n",
        "- 根據角色聲音合成每一行。\n",
        "- 將聲音檔案合併成一個 MP3 檔案。\n",
        "\n",
        "計畫擴充功能：\n",
        "\n",
        "- 上傳聲音至 Cloud 儲存空間\n",
        "- 使用 [文件 AI 光學文字辨識](https://cloud.google.com/document-ai) 讀取故事文字\n",
        "- 使用 Gemini 將故事轉換成劇本格式。\n",
        "  - 可能會：使用 Gemini 直接從書籍文字產生 [SSML](https://cloud.google.com/text-to-speech/docs/ssml)。\n",
        "- 使用 LangChain 建立替代實作。\n",
        "- 在支援更多聲音後，加入 [Journey 語音](https://cloud.google.com/text-to-speech/docs/voice-types#journey_voices)。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aed92deeb4a0"
      },
      "source": [
        "### 成本\n",
        "\n",
        "本教學使用 Google Cloud 的計費元件：\n",
        "\n",
        "* 文字轉語音\n",
        "* 雲端儲存\n",
        "\n",
        "深入了解 [文字轉語音定價](https://cloud.google.com/text-to-speech/pricing)，\n",
        "還有 [雲端儲存定價](https://cloud.google.com/storage/pricing)，\n",
        "並使用 [定價計算器](https://cloud.google.com/products/calculator/)\n",
        "根據你預估的使用量來產生成本估算。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "## 開始使用\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNSWiCNPjh_p"
      },
      "source": [
        "### 安裝 Vertex AI SDK、其他套件及其相依性\n",
        "\n",
        "安裝執行此雲端筆記本所需的下列套件。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 20203,
          "status": "ok",
          "timestamp": 1706636547883,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 360
        },
        "id": "2b4ef9b72d43",
        "outputId": "d2e8a399-b4f9-4af3-fe49-bde99f1c14cb"
      },
      "outputs": [],
      "source": [
        "# Install the packages\n",
        "%pip install --user --upgrade -q google-cloud-aiplatform google-cloud-texttospeech pydub pandas tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3a6juReciKR"
      },
      "source": [
        "如果你使用Mac，則需要安裝 [FFmpeg](https://ffmpeg.org/)。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzCUF4oqciKR"
      },
      "outputs": [],
      "source": [
        "import platform\n",
        "\n",
        "# Check if the system is macOS\n",
        "if platform.system() == \"Darwin\":\n",
        "    # Install using Homebrew\n",
        "    !brew install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbWwuHK8j1xm"
      },
      "source": [
        "### 執行下列單元以重新啟動核心。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f200f10a1da3"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTdx_NRxkD5M"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ 這個 kernel 將會重新啟動。請等到重新啟動程序完成後再進行下一步。⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbMFqPZ3tnwz"
      },
      "source": [
        "設定專案和地區。\n",
        "\n",
        "* 請注意，Text-to-Speech 的 **可用地區** ，請參閱 [文件](https://cloud.google.com/text-to-speech/docs/endpoints)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 123,
          "status": "ok",
          "timestamp": 1706636986323,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 360
        },
        "id": "GjSsu6cmUdEx"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"YOUR_PROJECT_ID\"  # @param {type:\"string\"}\n",
        "\n",
        "TTS_LOCATION = \"us\"  # @param {type:\"string\"}\n",
        "VERTEXAI_LOCATION = \"us-central1\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opUxT_k5TdgP"
      },
      "source": [
        "### 驗證筆記本環境\n",
        "\n",
        "* 如果你使用 **Colab** 執行這個筆記本，請執行下列Cell並繼續。\n",
        "* 如果你使用 **Vertex AI Workbench** ，請查看 [這裡](https://github.com/doggy8088/generative-ai/tree/main/setup-env) 的設定說明。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 1272,
          "status": "ok",
          "timestamp": 1706638093640,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 360
        },
        "id": "vbNgv4q1T2Mi"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()\n",
        "\n",
        "    ! gcloud config set project {PROJECT_ID}\n",
        "    ! gcloud auth application-default login -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "初始化 [Vertex AI Python SDK](https://cloud.google.com/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import vertexai\n",
        "\n",
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=VERTEXAI_LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "### 從 Google Cloud Storage 下載原始文字\n",
        "\n",
        "這個公開儲存區包含一些由 PaLM 生成的故事。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "executionInfo": {
          "elapsed": 2729,
          "status": "ok",
          "timestamp": 1706638098700,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 360
        },
        "id": "NIq7R4HZCfIc",
        "outputId": "ca8a1ab0-7039-4770-f427-89dfe4e510d1"
      },
      "outputs": [],
      "source": [
        "! gsutil cp gs://github-repo/speech/storytelling/*.txt ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "### 匯入函式庫\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 101,
          "status": "ok",
          "timestamp": 1706639580284,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 360
        },
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "from google.api_core.client_options import ClientOptions\n",
        "from google.cloud import texttospeech_v1beta1 as texttospeech\n",
        "from vertexai.preview.generative_models import GenerativeModel, GenerationConfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4gUI8WqciKS"
      },
      "source": [
        "### 定義常數\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 1381,
          "status": "ok",
          "timestamp": 1706639583553,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 360
        },
        "id": "6Pl3un_YciKS"
      },
      "outputs": [],
      "source": [
        "DEFAULT_LANGUAGE = \"en\"\n",
        "# Voice used for narration, scene details, etc.\n",
        "DEFAULT_VOICE = \"en-GB-Neural2-B\"\n",
        "\n",
        "tts_client = texttospeech.TextToSpeechClient(\n",
        "    client_options=ClientOptions(\n",
        "        api_endpoint=f\"{TTS_LOCATION}-texttospeech.googleapis.com\"\n",
        "    )\n",
        ")\n",
        "model = GenerativeModel(\"gemini-pro\")\n",
        "\n",
        "SILENCE_LENGTH = 200  # In Milliseconds\n",
        "TXT_EXTENSION = \".txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5CEc4-Wrjk2"
      },
      "source": [
        "### 輔助函式\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 135,
          "status": "ok",
          "timestamp": 1706640559737,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 360
        },
        "id": "kYx2wwhjrmD6"
      },
      "outputs": [],
      "source": [
        "def list_voices(\n",
        "    language_code: str = DEFAULT_LANGUAGE, voice_type: str = \"Neural2\"\n",
        ") -> List[Dict]:\n",
        "    response = tts_client.list_voices(language_code=language_code)\n",
        "\n",
        "    return [\n",
        "        {\n",
        "            \"name\": voice.name,\n",
        "            \"gender\": texttospeech.SsmlVoiceGender(voice.ssml_gender).name.lower(),\n",
        "        }\n",
        "        for voice in response.voices\n",
        "        if voice_type in voice.name and voice.name != DEFAULT_VOICE\n",
        "    ]\n",
        "\n",
        "\n",
        "def create_character_map(characters: List[str], voices: List[str]) -> Dict[str, str]:\n",
        "    responses = model.generate_content(\n",
        "        f\"\"\"Your job is to uniquely and appropriately match character names to voices available with Google Cloud Text to Speech.\n",
        "\n",
        "The following is a list of available voices for Google Cloud Text to Speech in a JSON list.\n",
        "\n",
        "{voices}\n",
        "\n",
        "The following is a list of character names in a JSON list:\n",
        "\n",
        "{characters}\n",
        "\n",
        "Output a JSON formatted object mapping Character Names to Voice Names:\n",
        "\"\"\",\n",
        "        generation_config=GenerationConfig(\n",
        "            max_output_tokens=2048, temperature=0.9, top_p=1\n",
        "        ),\n",
        "        safety_settings=[],\n",
        "        stream=True,\n",
        "    )\n",
        "\n",
        "    for response in responses:\n",
        "        json_string = response.text.replace(\"`\", \"\").replace(\"json\", \"\")\n",
        "        return json.loads(json_string)\n",
        "\n",
        "\n",
        "def synthesize_text(\n",
        "    text: str, output: str, voice_name: str, language_code: str = DEFAULT_LANGUAGE\n",
        "):\n",
        "    response = tts_client.synthesize_speech(\n",
        "        input=texttospeech.SynthesisInput(text=text),\n",
        "        voice=texttospeech.VoiceSelectionParams(\n",
        "            language_code=language_code,\n",
        "            name=voice_name,\n",
        "        ),\n",
        "        audio_config=texttospeech.AudioConfig(\n",
        "            audio_encoding=texttospeech.AudioEncoding.MP3\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # The response's audio_content is binary.\n",
        "    with open(output, \"wb\") as f:\n",
        "        f.write(response.audio_content)\n",
        "\n",
        "\n",
        "def combine_audio_files(audio_files: List[str], filename: str) -> str:\n",
        "    full_audio = AudioSegment.silent(duration=SILENCE_LENGTH)\n",
        "\n",
        "    for file in audio_files:\n",
        "        sound = AudioSegment.from_mp3(file)\n",
        "        silence = AudioSegment.silent(duration=SILENCE_LENGTH)\n",
        "        full_audio += sound + silence\n",
        "        os.remove(file)\n",
        "\n",
        "    outfile_name = f\"{Path(filename).stem}-complete.mp3\"\n",
        "    full_audio.export(outfile_name, format=\"mp3\")\n",
        "    return outfile_name\n",
        "\n",
        "\n",
        "def get_characters(input_file: str) -> List[str]:\n",
        "    character_list = []\n",
        "    with open(input_file, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    start_line = lines.index(\"Characters:\\n\")\n",
        "\n",
        "    for i in range(start_line + 2, len(lines)):\n",
        "        if lines[i] == \"\\n\":\n",
        "            break\n",
        "        character_list.append(lines[i].strip())\n",
        "    return character_list\n",
        "\n",
        "\n",
        "def parse_file(\n",
        "    input_file: str, character_to_voice: Dict[str, Tuple[str, str]]\n",
        ") -> List[str]:\n",
        "    with open(input_file, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    line_number = 1\n",
        "    output_files = []\n",
        "    filename = Path(input_file).stem\n",
        "\n",
        "    for line in tqdm(lines, \"Parsing input file\"):\n",
        "        split_line = line.strip().split(\": \", 1)\n",
        "\n",
        "        character = split_line[0]\n",
        "        if not character:  # Skip blank lines\n",
        "            continue\n",
        "\n",
        "        voice = character_to_voice.get(character, DEFAULT_VOICE)\n",
        "\n",
        "        if len(split_line) <= 1:\n",
        "            dialogue = split_line[0]\n",
        "        elif \"Scene\" in split_line[0]:\n",
        "            dialogue = f\"{split_line[0]}, {split_line[1]}\"\n",
        "        else:\n",
        "            dialogue = split_line[1]\n",
        "\n",
        "        output_file = f\"{filename}-{line_number}.mp3\"\n",
        "        output_files.append(output_file)\n",
        "        synthesize_text(dialogue, output_file, voice[0], voice[1])\n",
        "        line_number += 1\n",
        "\n",
        "    return output_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eaHokbL2nS9"
      },
      "source": [
        "## 利用腳本內容呼叫文字到語音 API\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4NR_30rfuhA"
      },
      "source": [
        "### 取得可用的語音\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "executionInfo": {
          "elapsed": 134,
          "status": "ok",
          "timestamp": 1706639804301,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 360
        },
        "id": "0KqGXuRVuBDf",
        "outputId": "a45c9baa-7fad-4dbf-b895-e330bda9dc49"
      },
      "outputs": [],
      "source": [
        "all_voices = list_voices()\n",
        "print(pd.DataFrame(all_voices))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKMhnJ6mf6bb"
      },
      "source": [
        "### 列出所有符號\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 120,
          "status": "ok",
          "timestamp": 1706639806497,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 360
        },
        "id": "j1DahJu-f5L3"
      },
      "outputs": [],
      "source": [
        "input_file = \"Macbeth.txt\"  # @param {type:\"string\"}\n",
        "\n",
        "character_list = get_characters(input_file)\n",
        "\n",
        "if len(character_list) > len(all_voices):\n",
        "    print(f\"Too many characters {len(character_list)}. Max {len(all_voices)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y081kurHgGoK"
      },
      "source": [
        "### 映射字元至聲音\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "executionInfo": {
          "elapsed": 119,
          "status": "ok",
          "timestamp": 1706639807510,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 360
        },
        "id": "otMX_-lfgIG1",
        "outputId": "bdcb7ab1-f087-4524-ae6b-0b057697761b"
      },
      "outputs": [],
      "source": [
        "character_to_voice = create_character_map(character_list, all_voices)\n",
        "\n",
        "print(pd.DataFrame(character_to_voice))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-laS59bgKo5"
      },
      "source": [
        "### 將輸入文字解析，每行輸出為聲音\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 2347,
          "status": "ok",
          "timestamp": 1706640498990,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 360
        },
        "id": "L6rYY43xgLwh"
      },
      "outputs": [],
      "source": [
        "output_files = parse_file(input_file, character_to_voice)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tAMk2RbgO-C"
      },
      "source": [
        "### 將聲音檔案合併為一個單一檔案\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xl0ZnHStgRg3"
      },
      "outputs": [],
      "source": [
        "outfile_name = combine_audio_files(output_files, input_file)\n",
        "print(f\"Audio content written to file {outfile_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 聆聽聲音\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "executionInfo": {
          "elapsed": 263,
          "status": "ok",
          "timestamp": 1706639872605,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 360
        },
        "id": "d_ax6LxzciKT",
        "outputId": "cab61805-f1ad-4088-fbe1-ea8d5f533d18"
      },
      "outputs": [],
      "source": [
        "Audio(outfile_name)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "common-cpu.m108",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}