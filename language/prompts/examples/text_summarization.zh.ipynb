{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# åˆ©ç”¨é ‚é» AI ä¸Šçš„ç”Ÿæˆå¼æ¨¡å‹é€²è¡Œæ–‡å­—æ‘˜è¦\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/doggy8088/generative-ai/blob/main/language/prompts/examples/text_summarization.zh.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory æ¨™èªŒ\"><br>åœ¨ Colab ä¸­åŸ·è¡Œ\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/doggy8088/generative-ai/blob/main/language/prompts/examples/text_summarization.zh.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub æ¨™èªŒ\"><br>åœ¨ GitHub ä¸ŠæŸ¥çœ‹\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/doggy8088/generative-ai/blob/main/language/prompts/examples/text_summarization.zh.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"é ‚é» AI æ¨™èªŒ\"><br>åœ¨é ‚é» AI å·¥ä½œå°ä¸­é–‹å•Ÿ\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|ä½œè€… | [Polong Lin](https://github.com/polong-lin) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## æ¦‚è§€\n",
        "æ–‡å­—æ‘˜è¦ç”¢ç”Ÿä¸€ä»½è¼ƒé•·æ–‡å­—æ–‡ä»¶ç°¡æ½”ä¸”æµåˆ©çš„æ‘˜è¦ã€‚æœ‰å…©ç¨®ä¸»è¦çš„æ–‡å­—æ‘˜è¦é¡å‹ï¼šæŠ½å–å¼å’ŒæŠ½è±¡å¼ã€‚æŠ½å–å¼æ‘˜è¦åŒ…å«é¸æ“‡åŸå§‹æ–‡å­—ä¸­çš„é—œéµå¥å­ï¼Œä¸¦å°‡å®ƒå€‘çµ„åˆèµ·ä¾†å½¢æˆæ‘˜è¦ã€‚æŠ½è±¡å¼æ‘˜è¦åŒ…å«ç”¢ç”Ÿæ–°å¥å­ï¼Œä»£è¡¨åŸå§‹æ–‡å­—ä¸­çš„é‡é»ã€‚åœ¨æœ¬ç­†è¨˜ä¸­ï¼Œä½ å°‡æ·±å…¥äº†è§£å¹¾å€‹ç¯„ä¾‹ï¼Œèªªæ˜å¤§å‹èªè¨€æ¨¡å‹å¦‚ä½•å”åŠ©æ ¹æ“šæ–‡å­—ç”¢ç”Ÿæ‘˜è¦ã€‚\n",
        "\n",
        "åœ¨ [å®˜æ–¹æ–‡ä»¶](https://cloud.google.com/vertex-ai/docs/generative-ai/text/summarization-prompts) ä¸­é€²ä¸€æ­¥ç­è§£æ–‡å­—æ‘˜è¦ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d975e698c9a4"
      },
      "source": [
        "### ç›®æ¨™\n",
        "\n",
        "åœ¨æœ¬æ•™å­¸ä¸­ï¼Œä½ å°‡å­¸ç¿’å¦‚ä½•ä½¿ç”¨ç”Ÿæˆæ¨¡å‹ï¼Œé€éä»¥ä¸‹ç¯„ä¾‹æ‘˜è¦æ–‡å­—ä¸­çš„è³‡è¨Šï¼š\n",
        "- è…³æœ¬æ‘˜è¦\n",
        "- å°‡æ–‡å­—æ‘˜è¦æˆè¦é»\n",
        "- åŒ…å«å¾…è¾¦äº‹é …çš„å°è©±æ‘˜è¦\n",
        "- æ¨™ç±¤ä»£å¹£åŒ–\n",
        "- æ¨™é¡Œå’Œæ¨™é¡Œç”¢ç”Ÿ\n",
        "\n",
        "ä½ é‚„å°‡å­¸ç¿’å¦‚ä½•é€éä½¿ç”¨ ROUGE ä½œç‚ºè©•ä¼°æ¡†æ¶ï¼Œå°‡æ¨¡å‹ç”Ÿæˆçš„æ‘˜è¦èˆ‡äººå·¥è£½ä½œçš„æ‘˜è¦é€²è¡Œæ¯”è¼ƒï¼Œé€²è€Œè©•ä¼°æ¨¡å‹ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6d865e68adb"
      },
      "source": [
        "### è²»ç”¨\n",
        "\n",
        "æœ¬æ•™å­¸æŒ‡å—ä½¿ç”¨ Google Cloud çš„è¨ˆè²»å…ƒä»¶ï¼š\n",
        "\n",
        "* Vertex AI ç”Ÿæˆå¼ AI Studio\n",
        "\n",
        "äº†è§£ [Vertex AI åƒ¹æ ¼](https://cloud.google.com/vertex-ai/pricing)ï¼Œ\n",
        "ä¸¦ä½¿ç”¨ [åƒ¹æ ¼è¨ˆç®—å™¨](https://cloud.google.com/products/calculator/)\n",
        "æ ¹æ“šé è¨ˆä½¿ç”¨æƒ…æ³ç”¢ç”Ÿè²»ç”¨ä¼°ç®—å€¼ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs9TZo0GJKCR"
      },
      "source": [
        "## é–‹å§‹ä½¿ç”¨\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a5AEr0lkLKD"
      },
      "source": [
        "### å®‰è£ Vertex AI SDK\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "148dd6321946"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-aiplatform --upgrade --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLVWFKFwkLKE"
      },
      "source": [
        "**åƒ… Colabï¼š** å–æ¶ˆä¸‹ä¸€å€‹Cellè¨»è§£ä»¥é‡æ–°å•Ÿå‹•Kernelæˆ–ä½¿ç”¨æŒ‰éˆ•é‡æ–°å•Ÿå‹•Kernelã€‚å°æ–¼ Vertex AI Workbenchï¼Œä½ å¯ä»¥ä½¿ç”¨é ‚ç«¯çš„æŒ‰éˆ•é‡æ–°å•Ÿå‹•çµ‚ç«¯æ©Ÿã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Hsqwn4hkLKE"
      },
      "outputs": [],
      "source": [
        "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe7OuYuGkLKF"
      },
      "source": [
        "### é©—è­‰ç­†è¨˜æœ¬ç’°å¢ƒ\n",
        "* å¦‚æœä½ ä½¿ç”¨ **Colab** åŸ·è¡Œæ­¤ç­†è¨˜æœ¬ï¼Œå–æ¶ˆè¨»è§£ä¸‹æ–¹çš„Cellä¸¦ç¹¼çºŒã€‚\n",
        "* å¦‚æœä½ ä½¿ç”¨ **Vertex AI å·¥ä½œå°** ï¼Œè«‹æŸ¥çœ‹[æ­¤è™•](https://github.com/doggy8088/generative-ai/tree/main/setup-env)çš„è¨­å®šèªªæ˜ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9Gx2SAZkLKF"
      },
      "outputs": [],
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "### åŒ¯å…¥å‡½å¼åº«\n",
        "\n",
        "è®“æˆ‘å€‘å¾åŒ¯å…¥æœ¬æ•™å­¸èª²ç¨‹æ‰€éœ€çš„å‡½å¼åº«é–‹å§‹\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**åƒ…é™ Colabï¼š** å–æ¶ˆä¸‹æ–¹å–®å…ƒæ ¼çš„è¨»è§£ï¼Œä»¥åˆå§‹åŒ– Vertex AI SDKã€‚å°æ–¼ Vertex AI Workbenchï¼Œä¸éœ€è¦åŸ·è¡Œæ­¤å‹•ä½œã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import vertexai\n",
        "\n",
        "# PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "# vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "from vertexai.language_models import TextGenerationModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP76a2la7O-a"
      },
      "source": [
        "### åŒ¯å…¥æ¨¡å‹\n",
        "\n",
        "åœ¨æ­¤ï¼Œæˆ‘å€‘è¼‰å…¥åç‚º `text-bison@001` çš„é è¨“ç·´æ–‡å­—ç”Ÿæˆæ¨¡å‹ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7isig7e07O-a"
      },
      "outputs": [],
      "source": [
        "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu1UAhoTKn51"
      },
      "source": [
        "## æ–‡æœ¬æ‘˜è¦\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgZvJeBpJKCS"
      },
      "source": [
        "### é€å­—ç¨¿æ‘˜è¦\n",
        "\n",
        "åœ¨ç¬¬ä¸€å€‹ç¯„ä¾‹ä¸­ï¼Œä½ é‡å°é‡å­é‹ç®—çš„æ–‡å­—æ‘˜è¦ä¸€æ®µã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA2NjngeJKCS"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "Provide a very short summary, no more than three sentences, for the following article:\n",
        "\n",
        "Our quantum computers work by manipulating qubits in an orchestrated fashion that we call quantum algorithms.\n",
        "The challenge is that qubits are so sensitive that even stray light can cause calculation errors â€” and the problem worsens as quantum computers grow.\n",
        "This has significant consequences, since the best quantum algorithms that we know for running useful applications require the error rates of our qubits to be far lower than we have today.\n",
        "To bridge this gap, we will need quantum error correction.\n",
        "Quantum error correction protects information by encoding it across multiple physical qubits to form a â€œlogical qubit,â€ and is believed to be the only way to produce a large-scale quantum computer with error rates low enough for useful calculations.\n",
        "Instead of computing on the individual qubits themselves, we will then compute on logical qubits. By encoding larger numbers of physical qubits on our quantum processor into one logical qubit, we hope to reduce the error rates to enable useful quantum algorithms.\n",
        "\n",
        "Summary:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt, temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aade04b2e86a"
      },
      "source": [
        "å–ä»£æ‘˜è¦ï¼Œæˆ‘å€‘å¯ä»¥è¦æ±‚ TLï¼›DR (ã€Œå¤ªé•·ï¼›æ²’è®€ã€)ã€‚ä½ å¯ä»¥æ¯”è¼ƒè¼¸å‡ºä¹‹é–“ç”¢ç”Ÿçš„å€åˆ¥ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c0c0f3dfe10"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "Provide a TL;DR for the following article:\n",
        "\n",
        "Our quantum computers work by manipulating qubits in an orchestrated fashion that we call quantum algorithms. \n",
        "The challenge is that qubits are so sensitive that even stray light can cause calculation errors â€” and the problem worsens as quantum computers grow. \n",
        "This has significant consequences, since the best quantum algorithms that we know for running useful applications require the error rates of our qubits to be far lower than we have today. \n",
        "To bridge this gap, we will need quantum error correction. \n",
        "Quantum error correction protects information by encoding it across multiple physical qubits to form a â€œlogical qubit,â€ and is believed to be the only way to produce a large-scale quantum computer with error rates low enough for useful calculations. \n",
        "Instead of computing on the individual qubits themselves, we will then compute on logical qubits. By encoding larger numbers of physical qubits on our quantum processor into one logical qubit, we hope to reduce the error rates to enable useful quantum algorithms.\n",
        "\n",
        "TL;DR:\n",
        "\"\"\"\n",
        "\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt, temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PATmHivJKCS"
      },
      "source": [
        "### å°‡æ–‡å­—ç¸½çµæˆè¦é»\n",
        "åœ¨ä¸‹ä¾‹ä¸­ï¼Œä½ æ–¼é‡å­è¨ˆç®—ä¸Šä½¿ç”¨ç›¸åŒæ–‡å­—ï¼Œä½†è¦æ±‚æ¨¡å‹ä»¥è¦é»å½¢å¼å°‡å…¶ç¸½çµå‡ºä¾†ã€‚æ­¡è¿ä½ è®Šæ›´æç¤ºã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2orkDF2VJKCT"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "Provide a very short summary in four bullet points for the following article:\n",
        "\n",
        "Our quantum computers work by manipulating qubits in an orchestrated fashion that we call quantum algorithms.\n",
        "The challenge is that qubits are so sensitive that even stray light can cause calculation errors â€” and the problem worsens as quantum computers grow.\n",
        "This has significant consequences, since the best quantum algorithms that we know for running useful applications require the error rates of our qubits to be far lower than we have today.\n",
        "To bridge this gap, we will need quantum error correction.\n",
        "Quantum error correction protects information by encoding it across multiple physical qubits to form a â€œlogical qubit,â€ and is believed to be the only way to produce a large-scale quantum computer with error rates low enough for useful calculations.\n",
        "Instead of computing on the individual qubits themselves, we will then compute on logical qubits. By encoding larger numbers of physical qubits on our quantum processor into one logical qubit, we hope to reduce the error rates to enable useful quantum algorithms.\n",
        "\n",
        "Bulletpoints:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt, temperature=0.2, max_output_tokens=256, top_k=1, top_p=0.8\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE7y-clBJKCT"
      },
      "source": [
        "### èˆ‡å¾…è¾¦äº‹é …çš„å°è©±æ‘˜è¦\n",
        "å°è©±æ‘˜è¦æ¶‰åŠå°‡å°è©±æ¿ƒç¸®æˆè¼ƒçŸ­çš„æ ¼å¼ï¼Œä»¥ä¾¿ä½ ä¸éœ€è¦é–±è®€æ•´å€‹è¨è«–ï¼Œä½†å¯ä»¥åˆ©ç”¨æ‘˜è¦ã€‚åœ¨æ­¤ç¯„ä¾‹ä¸­ï¼Œä½ è¦æ±‚æ¨¡å‹æ•´ç†åœ¨ç·šä¸Šé›¶å”®å®¢æˆ¶èˆ‡æ”¯æ´ä»£ç†ä¹‹é–“çš„ç¯„ä¾‹å°è©±ï¼Œä¸¦åœ¨æœ€å¾ŒåŠ å…¥å¾…è¾¦äº‹é …ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV-BWzRhJKCT"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "Please generate a summary of the following conversation and at the end summarize the to-do's for the support Agent:\n",
        "\n",
        "Customer: Hi, I'm Larry, and I received the wrong item.\n",
        "\n",
        "Support Agent: Hi, Larry. How would you like to see this resolved?\n",
        "\n",
        "Customer: That's alright. I want to return the item and get a refund, please.\n",
        "\n",
        "Support Agent: Of course. I can process the refund for you now. Can I have your order number, please?\n",
        "\n",
        "Customer: It's [ORDER NUMBER].\n",
        "\n",
        "Support Agent: Thank you. I've processed the refund, and you will receive your money back within 14 days.\n",
        "\n",
        "Customer: Thank you very much.\n",
        "\n",
        "Support Agent: You're welcome, Larry. Have a good day!\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt, temperature=0.2, max_output_tokens=256, top_k=40, top_p=0.8\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlOgWzmNJKCT"
      },
      "source": [
        "###  Hashtag åˆ†è©\n",
        "Hashtag åˆ†è©æ˜¯è™•ç†ä¸€æ®µæ–‡å­—ä¸¦å–å¾—å…¶ hashtagã€ŒTokenã€çš„éç¨‹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æƒ³è¦ç‚ºä½ çš„ç¤¾ç¾¤åª’é«”æ´»å‹•ç”¢ç”Ÿ hashtagï¼Œä½ å°±å¯ä»¥ä½¿ç”¨é€™å€‹æ–¹æ³•ã€‚åœ¨é€™å€‹ç¯„ä¾‹ä¸­ï¼Œä½ å¯ä»¥ä½¿ç”¨ [é€™ç¯‡ Google Cloud çš„æ¨æ–‡](https://twitter.com/googlecloud/status/1649127992348606469) ä¸¦ç”¢ç”Ÿä¸€äº›å¯ç”¨çš„ hashtagã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWa8rNV0JKCT"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "Tokenize the hashtags of this tweet:\n",
        "\n",
        "Google Cloud\n",
        "@googlecloud\n",
        "How can data help our changing planet? ğŸŒ\n",
        "\n",
        "In honor of #EarthDay this weekend, weâ€™re proud to share how weâ€™re partnering with\n",
        "@ClimateEngine\n",
        " to harness the power of geospatial data and drive toward a more sustainable future.\n",
        "\n",
        "Check out how â†’ https://goo.gle/3mOUfts\n",
        "\"\"\"\n",
        "\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt, temperature=0.8, max_output_tokens=1024, top_k=40, top_p=0.8\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f-w7mUxJKCT"
      },
      "source": [
        "### æ¨™é¡Œå’Œæ¨™é¡Œç”¢ç”Ÿ\n",
        "åœ¨ä¸‹é¢ï¼Œä½ è¦æ±‚æ¨¡å‹ç‚ºç‰¹å®šæ–‡æœ¬ç”¢ç”Ÿäº”å€‹å¯èƒ½çš„æ¨™é¡Œï¼æ¨™é¡Œçµ„åˆé¸é …ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWNri4DTJKCU"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "Write a title for this text, give me five options:\n",
        "Whether helping physicians identify disease or finding photos of â€œhugs,â€ AI is behind a lot of the work we do at Google. And at our Arts & Culture Lab in Paris, weâ€™ve been experimenting with how AI can be used for the benefit of culture.\n",
        "Today, weâ€™re sharing our latest experimentsâ€”prototypes that build on seven years of work in partnership the 1,500 cultural institutions around the world.\n",
        "Each of these experimental applications runs AI algorithms in the background to let you unearth cultural connections hidden in archivesâ€”and even find artworks that match your home decor.\"\n",
        "\"\"\"\n",
        "\n",
        "print(\n",
        "    generation_model.predict(\n",
        "        prompt, temperature=0.8, max_output_tokens=256, top_k=1, top_p=0.8\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcpmZnwKJKCU"
      },
      "source": [
        "## è©•ä¼°\n",
        "ä½ å¯ä»¥ä½¿ç”¨ [ROUGE](https://en.wikipedia.org/wiki/ROUGE_(metric)) ä½œç‚ºè©•ä¼°æ¶æ§‹ä¾†è©•ä¼°æ‘˜è¦ä»»å‹™çš„è¼¸å‡ºã€‚ROUGE (é¢å‘å¬å›çš„ç²¾è¦è©•ä¼°æ›¿èº«) æ˜¯ä¸€ç¨®è‡ªå‹•ç¢ºå®šæ‘˜è¦å“è³ªçš„æ¸¬é‡æ–¹å¼ï¼Œæ–¹æ³•æ˜¯å°‡å…¶èˆ‡äººé¡å»ºç«‹çš„å…¶ä»– (ç†æƒ³çš„) æ‘˜è¦åšæ¯”è¼ƒã€‚é€™äº›æ¸¬é‡æ–¹æ³•è¨ˆç®—é‡ç–Šå–®å…ƒæ•¸ï¼Œä¾‹å¦‚ n å…ƒçµ„ã€å­—è©é †åºï¼Œå’Œé›»è…¦è‡ªå‹•ç”¢ç”Ÿçš„æ‘˜è¦èˆ‡äººé¡å»ºç«‹çš„ç†æƒ³æ‘˜è¦ä¹‹é–“çš„å­—è©å°ã€‚\n",
        "\n",
        "\n",
        "ç¬¬ä¸€æ­¥æ˜¯å®‰è£ ROUGE å‡½å¼åº«ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJcl38ElJKCU"
      },
      "outputs": [],
      "source": [
        "!pip install rouge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD9eKq3SJKCU"
      },
      "source": [
        "å¾ä¸€å€‹èªè¨€æ¨¡å‹å»ºç«‹æ‘˜è¦ï¼Œä½ å¯ä»¥ä½¿ç”¨å®ƒä¾†èˆ‡äººé¡ç”Ÿæˆçš„æ‘˜è¦æ¯”è¼ƒã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37m_fb-HJKCU"
      },
      "outputs": [],
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "ROUGE = Rouge()\n",
        "\n",
        "prompt = \"\"\"\n",
        "Provide a very short, maximum four sentences, summary for the following article:\n",
        "\n",
        "Our quantum computers work by manipulating qubits in an orchestrated fashion that we call quantum algorithms.\n",
        "The challenge is that qubits are so sensitive that even stray light can cause calculation errors â€” and the problem worsens as quantum computers grow.\n",
        "This has significant consequences, since the best quantum algorithms that we know for running useful applications require the error rates of our qubits to be far lower than we have today.\n",
        "To bridge this gap, we will need quantum error correction.\n",
        "Quantum error correction protects information by encoding it across multiple physical qubits to form a â€œlogical qubit,â€ and is believed to be the only way to produce a large-scale quantum computer with error rates low enough for useful calculations.\n",
        "Instead of computing on the individual qubits themselves, we will then compute on logical qubits. By encoding larger numbers of physical qubits on our quantum processor into one logical qubit, we hope to reduce the error rates to enable useful quantum algorithms.\n",
        "\n",
        "Summary:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "candidate = generation_model.predict(\n",
        "    prompt, temperature=0.1, max_output_tokens=1024, top_k=40, top_p=0.9\n",
        ").text\n",
        "\n",
        "print(candidate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b44f9872e1ba"
      },
      "source": [
        "ä½ é‚„éœ€è¦ä¸€ä½äººç‚ºç”¢ç”Ÿçš„æ‘˜è¦ï¼Œæˆ‘å€‘å°‡åˆ©ç”¨é€™å€‹æ‘˜è¦ä¾†èˆ‡æ¨¡å‹æ‰€ç”¢ç”Ÿçš„ã€Œå€™é¸è€…ã€é€²è¡Œæ¯”è¼ƒã€‚æˆ‘å€‘å°‡ç¨±æ­¤ç‚ºã€Œåƒç…§ã€ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0qNdPzOJKCc"
      },
      "outputs": [],
      "source": [
        "reference = \"Quantum computers are sensitive to noise and errors. To bridge this gap, we will need quantum error correction. Quantum error correction protects information by encoding across multiple physical qubits to form a â€œlogical qubitâ€.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KKaYhzwJKCc"
      },
      "source": [
        "ç¾åœ¨ä½ å¯ä»¥å–å¾—å€™é¸é …ç›®å’Œåƒè€ƒä»¥è©•ä¼°æ•ˆèƒ½ã€‚åœ¨æ­¤æ¡ˆä¾‹ä¸­ï¼ŒROUGE æœƒæä¾›çµ¦ä½ ï¼š\n",
        "\n",
        "- `rouge-1`ï¼Œç”¨æ–¼è¡¡é‡å–®å­—å…±ç¾é »ç‡\n",
        "- `rouge-2`ï¼Œç”¨æ–¼è¡¡é‡äºŒå­—å…±ç¾é »ç‡\n",
        "- `rouge-l`ï¼Œç”¨æ–¼è¡¡é‡æœ€é•·å…¬å…±å­åºåˆ—\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHUH6VuTJKCc"
      },
      "outputs": [],
      "source": [
        "ROUGE.get_scores(candidate, reference)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "text_summarization.ipynb",
      "toc_visible": true
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-11.m108",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}