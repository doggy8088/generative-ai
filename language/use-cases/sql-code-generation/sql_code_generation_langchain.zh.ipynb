{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47bgjiSzeJnA"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF9B5dFQeLu7"
      },
      "source": [
        "# ä½¿ç”¨ LangChain åœ¨ Vertex AI ä¸Šé€²è¡Œ SQL ç¨‹å¼ç¢¼ç”¢ç”Ÿ ğŸ¦œğŸ”—\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/doggy8088/generative-ai/blob/main/language/use-cases/sql-code-generation/sql_code_generation_langchain.zh.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> åœ¨ Colab ä¸­åŸ·è¡Œ\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/doggy8088/generative-ai/blob/main/language/use-cases/sql-code-generation/sql_code_generation_langchain.zh.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> åœ¨ GitHub ä¸Šæª¢è¦–\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/doggy8088/generative-ai/blob/main/language/use-cases/sql-code-generation/sql_code_generation_langchain.zh.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> åœ¨ Vertex AI Workbench ä¸­é–‹å•Ÿ\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| | |\n",
        "|-|-|\n",
        "| ä½œè€…: | [Shubham Chawla](https://www.github.com/shubhamgoogle), [Roy Arsan](https://www.linkedin.com/in/arsan) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvryK2kGeWfP"
      },
      "source": [
        "## æ¦‚è¿°\n",
        "å¤§èªè¨€æ¨¡å‹å¯æ–¼ç”¢ç”Ÿç¨‹å¼ç¢¼ï¼ŒåŒ…å« SQLã€‚ç‰¹åˆ¥æ˜¯ï¼Œæ¨¡å‹å¯ä»¥å°‡è‡ªç„¶èªè¨€æ–‡å­—è½‰æ›æˆ SQL æŸ¥è©¢ã€‚å…¶ä¸­ä¸€å€‹å¸¸è¦‹çš„ç›®çš„æ˜¯è®“ä½¿ç”¨è€…åœ¨ä¸éœ€è¦çŸ¥é“è¡¨æ ¼åç¨±ã€è³‡æ–™æ¶æ§‹åŠåŸºç¤è³‡æ–™å€‰å„²ä¸­çš„ç‰¹å®š SQL æ–¹è¨€æˆ–æŸ¥è©¢å¼•æ“ (ä¾‹å¦‚ BigQuery) çš„æƒ…æ³ä¸‹ï¼Œä¹Ÿå¯ä»¥æŸ¥è©¢è³‡æ–™ã€‚\n",
        "\n",
        "æœ¬è¨˜äº‹æ¶µè“‹ SQL ç¨‹å¼ç¢¼ç”¢ç”Ÿä¸­æç¤ºå·¥ç¨‹çš„æœ€ä½³å¯¦å‹™ï¼Œä»¥åŠé€é [Langchain Google Cloud Vertex AI](https://python.langchain.com/docs/integrations/llms/google_vertex_ai_palm) åŸ·è¡Œï¼Œä¸¦æ–¼ [SQL-PaLM: æ”¹å–„å¤§å‹èªè¨€æ¨¡å‹é©æ‡‰ï¼Œä»¥ç”¨æ–¼æ–‡å­—è½‰ SQL](https://arxiv.org/pdf/2306.00739.pdf) ä¸­å¯¦è¡Œæ‰€å­¸åˆ°çš„çŸ¥è­˜ã€‚ä¾‹å¦‚ï¼ŒBigQuery è³‡æ–™é›†æ¶æ§‹æœƒä»¥å‹•æ…‹æ–¹å¼æ“·å–ï¼Œä¸¦ä½œç‚ºæç¤ºçš„å…§å®¹æä¾›ï¼Œä»¥å¥ å®š LLM çš„åŸºç¤ä¸¦å€‹äººåŒ–å…¶è¼¸å‡ºã€‚æœ¬è¨˜äº‹ä¹Ÿç¤ºç¯„æª¢ç´¢åŠ å¼·ç”¢ç”Ÿ (RAG)ï¼Œæ–¹æ³•æ˜¯ä½¿ç”¨ä¾†è‡ª Langchain ç¯„ä¾‹é¸æ“‡å™¨çš„ [SemanticSimilarityExampleSelector](https://python.langchain.com/docs/modules/model_io/prompts/example_selector_types/similarity) ä¾†å‹•æ…‹æ“·å–ä¸¦å‚³éæœ€ç›¸é—œçš„å¹¾ç¨®ç¯„ä¾‹åˆ°è±å¯Œçš„ LLM æç¤ºã€‚é€™æœ‰åŠ©æ–¼ç¢ºä¿æœ€æº–ç¢ºã€æœ€ç›¸é—œçš„ LLM è¼¸å‡ºï¼Œä¹Ÿå°±æ˜¯ç”¢ç”Ÿçš„ SQL æŸ¥è©¢ï¼ŒåŒæ™‚é™åˆ¶æ‰€éœ€çš„ LLM è¼¸å…¥ Token æ•¸é‡ï¼Œé€²è€Œé™ä½æˆæœ¬ã€‚æœ¬è¨˜äº‹ä¹Ÿç¤ºç¯„ç°¡å–®çš„æ¨¡å‹è©•ä¼°ï¼Œå…¶ä¸­ç”¢ç”Ÿçš„ SQL æŸ¥è©¢é€éé‡å° BigQuery è³‡æ–™é›†åŸ·è¡Œä¾†è©•ä¼°ï¼Œä¸¦é€éå°‡å…¶èˆ‡çœŸå¯¦æŸ¥è©¢åŠç›¸æ‡‰çµæœé€²è¡Œæ¯”è¼ƒã€‚\n",
        "\n",
        "åœ¨æœ¬è¨˜äº‹ä¸­ï¼Œä½ æœƒç”¢ç”Ÿ SQL æŸ¥è©¢ä¾†åˆ†æ Cloud Audit Logsï¼Œä¸¦å›ç­”ä½ è‡ªå·±çš„ Google Cloud å°ˆæ¡ˆä¸­çš„æ´»å‹•å‘¨é­é—œéµå®‰å…¨æ€§å•é¡Œã€‚é›–ç„¶æœ¬æ–‡ä½¿ç”¨ BigQuery æ—¥èªŒè³‡æ–™é›†ï¼Œä½†æœ¬æ–‡æå‡ºçš„æ¦‚å¿µå’Œæ–¹æ³•ä¹Ÿå¯ä»¥å¥—ç”¨æ–¼å…¶ä»–è³‡æ–™åº«èˆ‡è³‡æ–™é›†ã€‚\n",
        "\n",
        "![NL2SQL flow](https://services.google.com/fh/files/misc/nl2sql_for_log_analytics2.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ool643Tzg7W2"
      },
      "source": [
        "### ç›®æ¨™\n",
        "\n",
        "åœ¨å®Œæˆç­†è¨˜æœ¬å¾Œï¼Œä½ å°‡å¯ä»¥ï¼š\n",
        "\n",
        "* ä½¿ç”¨æ¨¡å‹æ ¹æ“šè‡ªç„¶èªè¨€å•é¡Œç”¢ç”Ÿ SQL æŸ¥è©¢ï¼š\n",
        "  * ä½¿ç”¨ VertexAIEmbeddings å»ºç«‹å…§åµŒ\n",
        "  * ä½¿ç”¨ Langchain ç¯„ä¾‹é¸æ“‡å™¨è‡ªå‹•ç‚ºå°é‡ç¤ºç¯„æç¤ºé¸æ“‡ç›¸é—œç¯„ä¾‹\n",
        "  * æä¾›è‡ªè¨‚è³‡æ–™é›†æ¶æ§‹ä½œç‚ºå…§å®¹\n",
        "  * æ ¼å¼åŒ–æ¨¡å‹è¼¸å‡º\n",
        "\n",
        "* è©•ä¼°æ¨¡å‹ç”¢ç”Ÿä¹‹æŸ¥è©¢ï¼Œæ–¹æ³•ç‚ºï¼š\n",
        "  * å°å¯¦éš›è³‡æ–™é›†åŸ·è¡Œå·²èª¿æ•´çš„æŸ¥è©¢\n",
        "  * ä½¿ç”¨ pandas è³‡æ–™æ¡†ç›¸ç­‰æª¢æŸ¥ï¼Œå°‡æŸ¥è©¢ (åŠå…¶çµæœ) èˆ‡ ground truth æŸ¥è©¢é€²è¡Œæ¯”è¼ƒ\n",
        "  * è¨ˆç®—æ¨¡å‹æº–ç¢ºåº¦åˆ†æ•¸\n",
        "\n",
        "æ­¤å¤–ï¼Œä½ å¯ä»¥ä½¿ç”¨é€™å€‹ç­†è¨˜æœ¬å¾ä½ è‡ªå·±çš„ç¨½æ ¸è¨˜éŒ„ä¸­å›ç­”ä½ è‡ªå·±çš„å®‰å…¨æ€§å•é¡Œï¼Œä¾‹å¦‚ï¼š\n",
        "\n",
        "- éå»ä¸€å€‹æœˆå…§ï¼Œæ˜¯å¦æœ‰ä¸æ­£å¸¸çš„é«˜é›²ç«¯ API ä½¿ç”¨é‡ç”±ä»»ä½•ä½¿ç”¨è€…èº«åˆ†ä½¿ç”¨ï¼Ÿ\n",
        "- éå» 7 å¤©å…§ï¼Œæ˜¯å¦æœ‰ä¸é©ç•¶çš„èº«åˆ†åŸ·è¡Œä»»ä½•ç ´å£æ€§è¡Œç‚ºï¼Ÿ\n",
        "- æœ¬é€±å…§ï¼Œæ˜¯å¦æœ‰ä½¿ç”¨è€…å­˜å–åˆ°ç•°å¸¸å¤§é‡è³‡æ–™ï¼Œå°è‡´æ¯æ—¥è³‡æ–™é‡æš´å¢ï¼Ÿ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqxB1023g_fM"
      },
      "source": [
        "## é–‹å§‹ä½¿ç”¨\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2Vfi5W0hNto"
      },
      "source": [
        "### å¿…å‚™æ¢ä»¶\n",
        "å¦‚æœä½ å°šæœªåŸ·è¡Œæ­¤æ“ä½œï¼Œå”¯ä¸€çš„éœ€æ±‚æ˜¯å°‡ä½ ç¾æœ‰çš„è¨˜éŒ„å€å¡Š [å‡ç´š](https://cloud.google.com/logging/docs/buckets#upgrade-bucket) è‡³ Log Analyticsï¼Œé€™æ¨£ä¾¿èƒ½ç‚ºä½ é€£çµä¸€å€‹ BigQuery è³‡æ–™é›†ï¼Œè£¡é¢æœ‰å¯é€²è¡ŒæŸ¥è©¢çš„è¨˜éŒ„è³‡æ–™ã€‚é€™æ˜¯ **ä¸€éµå®Œæˆæ­¥é©Ÿï¼Œä¸æœƒç”¢ç”Ÿé¡å¤–çš„è²»ç”¨** ã€‚é è¨­æƒ…æ³ä¸‹ï¼Œæ¯å€‹å°ˆæ¡ˆçš„ _Required_ å€å¡Šæœƒå•Ÿç”¨ã€æ“·å–ä¸¦å„²å­˜ Cloud Audit ç®¡ç†å“¡æ´»å‹•è¨˜éŒ„ï¼Œä¸æœƒç”¢ç”Ÿä»»ä½•è²»ç”¨ã€‚\n",
        "\n",
        "![one click prerequisite](https://services.google.com/fh/files/misc/upgrade_log_bucket.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIZYzBgHhT6R"
      },
      "source": [
        "### å®‰è£ SDK\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3EARCs46U-I"
      },
      "outputs": [],
      "source": [
        "# Install Vertex AI SDK to use for model predictions\n",
        "!pip install google-cloud-aiplatform google-cloud-bigquery --upgrade --user\n",
        "!pip install langchain\n",
        "!pip install --upgrade --quiet  langchain-core langchain-google-vertexai\n",
        "!pip install --upgrade --quiet langchain langchain-google-vertexai\n",
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbScDyV5hf1D"
      },
      "source": [
        "**åƒ…é™ Colabï¼š** å–æ¶ˆä»¥ä¸‹Cellè¨»è§£ä»¥é‡æ–°å•Ÿå‹•æ ¸å¿ƒæˆ–ä½¿ç”¨æŒ‰éˆ•é‡æ–°å•Ÿå‹•æ ¸å¿ƒã€‚å°æ–¼ Vertex AI Workbenchï¼Œä½ å¯ä»¥ä½¿ç”¨å³ä¸Šæ–¹çš„æŒ‰éˆ•é‡æ–°å•Ÿå‹•çµ‚ç«¯æ©Ÿã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eJdvWP-Dq35"
      },
      "outputs": [],
      "source": [
        "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akTXroE0ChYP"
      },
      "source": [
        "### å¼•é€²å‡½å¼åº«\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBMjDTw59cFt"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain_google_vertexai import VertexAIEmbeddings, VertexAI\n",
        "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.cloud import bigquery\n",
        "from google.cloud import aiplatform\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akW4u3cIjLG7"
      },
      "source": [
        "### ç‚º BigQuery è¨­å®šå°ˆæ¡ˆå’Œè³‡æ–™é›†\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZWnTdzIjLM6"
      },
      "source": [
        "é€™æ˜¯åŒ…å«ä¸‹åˆ—é …ç›®çš„å°ˆæ¡ˆï¼š\n",
        "- é€£çµçš„ BigQuery è³‡æ–™é›† `BQ_LINKED_DATASET` (å«ä½ çš„åŸå§‹è¨˜éŒ„)ï¼Œä»¥åŠï¼Œ\n",
        "- æ–°çš„ BigQuery è³‡æ–™é›† `BQ_PROCESSED_DATASET`ï¼Œç”¨ä¾†å„²å­˜å·²è™•ç†çš„è¨˜éŒ„ã€‚\n",
        "\n",
        "é€™å€‹å°ˆæ¡ˆå¯ä»¥æ˜¯ä½ ç”¨æ–¼ Vertex AI çš„å°ˆæ¡ˆï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸åŒçš„å°ˆæ¡ˆã€‚\n",
        "\n",
        "è«‹ç¢ºå®šä½ æœ‰ `BQ_LINKED_DATASET` è³‡æ–™é›†çš„ **BigQuery Data Viewer** è§’è‰²\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-mYUuAS7CeX"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "LOCATION_US = \"US\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\n",
        "BQ_LINKED_DATASET = \"\"  # @param {type:\"string\"}\n",
        "BQ_PROCESSED_DATASET = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66PtfF1PhnEV"
      },
      "source": [
        "### é©—è­‰ä½ çš„ç­†è¨˜æœ¬é›»è…¦ç’°å¢ƒ\n",
        "* å¦‚æœä½ ä½¿ç”¨ **Colab** åŸ·è¡Œæ­¤ç­†è¨˜æœ¬é›»è…¦ï¼ŒåŸ·è¡Œä¸‹åˆ—Cellä¸¦ç¹¼çºŒã€‚\n",
        "* å¦‚æœä½ ä½¿ç”¨ **Vertex AI å·¥ä½œå°** ï¼Œè«‹æŸ¥çœ‹ [é€™è£¡](https://github.com/doggy8088/generative-ai/tree/main/setup-env) çš„è¨­å®šèªªæ˜ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPy4O74t_LU2"
      },
      "outputs": [],
      "source": [
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhcMpyDBKexo"
      },
      "source": [
        "### è¨­å®šåµŒå…¥å’Œ Vertex AI LLM æ¨¡å‹\n",
        "\n",
        "åœ¨ç›®å‰çš„ç¯„ä¾‹ï¼Œæˆ‘å€‘æ­£åœ¨ä½¿ç”¨ text-bison@002 å¤§å‹èªè¨€æ¨¡å‹ï¼Œä½†ä½ å¯ä»¥ä½¿ç”¨ Google æä¾›çš„å…¶ä»–æ¨¡å‹ geminiã€gemini-proã€ulta ç­‰ã€‚å°æ–¼åµŒå…¥ï¼Œæˆ‘å€‘ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„ textembedding-geckoã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4vG3p5oKd92"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"text-bison@002\"  # @param {type:\"string\"}\n",
        "EMBEDDING_MODEL_ID = \"textembedding-gecko@latest\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sipwSsYKCEMe"
      },
      "source": [
        "### åŒ¯å…¥æ¨£æœ¬æŸ¥è©¢\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIbiuWUTCHDD"
      },
      "source": [
        "ä½ ç¾åœ¨æœƒå¾CSVæ–‡ä»¶è£¡æ“·å–15å€‹ç¯„ä¾‹å®‰å…¨å•é¡Œå’Œç›¸æ‡‰çš„SQLæŸ¥è©¢æ¸…å–®ã€‚é€™äº›å®‰å…¨å•é¡Œæ˜¯è®Šå‹•è‡ªé–‹åŸå§‹ç¢¼[ç¤¾ç¾¤å®‰å…¨åˆ†æ](https://github.com/GoogleCloudPlatform/security-analytics)çš„ã€‚CSAæä¾›ä¸€çµ„å®‰å…¨å•é¡Œä»¥åŠå°æ‡‰çš„æŸ¥è©¢ï¼Œé©ç”¨æ–¼BigQueryã€Log Analyticså’ŒChronicleã€‚\n",
        "\n",
        "æˆ‘å€‘æœƒä½¿ç”¨é€™äº›æŸ¥è©¢çš„å­é›†ä½œç‚ºæ¨¡å‹æç¤ºç¯„ä¾‹ä¸­çš„å°æ¨£æœ¬ï¼Œä»¥åŠå°‡å‰©é¤˜çš„éƒ¨åˆ†ç”¨æ–¼æ¨¡å‹è©•ä¼°ã€‚\n",
        "\n",
        "åŸ·è¡Œä¸‹åˆ—å‘½ä»¤ï¼Œå¾GCSå„²å­˜å€è®€å–CSVæ–‡ä»¶ï¼Œä¸¦è¼‰å…¥æ‰€æœ‰è¨˜éŒ„è‡³è¨˜æ†¶ä¸­çš„pandas DataFrameä¸­ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_9ZBVhjIXFI"
      },
      "outputs": [],
      "source": [
        "BUCKET_ID = \"csa-datasets-public\"  # @param {type:\"string\"}\n",
        "FILENAME = \"SQL_Generator_Example_Queries.csv\"  # @param {type:\"string\"}\n",
        "df = pd.read_csv(f\"gs://{BUCKET_ID}/{FILENAME}\", header=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QBZwTUnDnuC"
      },
      "source": [
        "### èƒå–è¨“ç·´ & è©•ä¼°è³‡æ–™é›†\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPoHff6CDslh"
      },
      "source": [
        "æå–è¨“ç·´å’Œè©•ä¼°è³‡æ–™é›†ï¼Œä¸¦å„²å­˜åœ¨å„è‡ªçš„è³‡æ–™æ¶æ§‹ä¸­ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x24U6jDzDo0E"
      },
      "outputs": [],
      "source": [
        "train_df = df.loc[df[\"Dataset\"] == \"Train\", [\"Question\", \"SQL Query\"]]\n",
        "eval_df = df.loc[df[\"Dataset\"] == \"Eval\", [\"Question\", \"SQL Query\"]]\n",
        "train_dict = (\n",
        "    train_df[[\"Question\", \"SQL Query\"]]\n",
        "    .rename(columns={\"SQL Query\": \"answer\"})\n",
        "    .rename(columns={\"Question\": \"question\"})\n",
        "    .to_dict(orient=\"records\")\n",
        ")\n",
        "train_df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6AtPphSBjxn"
      },
      "source": [
        "## æº–å‚™è³‡æ–™\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC6Wbd6EBnM4"
      },
      "source": [
        "> å¦‚æœä½ å·²ä½¿ç”¨ [Dataform ä½œç‚º Community Security Analytics çš„ä¸€éƒ¨åˆ†](https://github.com/GoogleCloudPlatform/security-analytics/tree/main/dataform) (CSA) ä¾†è™•ç†åŸå§‹è¨˜éŒ„ä¸¦ä½¿ç”¨ç¶“éæ•´ç†çš„è¡¨æ ¼é€²è¡Œæ¨™æº–åŒ–ï¼Œå¯ä»¥ç•¥éæ­¤éƒ¨åˆ†ã€‚å¦‚éœ€ç­è§£ CSA ä»¥åŠå¦‚ä½•è‡ªå‹•æŒçºŒå»ºç«‹ç¶“éå¾Œè£½è™•ç†çš„è³‡æ–™è¡¨ä»¥å–ä»£åŸå§‹è¨˜éŒ„ï¼Œè«‹æŸ¥çœ‹ [Google Cloud éƒ¨è½æ ¼æ–‡ç« ](https://cloud.google.com/blog/products/data-analytics/deploy-community-security-analytics-with-dataform)ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB1Ki-d5Bp75"
      },
      "source": [
        "å¦‚åŒä»»ä½•å…¶ä»–çš„äººå·¥æ™ºæ…§ /æ©Ÿå™¨å­¸ç¿’å°ˆæ¡ˆï¼Œç¬¬ä¸€ä»¶äº‹ä¾¿æ˜¯æº–å‚™å¥½è³‡æ–™ï¼ŒåŒ…æ‹¬çµ¦å°‘æ¬¡æç¤ºå’Œå¾ŒçºŒè©•ä¼°æ‰€ç”¨çš„è³‡æ–™é›†ã€‚ä½ æœƒå°‡å„²å­˜åœ¨ BigQuery é€£çµè³‡æ–™é›†çš„åŸå§‹è¨˜éŒ„é å…ˆè™•ç†æˆæ‘˜è¦è¡¨æ ¼ï¼Œä¸¦æ”¾åˆ°ä½ çš„æ–° BigQuery è³‡æ–™é›†è£¡ã€‚é€™å€‹è¡¨æ ¼å°‡ä»¥å½™ç¸½æ–¹å¼é¡¯ç¤ºè¨˜éŒ„ï¼Œä¸¦æ­£è¦åŒ–æˆä¸€å€‹ç°¡å–®çš„æ¶æ§‹ã€‚é€™è®“ä½ å¯ä»¥è§£é–å’Œç¸®æ”¾æ©Ÿå™¨å­¸ç¿’åˆ†æï¼š\n",
        "- å¾é‹ç®—è§€é»è€Œè¨€ï¼Œå› ç‚ºé€™å€‹è³‡æ–™é›†è¼ƒå°ä¸”ç°¡å–®ã€‚\n",
        "- å¾äººæ‰è§€é»è€Œè¨€ï¼Œå› ç‚ºç ”ç©¶äººå“¡å’Œåˆ†æå¸«ä¸ä¸€å®šè¦ç†Ÿæ‚‰åŸå§‹è¨˜éŒ„çš„è¤‡é›œæ¶æ§‹ ( [Log Entry å®šç¾©](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry))ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR65cweHLbA_"
      },
      "source": [
        "### å»ºç«‹æ–°è³‡æ–™é›†\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJ4ufY5pLcEK"
      },
      "outputs": [],
      "source": [
        "!bq --location=LOCATION_US mk --dataset {BQ_PROJECT_ID}:{BQ_PROCESSED_DATASET}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX3XEZ4MLMac"
      },
      "source": [
        "ä½¿ç”¨è¨˜éŒ„åˆ†æ Bigquery è¡¨æ ¼å»ºç«‹æ–°çš„ csa_4_01_summary_daily\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KWvGJw0C7YK2"
      },
      "outputs": [],
      "source": [
        "TABLE_NAME = \"csa_4_01_summary_daily\"\n",
        "TABLE_ID = f\"{PROJECT_ID}.{BQ_PROCESSED_DATASET}.{TABLE_NAME}\"\n",
        "SUMMARY_LOOKBACK_DAYS = 90\n",
        "\n",
        "client = bigquery.Client(project=PROJECT_ID, location=LOCATION_US)\n",
        "client.create_dataset(dataset=BQ_PROCESSED_DATASET, exists_ok=True)\n",
        "\n",
        "job_config = bigquery.QueryJobConfig(\n",
        "    destination=TABLE_ID, write_disposition=\"WRITE_TRUNCATE\"\n",
        ")\n",
        "\n",
        "sql = f\"\"\"\n",
        "SELECT\n",
        "  EXTRACT(DATE FROM timestamp) AS day,\n",
        "  proto_payload.audit_log.authentication_info.principal_email,\n",
        "  ARRAY_AGG(DISTINCT proto_payload.audit_log.method_name IGNORE NULLS) AS actions,\n",
        "  COUNT(*) AS counter\n",
        "FROM `{PROJECT_ID}.{BQ_LINKED_DATASET}._AllLogs`\n",
        "WHERE\n",
        "  timestamp >=  TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {SUMMARY_LOOKBACK_DAYS} DAY)\n",
        "  AND proto_payload.audit_log.authentication_info.principal_email IS NOT NULL\n",
        "  AND proto_payload.audit_log.method_name NOT LIKE \"storage.%.get\"\n",
        "  AND proto_payload.audit_log.method_name NOT LIKE \"v1.compute.%.list\"\n",
        "  AND proto_payload.audit_log.method_name NOT LIKE \"beta.compute.%.list\"\n",
        "GROUP BY\n",
        "  day,\n",
        "  proto_payload.audit_log.authentication_info.principal_email\n",
        "\"\"\"\n",
        "\n",
        "# Start the query and save results in new table\n",
        "query_job = client.query(sql, job_config=job_config)\n",
        "result = query_job.result()  # Wait for the job to complete.\n",
        "\n",
        "print(f\"{result.total_rows} user action records loaded to table {TABLE_ID}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRA74CdhEODS"
      },
      "source": [
        "### å»ºæ§‹ schema å®šç¾© (ç²¾ç°¡ç‰ˆï¼‰\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJneRks9ERIt"
      },
      "source": [
        "é¦–å…ˆï¼Œæˆ‘å€‘éœ€è¦å»ºç«‹ç°¡æ½”çš„è³‡æ–™é›†æ¶æ§‹å®šç¾©ã€‚å¦‚åŒå‰é¢æ‰€è¿°ï¼Œæˆ‘å€‘æœƒå°‡å®ƒç”¨ä½œæç¤ºèƒŒæ™¯çš„ä¸€éƒ¨åˆ†ä¾†è§£æ±ºçµæœã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyZHLd-oEozF"
      },
      "source": [
        "å¾ BigQuery è³‡æ–™é›†çš„ `INFORMATION_SCHEMA` ä¸­æ“·å–è³‡æ–™è¡¨å’Œæ¬„ä½å®šç¾©ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "n49TC0PaJ23L"
      },
      "outputs": [],
      "source": [
        "# Following SQL query will generate schema definition of your dataset\n",
        "\n",
        "BQ_TABLES = df[\"Qualified table name\"].replace(\"\", np.nan).dropna().unique()\n",
        "print(BQ_TABLES)\n",
        "QUERY = f\"\"\"\\\n",
        "SELECT\n",
        "    '[Schema (values)]: ' || '| log_summary | ' || STRING_AGG(table_values, ' | ') || ';' AS tables_definition,\n",
        "    '[Column names (type)]: ' || STRING_AGG(column_names_types) || ';' AS columns_definition\n",
        "FROM (\n",
        "    SELECT\n",
        "      table_name,\n",
        "      table_name || ' : ' || STRING_AGG(column_name, ' , ') as table_values,\n",
        "      STRING_AGG(table_name || ' : ' || column_name || ' (' || data_type || ')', ' | ') as column_names_types\n",
        "    FROM {PROJECT_ID}.{BQ_PROCESSED_DATASET}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS\n",
        "    WHERE table_name IN {'(' + \",\".join(map(lambda x: f\"'{x}'\", BQ_TABLES)) + ')'}\n",
        "    GROUP BY table_name\n",
        "    ORDER BY table_name\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "# Create query job\n",
        "query_job = client.query(QUERY)\n",
        "# Get first row\n",
        "schema = next(query_job.result())\n",
        "\n",
        "# Build schema definition\n",
        "schema_definition = f\"\"\"\\\n",
        "{schema.tables_definition}\n",
        "\n",
        "{schema.columns_definition}\n",
        "\"\"\"\n",
        "\n",
        "print(schema_definition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### å»ºç«‹æç¤º\n",
        "\n",
        "æˆ‘å€‘ä½¿ç”¨ä½¿ç”¨è€…è¼¸å…¥å’Œä½¿ç”¨ Langchain FewShotPromptTemplate å‹•æ…‹æå–çš„å¹¾å€‹é¡é ­ä¾†å»ºç«‹æç¤º\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### å»ºç«‹ VertexAI embeddings ä»¥å»ºç«‹æ–‡å­—è¡¨å¾µ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding = VertexAIEmbeddings(model_name=EMBEDDING_MODEL_ID, project=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh0vG61jR6Bb"
      },
      "source": [
        "#### å»ºç«‹å°‘é‡æç¤º\n",
        "\n",
        "`SemanticSimilarityExampleSelector` é¸æ“‡ç¯„ä¾‹çš„ä¾æ“šï¼Œç‚ºç¯„ä¾‹å’Œè¼¸å…¥æœ€ç›¸ä¼¼çš„çµ„åˆ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IftnEU2SAiJ8"
      },
      "outputs": [],
      "source": [
        "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
        "    # This is the list of examples available to select from.\n",
        "    train_dict,\n",
        "    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
        "    embedding,\n",
        "    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
        "    FAISS,\n",
        "    # This is the number of examples to produce.\n",
        "    k=2,\n",
        ")\n",
        "\n",
        "# Select the most similar example to the input.\n",
        "question = \"select user actions that contains the word 'delete' or 'remove'\"\n",
        "selected_examples = example_selector.select_examples({\"question\": question})\n",
        "print(f\"Examples most similar to the input: {question}\")\n",
        "for example in selected_examples:\n",
        "    print(\"\\n\")\n",
        "    for k, v in example.items():\n",
        "        print(f\"{k}: {v}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ç”¨æ–¼å»ºç«‹æç¤ºçš„ Helper å‡½å¼\n",
        "\n",
        "ä¸‹æ–¹å‡½å¼å°‡ç”¨æ–¼å°‡ä½¿ç”¨è€…è¼¸å…¥è½‰æ›æˆå¯¦éš›æç¤ºï¼Œå…¶ä¸­åŒ…å«å°‘é‡ç¯„ä¾‹å’Œé–‹é ­\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_prompt(user_prompt, example_selector):\n",
        "    prompt_template = f\"\"\"\\\n",
        "    This is a task converting text into GoogleSQL statement.\n",
        "    We will first give you the dataset schema and then ask a question in text.\n",
        "    You are asked to generate SQL statement which is valid for BigQuery.\n",
        "    Remove any delimiters around answer such as \"```\"\n",
        "\n",
        "    BigQuery tables schema definition:\n",
        "    {schema_definition}\n",
        "    Here are a few shot examples:\n",
        "    \"\"\"\n",
        "    example_prompt = PromptTemplate(\n",
        "        input_variables=[\"question\", \"answer\"],\n",
        "        template=\"question: {question}\\nanswer: {answer}\",\n",
        "    )\n",
        "\n",
        "    prompt = FewShotPromptTemplate(\n",
        "        example_selector=example_selector,\n",
        "        example_prompt=example_prompt,\n",
        "        prefix=prompt_template,\n",
        "        suffix=\"question: {question}\\nanswer: \",\n",
        "        input_variables=[\"question\"],\n",
        "    )\n",
        "    final_prompt = prompt.format(question=user_prompt)\n",
        "    return final_prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhxjQ6F0Fol0"
      },
      "source": [
        "## ç”Ÿæˆ SQL æŸ¥è©¢\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK8aYpx0Fse0"
      },
      "source": [
        "### å®šç¾©ç”¨æ–¼ç”¢ç”Ÿ SQL çš„è¼”åŠ©å‡½å¼\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfqswuz2Fwqw"
      },
      "source": [
        "`generate_sql()`: æ­¤å‡½å¼ç”¨æ–¼å¾ Vertex AI LLM æ¨¡å‹ä¸­æ“·å– SQL æŸ¥è©¢ï¼Œä¸¦ä½¿ç”¨æˆ‘å€‘è¿„ä»Šç‚ºæ­¢å»ºç½®çš„æç¤ºç¯„æœ¬ã€‚\n",
        "\n",
        "`execute_sql()`: æ­¤å‡½å¼ç”¨æ–¼é‡å°å¯¦éš› BigQuery è³‡æ–™é›†åŸ·è¡Œ SQL æŸ¥è©¢ï¼Œä¸¦å°‡çµæœå‚³å›ç‚ºè³‡æ–™æ¡†ã€‚\n",
        "\n",
        "`build_prompt()`: æ­¤å‡½å¼ç”¨æ–¼å»ºç«‹æœ€çµ‚æç¤ºï¼Œå…¶ä¸­åŒ…å«æ‰€æœ‰æç¤ºçš„å…±ç”¨å­—é¦–å’Œå­—å°¾\n",
        "\n",
        "è«‹æ³¨æ„ï¼Œ`generate_sql()` å¦‚ä½•ä½¿ç”¨ `sanitize_output()` å‡½å¼åœ¨å›å‚³çµæœå‰å°‡å›æ‡‰åˆ†è§£ç‚º SQL æŸ¥è©¢æœ¬èº«ã€‚å³ä½¿æ¨¡å‹æç¤ºåŒ…å«èª¿æ•´æ¨¡å‹è¼¸å‡ºçš„æŒ‡ç¤ºï¼Œä»ç„¶å¯èƒ½æœƒæœ‰éœ€è¦ç§»é™¤çš„å¼•è™Ÿæˆ–ç¨‹å¼å€å¡Šåå¼•è™Ÿï¼Œä»¥é¿å…å¾ŒçºŒçš„ SQL èªæ³•éŒ¯èª¤ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O45Xw1uql0rF"
      },
      "outputs": [],
      "source": [
        "# Limit number of bytes processed as a guardrail for cost control\n",
        "BQ_MAX_BYTES_BILLED = pow(2, 30)  # 1GB\n",
        "\n",
        "\n",
        "def execute_sql(query: str):\n",
        "    print(\"Executing SQL...\")\n",
        "\n",
        "    # Qualify table names with your project and dataset ID\n",
        "    for table_name in BQ_TABLES:\n",
        "        query = query.replace(\n",
        "            table_name, f\"{PROJECT_ID}.{BQ_PROCESSED_DATASET}.{table_name}\"\n",
        "        )\n",
        "\n",
        "    # Validate the query by performing a dry run without incurring a charge\n",
        "    job_config = bigquery.QueryJobConfig(use_query_cache=False, dry_run=True)\n",
        "    try:\n",
        "        response = client.query(query, job_config=job_config)\n",
        "    except Exception as e:\n",
        "        print(\"Error validating query:\")\n",
        "        print(e)\n",
        "        return e\n",
        "\n",
        "    print(\"Query will process {:.2f} KB.\".format(response.total_bytes_processed / 1024))\n",
        "\n",
        "    # Execute the query\n",
        "    job_config = bigquery.QueryJobConfig(\n",
        "        use_query_cache=False, maximum_bytes_billed=BQ_MAX_BYTES_BILLED\n",
        "    )\n",
        "    try:\n",
        "        response = client.query(query)\n",
        "        df = response.to_dataframe()\n",
        "    except Exception as e:\n",
        "        print(\"Error executing query:\")\n",
        "        print(e)\n",
        "        return e\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "\n",
        "# Strip text to include only the SQL code block with\n",
        "def sanitize_output(text: str) -> str:\n",
        "    # Strip whitespace and any potential backticks enclosing the code block\n",
        "    text = text.strip()\n",
        "    regex = re.compile(r\"^\\s*```(\\w+)?|```\\s*$\")\n",
        "    text = regex.sub(\"\", text).strip()\n",
        "\n",
        "    # Find and remove any trailing quote without corresponding opening quote\n",
        "    if re.search(r'^[^\"]*\"$', text):\n",
        "        text = text[:-1]\n",
        "    # Find and remove any leading quote without corresponding closing quote\n",
        "    if re.search(r'^\"[^\"]*$', text):\n",
        "        text = text[1:]\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# Call model using prompt and pre-defined parameters\n",
        "def generate_sql(\n",
        "    prompt: str,\n",
        "    temperature: float = 0.2,\n",
        "    max_output_tokens: int = 1024,\n",
        "    top_k: int = 40,\n",
        "    top_p: float = 0.8,\n",
        ") -> str:\n",
        "    print(\"Generating SQL...\")\n",
        "    print(\"Number of input tokens: \" + str(len(prompt)))\n",
        "\n",
        "    model = VertexAI(\n",
        "        model_name=MODEL_ID,\n",
        "        temperatore=temperature,\n",
        "        max_output_tokens=max_output_tokens,\n",
        "        top_k=top_k,\n",
        "        top_p=top_p,\n",
        "    )\n",
        "    final_prompt = build_prompt(prompt, example_selector)\n",
        "    print(final_prompt)\n",
        "    text = model.invoke(final_prompt)\n",
        "    print(\"Number of output tokens: \" + str(len(text)))\n",
        "    print(\"Response:\")\n",
        "    print(text)\n",
        "    # Strip text to include only the SQL code block\n",
        "    text = sanitize_output(text)\n",
        "    print(\"Response stripped:\")\n",
        "    print(text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--NVnQyodhAC"
      },
      "source": [
        "### ç¯„ä¾‹ 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR9hiB2Tdx53"
      },
      "source": [
        "è®“æˆ‘å€‘ç”Ÿæˆ SQL ä¾†å›ç­”é€™å€‹ç¯„ä¾‹å•é¡Œï¼š\n",
        "\n",
        "*åˆ—å‡ºåŒ…å«ã€Œåˆªé™¤ã€æˆ–ã€Œç§»é™¤ã€å­—è©çš„æ‰€æœ‰ä½¿ç”¨è€…æ“ä½œï¼Œæ™‚æ®µæ¶µè“‹ä¸Šå€‹æœˆã€‚åœ¨çµæœä¸­åŒ…å«ä½¿ç”¨è€…èˆ‡æ—¥æœŸã€‚*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Wmk0c2H_lhcB"
      },
      "outputs": [],
      "source": [
        "user_prompt = \"List all user actions that contains the word 'delete' or 'remove' over the last month. Include the user and the day in the results.\"\n",
        "\n",
        "final_generated_prompt = build_prompt(user_prompt, example_selector)\n",
        "print(final_generated_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF0_OL5Odvdn"
      },
      "source": [
        "æˆ‘å€‘ä½¿ç”¨ BigQuery ä¸­çš„ç·šä¸Šè³‡æ–™é›†æ¸¬è©¦æ‰€ç”¢ç”Ÿçš„æŸ¥è©¢ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gEaH9nZbOloi"
      },
      "outputs": [],
      "source": [
        "output = generate_sql(example_selector, user_prompt)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uzuKxoud6Cf"
      },
      "source": [
        "è®“æˆ‘å€‘é‡å°ä½ çš„ BigQuery è³‡æ–™é›†æ¸¬è©¦ç”¢ç”Ÿçš„æŸ¥è©¢ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HeNR3q_xPfO2"
      },
      "outputs": [],
      "source": [
        "# Execute the query\n",
        "query_result = execute_sql(output)\n",
        "display(query_result.head(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vnb2LuGjLjpN"
      },
      "source": [
        "### ç¯„ä¾‹ 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW-fLol-LjpX"
      },
      "source": [
        "è®“æˆ‘å€‘ç”Ÿæˆ SQL ä¾†å›ç­”é€™å€‹ç¯„ä¾‹å•é¡Œï¼š\n",
        "\n",
        "*åˆ—å‡ºåŒ…å«ã€Œåˆªé™¤ã€æˆ–ã€Œç§»é™¤ã€å­—è©çš„æ‰€æœ‰ä½¿ç”¨è€…æ“ä½œï¼Œæ™‚æ®µæ¶µè“‹ä¸Šå€‹æœˆã€‚åœ¨çµæœä¸­åŒ…å«ä½¿ç”¨è€…èˆ‡æ—¥æœŸã€‚*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JyE38cipLjpY"
      },
      "outputs": [],
      "source": [
        "user_prompt = \"List any action containing IAM case-insensitive by any unapproved user over the last 7 days, where approved user include 'admin@example.com'\"\n",
        "\n",
        "final_generated_prompt = build_prompt(user_prompt, example_selector)\n",
        "print(final_generated_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAG4I30NLjpY"
      },
      "source": [
        "æˆ‘å€‘ä½¿ç”¨ BigQuery ä¸­çš„ç·šä¸Šè³‡æ–™é›†æ¸¬è©¦æ‰€ç”¢ç”Ÿçš„æŸ¥è©¢ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "h_LksGE3LjpY"
      },
      "outputs": [],
      "source": [
        "output = generate_sql(example_selector, user_prompt)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nqeQsWGLjpY"
      },
      "source": [
        "è®“æˆ‘å€‘é‡å°ä½ çš„ BigQuery è³‡æ–™é›†æ¸¬è©¦ç”¢ç”Ÿçš„æŸ¥è©¢ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PJq19QC_LjpY"
      },
      "outputs": [],
      "source": [
        "# Execute the query\n",
        "query_result = execute_sql(output)\n",
        "display(query_result.head(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmI4izZRd-Id"
      },
      "source": [
        "## è©•ä¼°æ¨¡å‹\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3dkE8mCeFri"
      },
      "source": [
        "### åœ¨è©•ä¼°è³‡æ–™é›†ä¸Šé‹è¡Œæ¨¡å‹\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmrMER40eI4O"
      },
      "source": [
        "è®“æˆ‘å€‘ç‚ºè©•ä¼°è³‡æ–™é›†ä¸­æ‰€æœ‰çš„å•é¡Œç”¢ç”Ÿ SQL æŸ¥è©¢ã€‚è©²è³‡æ–™é›†åŒæ™‚åŒ…æ‹¬ã€Œå•é¡Œã€å’Œæ­£è§£ã€ŒSQL æŸ¥è©¢ã€ã€‚åŸ·è¡Œä»¥ä¸‹ç¨‹å¼ç¢¼ï¼Œç‚ºè³‡æ–™é›†ä¸­çš„æ¯å€‹å•é¡Œè‡ªå‹•å‘¼å«æ¨¡å‹ï¼Œä¸¦å°‡å›æ‡‰è¨˜éŒ„åœ¨æ–°çš„æ¬„ä½ã€Œå·²ç”¢ç”Ÿçš„ SQL æŸ¥è©¢ã€ã€‚ç”±æ–¼æ¨¡å‹å‘¼å«æ˜¯ä¸²åˆ—åŸ·è¡Œçš„ï¼Œé€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7UwUYtOEg-mf"
      },
      "outputs": [],
      "source": [
        "eval_df[\"Generated SQL Query\"] = eval_df[\"Question\"].apply(\n",
        "    lambda x: generate_sql(example_selector, x)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udQqttGIGNmM"
      },
      "source": [
        "### æ¯”è¼ƒè¼¸å‡ºçµæœ\n",
        "\n",
        "åœ¨ä¸‹ä¸€å–®å…ƒæ ¼ä¸­ï¼Œæˆ‘å€‘å°‡åŸ·è¡ŒåŸå§‹çš„ SQL æŸ¥è©¢ï¼Œç„¶å¾Œç›´æ¥æ¯”å°å®ƒçš„è¼¸å‡ºèˆ‡æ‰€ç”¢ç”Ÿ SQL æŸ¥è©¢çš„è¼¸å‡ºã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rffyi5XX1Giu"
      },
      "outputs": [],
      "source": [
        "def compare_dataframes(sql_query, generated_sql_query):\n",
        "    \"\"\"Compares two pandas DataFrames row-wise using columns from the second DataFrame.\n",
        "    Args:\n",
        "        SQL Query, Generated SQL Query\n",
        "    Returns:\n",
        "        True if output of both the SQL queries matches otherwise False\n",
        "    \"\"\"\n",
        "    df1 = execute_sql(sql_query)\n",
        "    df2 = execute_sql(generated_sql_query)\n",
        "\n",
        "    # If generated query returned an error instead of a dataframe with results:\n",
        "    if not isinstance(df2, pd.DataFrame):\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        df2 = df2[df1.columns]\n",
        "    except KeyError:\n",
        "        # Columns in results of ground truth query are missing\n",
        "        # from results returned by generated query\n",
        "        return False\n",
        "\n",
        "    comparison_result = df2.eq(df1)\n",
        "    matching_rows = comparison_result.all(axis=1)\n",
        "    matching_count = matching_rows.sum()\n",
        "    # return df1, df2\n",
        "    return True if matching_count == len(df1) else False\n",
        "\n",
        "\n",
        "eval_df[\"Data Match\"] = eval_df.apply(\n",
        "    lambda x: compare_dataframes(x[\"SQL Query\"], x[\"Generated SQL Query\"]), axis=1\n",
        ")\n",
        "# eval_df[\"sql_query_output\"],eval_df[\"generated_sql_query_output\"] = eval_df.apply(lambda x: compare_dataframes(x[\"SQL Query\"], x[\"Generated SQL Query\"]), axis=1)\n",
        "\n",
        "# Note: To save the output data to the final dataframe, make these changes: 1. Uncomment lines 26 and 30. 2. Comment out line 29."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydZeqe3FGUQf"
      },
      "source": [
        "## æœ€çµ‚çµæœ\n",
        "\n",
        "åœ¨ä»¥ä¸‹å–®å…ƒæ ¼ä¸­ï¼Œæˆ‘å€‘å°‡è¨ˆç®—æ¨¡å‹çš„æœ€çµ‚åˆ†æ•¸ã€‚é€™å€‹åˆ†æ•¸è¡¨ç¤ºåŸå§‹æŸ¥è©¢å’Œç”ŸæˆæŸ¥è©¢ä¹‹é–“æˆåŠŸåŒ¹é…çš„ç™¾åˆ†æ¯”ï¼Œå¦‚ã€Œè³‡æ–™é…å°ã€æ¬„ä¸­æ‰€ç¤ºã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-a85rHhNCs2"
      },
      "source": [
        "### åˆ†æ•¸\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SnMTlFSHV17"
      },
      "outputs": [],
      "source": [
        "def get_prcntg_match(eval_df):\n",
        "    return round(eval_df[\"Data Match\"].sum() / len(eval_df) * 100)\n",
        "\n",
        "\n",
        "prcntg_match = get_prcntg_match(eval_df)\n",
        "print(f\"Final Score based on the percentage of data match: {prcntg_match}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nQc4ePmIa-7"
      },
      "source": [
        "### è¼¸å‡º\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1eQxydrDEA-R"
      },
      "outputs": [],
      "source": [
        "pd.set_option(\"display.max_rows\", None)\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.width\", None)\n",
        "pd.set_option(\"display.max_colwidth\", -1)\n",
        "display(eval_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}