{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "## 使用 BigQuery DataFrames 與生成式 AI 進行程式碼生成\n",
        "\n",
        "<table align=\"left\">\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://colab.sandbox.google.com/github/doggy8088/generative-ai/blob/main/language/use-cases/applying-llms-to-data/bq_dataframes_llm_code_generation.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中執行\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/doggy8088/generative-ai/blob/main/language/use-cases/applying-llms-to-data/bq_dataframes_llm_code_generation.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      在 GitHub 上查看\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/doggy8088/generative-ai/blob/main/language/use-cases/applying-llms-to-data/bq_dataframes_llm_code_generation.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      在 Vertex AI Workbench 中開啟\n",
        "    </a>\n",
        "  </td>                                                                                               \n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|作者 | [Ashley Xu](https://github.com/ashleyxuu) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24743cf4a1e1"
      },
      "source": [
        "**_注意_** : 已在下列環境測試筆記本：\n",
        "\n",
        "* Python 版本 = 3.10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## 概觀\n",
        "\n",
        "使用此筆記本逐步了解一個範例使用案例，其中使用 BigQuery DataFrames 及其與 Vertex AI 上的生成式 AI 支援整合來產生範例程式碼。\n",
        "\n",
        "進一步瞭解 [BigQuery DataFrames](https://cloud.google.com/python/docs/reference/bigframes/latest)。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d975e698c9a4"
      },
      "source": [
        "### 目標\n",
        "\n",
        "本教學課程中，你將建立一個包含範例程式碼以呼叫指定 API 程式的 CSV 檔案。\n",
        "\n",
        "步驟包括：\n",
        "\n",
        "- 在 BigQuery DataFrames 中定義 LLM 模型，特別是 PaLM API 的 [「文字-bison」模型](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/text)(採用 `bigframes.ml.llm`)。\n",
        "- 透過從 Cloud Storage 讀取資料來建立 DataFrame。\n",
        "- 操作 DataFrame 中的資料，以建置 LLM 提示。\n",
        "- 使用 `predict` 方法將 DataFrame 提示傳送至 LLM 模型。\n",
        "- 建立並使用自訂函式，以轉換 LLM 模型回應提供的輸出。\n",
        "- 將轉換後的結果 DataFrame 匯出為 CSV 檔案。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08d289fa873f"
      },
      "source": [
        "### 資料集\n",
        "\n",
        "本教學使用一個列出各種 Pandas DataFrame 和 Series API 名稱的資料集。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aed92deeb4a0"
      },
      "source": [
        "### 成本\n",
        "\n",
        "本教學課程使用 Google Cloud 的計費元件：\n",
        "\n",
        "* BigQuery\n",
        "* Vertex AI 上的生成式 AI 支援\n",
        "* Cloud Functions\n",
        "\n",
        "進一步了解 [BigQuery 計算定價](https://cloud.google.com/bigquery/pricing#analysis_pricing_models)、[Vertex AI 上的生成式 AI 支援定價](https://cloud.google.com/vertex-ai/pricing#generative_ai_models) 以及 [Cloud Functions 定價](https://cloud.google.com/functions/pricing)，\n",
        "並使用 [定價計算器](https://cloud.google.com/products/calculator/)，根據預計用量來產生成本估算。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "## 安裝\n",
        "\n",
        "安裝以下套件，執行這個筆記本需要這些套件：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b4ef9b72d43"
      },
      "outputs": [],
      "source": [
        "!pip install bigframes --upgrade --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF1j6f9HApxa"
      },
      "source": [
        "## 開始前\n",
        "\n",
        "完成本節中的任務以設定你的環境。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wbr2aVtFQBcg"
      },
      "source": [
        "### 設定 Google Cloud 專案\n",
        "\n",
        "**無論你使用哪種類型的筆記本環境，都必須執行下列步驟。** \n",
        "\n",
        "1. [選擇或建立 Google Cloud 專案](https://console.cloud.google.com/cloud-resource-manager)。初次建立帳戶時，你可獲得 300 美元的額度來支付運算/儲存成本。\n",
        "\n",
        "2. [確保已為專案啟用帳單](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
        "\n",
        "3. [按一下這裡](https://console.cloud.google.com/flows/enableapi?apiid=bigquery.googleapis.com,bigqueryconnection.googleapis.com,cloudfunctions.googleapis.com,run.googleapis.com,artifactregistry.googleapis.com,cloudbuild.googleapis.com,cloudresourcemanager.googleapis.com) 以啟用下列 API：\n",
        "\n",
        "  * BigQuery API\n",
        "  * BigQuery Connection API\n",
        "  * Cloud Functions API\n",
        "  * Cloud Run API\n",
        "  * Artifact Registry API\n",
        "  * Cloud Build API\n",
        "  * Cloud Resource Manager API\n",
        "  * Vertex AI API\n",
        "\n",
        "4. 如果你是在本機執行此筆記本，請安裝 [Cloud SDK](https://cloud.google.com/sdk)。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReHDGG5g0XY"
      },
      "source": [
        "#### 設定你的專案 ID\n",
        "\n",
        "如果你不知道你的專案 ID，請嘗試以下：\n",
        "* 執行 `gcloud config list`。\n",
        "* 執行 `gcloud projects list`。\n",
        "* 查看支援頁： [找出專案 ID](https://support.google.com/googleapi/answer/7014113)。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM1iC_MfAts1"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "#### 設定區域\n",
        "\n",
        "你也可以變更 BigQuery 使用的 `REGION` 變數。進一步了解 [BigQuery 區域](https://cloud.google.com/bigquery/docs/locations#supported_locations)。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eF-Twtc4XGem"
      },
      "outputs": [],
      "source": [
        "REGION = \"US\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBCra4QMA2wR"
      },
      "source": [
        "### 驗證 Google Cloud 帳戶\n",
        "\n",
        "根據你的 Jupyter 環境，你可能必須手動驗證。依照相關指示操作。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74ccc9e52986"
      },
      "source": [
        "**Vertex AI Workbench** \n",
        "\n",
        "保持不動，你已得到身分驗證。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de775a3773ba"
      },
      "source": [
        "**本地 JupyterLab 範例** \n",
        "\n",
        "取消註解並執行以下Cell：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "254614fa0c46"
      },
      "outputs": [],
      "source": [
        "# ! gcloud auth login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef21552ccea8"
      },
      "source": [
        "**Colab** \n",
        "\n",
        "取消註釋並執行以下Cell：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "603adbbf0532"
      },
      "outputs": [],
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "### 匯入函式庫\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "import bigframes.pandas as bf\n",
        "from google.cloud import bigquery_connection_v1 as bq_connection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "source": [
        "### 設定 BigQuery DataFrames 選項\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPPMuw2PXGeo"
      },
      "outputs": [],
      "source": [
        "bf.options.bigquery.project = PROJECT_ID\n",
        "bf.options.bigquery.location = REGION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTVtFlqeFbrU"
      },
      "source": [
        "如果你想重設建立的 DataFrame 或 Series 物件的位置，執行 `bf.reset_session()` 重設工作階段。然後，你可以重複使用 `bf.options.bigquery.location` 指定另一個位置。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eytf4xQHzcF"
      },
      "source": [
        "# 定義 LLM 模型\n",
        "\n",
        "BigQuery DataFrame 提供與 PaLM API 的 [`text-bison` 模型](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/text) 的整合，透過 Vertex AI。\n",
        "\n",
        "本部分將逐步說明在筆記本中使用模型所需的步驟。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS4VO1TGiO4G"
      },
      "source": [
        "## 建立 BigQuery Cloud 資源連接\n",
        "\n",
        "你需要建立 [Cloud 資源連接](https://cloud.google.com/bigquery/docs/create-cloud-resource-connection) 以讓 BigQuery 資料架構能與 Vertex AI 服務互動。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFPjDM4LVh96"
      },
      "outputs": [],
      "source": [
        "CONN_NAME = \"bqdf-llm\"\n",
        "\n",
        "client = bq_connection.ConnectionServiceClient()\n",
        "new_conn_parent = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
        "exists_conn_parent = f\"projects/{PROJECT_ID}/locations/{REGION}/connections/{CONN_NAME}\"\n",
        "cloud_resource_properties = bq_connection.CloudResourceProperties({})\n",
        "\n",
        "try:\n",
        "    request = client.get_connection(\n",
        "        request=bq_connection.GetConnectionRequest(name=exists_conn_parent)\n",
        "    )\n",
        "    CONN_SERVICE_ACCOUNT = f\"serviceAccount:{request.cloud_resource.service_account_id}\"\n",
        "except Exception:\n",
        "    connection = bq_connection.types.Connection(\n",
        "        {\"friendly_name\": CONN_NAME, \"cloud_resource\": cloud_resource_properties}\n",
        "    )\n",
        "    request = bq_connection.CreateConnectionRequest(\n",
        "        {\n",
        "            \"parent\": new_conn_parent,\n",
        "            \"connection_id\": CONN_NAME,\n",
        "            \"connection\": connection,\n",
        "        }\n",
        "    )\n",
        "    response = client.create_connection(request)\n",
        "    CONN_SERVICE_ACCOUNT = (\n",
        "        f\"serviceAccount:{response.cloud_resource.service_account_id}\"\n",
        "    )\n",
        "print(CONN_SERVICE_ACCOUNT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6l6Ol2biU9h"
      },
      "source": [
        "## 對服務帳戶設定權限\n",
        "\n",
        "資源連線服務帳戶需要特定專案層級的權限：\n",
        " - `roles/aiplatform.user` 及 `roles/bigquery.connectionUser`：這些角色是需要連線去使用 Vertex AI 中的 LLM 模型建立模型定義 ([文件](https://cloud.google.com/bigquery/docs/generate-text#give_the_service_account_access))。\n",
        " - `roles/run.invoker`：此角色是需要連線存取備份自訂／遠端函式的 Cloud Run 服務之唯讀存取 ([文件](https://cloud.google.com/bigquery/docs/remote-functions#grant_permission_on_function))。\n",
        "\n",
        "執行以下 `gcloud` 命令設定這些權限：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8wja24SVq6s"
      },
      "outputs": [],
      "source": [
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={CONN_SERVICE_ACCOUNT} --role='roles/bigquery.connectionUser'\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={CONN_SERVICE_ACCOUNT} --role='roles/aiplatform.user'\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={CONN_SERVICE_ACCOUNT} --role='roles/run.invoker'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUjT8nw-jIXp"
      },
      "source": [
        "## 定義模型\n",
        "\n",
        "使用 bigframes.ml.llm 定義模型:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdjeXFwcHfl7"
      },
      "outputs": [],
      "source": [
        "from bigframes.ml.llm import PaLM2TextGenerator\n",
        "\n",
        "session = bf.get_global_session()\n",
        "connection = f\"{PROJECT_ID}.{REGION}.{CONN_NAME}\"\n",
        "model = PaLM2TextGenerator(session=session, connection_name=connection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbW0oCnU1s1N"
      },
      "source": [
        "# 將 Cloud Storage 中的資料讀取至 BigQuery DataFrames\n",
        "\n",
        "你可以透過閱讀以下任一位置的資料來建立 BigQuery DataFrames DataFrame：\n",
        "\n",
        "* 本地資料檔案\n",
        "* 儲存在 BigQuery 資料表的資料\n",
        "* 儲存在 Cloud Storage 的資料檔案\n",
        "* 記憶中的 pandas DataFrame\n",
        "\n",
        "在本教學課程中，你將透過閱讀儲存在 Cloud Storage 中的兩個 CSV 檔案來建立 BigQuery DataFrames DataFrames，一個包含 DataFrame API 名稱清單，另一個包含 Series API 名稱清單。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SchiTkQGIJog"
      },
      "outputs": [],
      "source": [
        "df_api = bf.read_csv(\"gs://cloud-samples-data/vertex-ai/bigframe/df.csv\")\n",
        "series_api = bf.read_csv(\"gs://cloud-samples-data/vertex-ai/bigframe/series.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OBjw2nmQY3-"
      },
      "source": [
        "看看每個檔案的數列資料：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCqgVCIsGGuv"
      },
      "outputs": [],
      "source": [
        "df_api.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGJnZbgEGS5-"
      },
      "outputs": [],
      "source": [
        "series_api.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3ZJEsi7SUKV"
      },
      "source": [
        "# 使用 LLM 模型產生程式碼\n",
        "\n",
        "準備提示，並將其發送到 LLM 模型進行預測。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EMAqR37AfLS"
      },
      "source": [
        "## 在 BigQuery DataFrames 中使用 Prompt 設計\n",
        "\n",
        "專門設計 LLM 提示的開發領域快速成長，如需瞭解更多資訊，請參閱 [此文件](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/introduction-prompt-design)。\n",
        "\n",
        "在這個教學課程中，你使用一個簡單的提示，請 LLM 模型提供上個步驟 DataFrames 中每個 API 方法 (或列) 的範例程式碼。輸出為新的 DataFrames `df_prompt` 和 `series_prompt`，其中包含提示文字。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDAaIwHpQCDZ"
      },
      "outputs": [],
      "source": [
        "df_prompt_prefix = \"Generate Pandas sample code for DataFrame.\"\n",
        "series_prompt_prefix = \"Generate Pandas sample code for Series.\"\n",
        "\n",
        "df_prompt = df_prompt_prefix + df_api[\"API\"]\n",
        "series_prompt = series_prompt_prefix + series_api[\"API\"]\n",
        "\n",
        "df_prompt.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwPLjqW2Ajzh"
      },
      "source": [
        "## 使用 LLM 範例進行預測\n",
        "\n",
        "將包含完整提示文字的 BigQuery DataFrames DataFrame 作為 `predixt` 方法的輸入。`predixt` 方法會呼叫 LLM 範例，並將其產生的文字輸出傳回兩個新的 BigQuery DataFrames DataFrames，`df_pred` 和 `series_pred`。\n",
        "\n",
        "注意：預測可能需要花費幾分鐘時間執行。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i6HkFJZa8na"
      },
      "outputs": [],
      "source": [
        "df_pred = model.predict(df_prompt.to_frame(), max_output_tokens=1024)\n",
        "series_pred = model.predict(series_prompt.to_frame(), max_output_tokens=1024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89cB8MW4UIdV"
      },
      "source": [
        "一旦預測處理完畢，請檢視 LLM 的範例輸出，其提供 DataFrame 資料集所列 API 名稱的程式碼範例。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9A2gw6hP_2nX"
      },
      "outputs": [],
      "source": [
        "print(df_pred[\"ml_generate_text_llm_result\"].iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx4lsNqMorJ-"
      },
      "source": [
        "# 使用遠端函式操控 LLM 輸出\n",
        "\n",
        "LLM 提供的輸出經常包含超出程式碼範例本身的額外文字。使用 BigQuery DataFrames，你可以部署處理並轉換此輸出的自訂 Python 函式。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8L7SN03VByG"
      },
      "source": [
        "執行下方的Cell會建立一個自訂函式，你可以使用這項函式以兩種方式處理 LLM 輸出的資料：\n",
        "1. 從 LLM 文字輸出中移除程式碼區塊。\n",
        "2. 將 `import pandas as pd` 取代為 `import bigframes.pandas as bf`，讓產生的程式碼區塊可配合 BigQuery Cell使用。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GskyyUQPowBT"
      },
      "outputs": [],
      "source": [
        "@bf.remote_function([str], str, bigquery_connection=CONN_NAME)\n",
        "def extract_code(text: str):\n",
        "    try:\n",
        "        res = text[text.find(\"\\n\") + 1 : text.find(\"```\", 3)]\n",
        "        res = res.replace(\"import pandas as pd\", \"import bigframes.pandas as bf\")\n",
        "        if \"import bigframes.pandas as bf\" not in res:\n",
        "            res = \"import bigframes.pandas as bf\\n\" + res\n",
        "        return res\n",
        "    except:\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVQAoqBUOJQf"
      },
      "source": [
        "自定義函式部署為 [雲端函式](https://cloud.google.com/functions/docs/)，然後與 BigQuery 整合為 [遠端函式](https://cloud.google.com/bigquery/docs/remote-functions)。儲存兩個函式的名稱，以便你可以在這個筆記本的結尾清理它們。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBlp-C-DOHRO"
      },
      "outputs": [],
      "source": [
        "CLOUD_FUNCTION_NAME = format(extract_code.bigframes_cloud_function)\n",
        "print(\"Cloud Function Name \" + CLOUD_FUNCTION_NAME)\n",
        "REMOTE_FUNCTION_NAME = format(extract_code.bigframes_remote_function)\n",
        "print(\"Remote Function Name \" + REMOTE_FUNCTION_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FEucaiqVs3H"
      },
      "source": [
        "將客製化函式套用於每一 筆 LLM 輸出 DataFrame，以取得處理過的結果：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsQ9cmoWo0Ps"
      },
      "outputs": [],
      "source": [
        "df_code = df_pred.assign(\n",
        "    code=df_pred[\"ml_generate_text_llm_result\"].apply(extract_code)\n",
        ")\n",
        "series_code = series_pred.assign(\n",
        "    code=series_pred[\"ml_generate_text_llm_result\"].apply(extract_code)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujQVVuhfWA3y"
      },
      "source": [
        "你可以透過檢視第一行資料來看出差異：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yWzjhGy_zcy"
      },
      "outputs": [],
      "source": [
        "print(df_code[\"code\"].iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTRdUw-Ro5R1"
      },
      "source": [
        "# 將結果儲存至雲端儲存空間\n",
        "\n",
        "BigQuery DataFrames 可讓你將 BigQuery DataFrames DataFrame 作為 CSV 檔案儲存到雲端儲存空間，以利後續使用。現在就使用處理過的 LLM 輸出資料試試看。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DQ7eiQxPTi3"
      },
      "source": [
        "建立一個有唯一名稱的新 Cloud Storage 儲存空間：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J5LHgS6LLZ0"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "BUCKET_ID = \"code-samples-\" + str(uuid.uuid1())\n",
        "\n",
        "!gsutil mb gs://{BUCKET_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyxZXj0UPYUv"
      },
      "source": [
        "使用 `to_csv` 將每個 BigQuery DataFrame 資料框作為 CSV 檔案寫入 Cloud Storage 儲存空間:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zs_b5L-4IvER"
      },
      "outputs": [],
      "source": [
        "df_code[[\"code\"]].to_csv(f\"gs://{BUCKET_ID}/df_code*.csv\")\n",
        "series_code[[\"code\"]].to_csv(f\"gs://{BUCKET_ID}/series_code*.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDBtDlrTuuh8"
      },
      "source": [
        "你可以前往 Cloud Storage 儲存空間瀏覽器下載這兩個檔案並檢視。\n",
        "\n",
        "執行下列Cell，然後連結至你的 Cloud Storage 儲存空間瀏覽器：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PspCXu-qu_ND"
      },
      "outputs": [],
      "source": [
        "print(f\"https://console.developers.google.com/storage/browser/{BUCKET_ID}/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGSvUk48RK20"
      },
      "source": [
        "# 總結和後續步驟\n",
        "\n",
        "你已使用 BigQuery DataFrames 與 LLM 模型 (`bigframes.ml.llm`) 的整合產生程式碼範例，並透過在 BigQuery DataFrames 中建立和使用自訂函式來轉換 LLM 輸出。\n",
        "\n",
        "進一步了解 [文件](https://cloud.google.com/python/docs/reference/bigframes/latest) 中的 BigQuery DataFrames，並在 [GitHub 儲存庫](https://github.com/googleapis/python-bigquery-dataframes/tree/main/notebooks) 中找出更多範例筆記本。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## 清理\n",
        "\n",
        "如需清理此專案中使用的所有 Google Cloud 資源，你可以 [刪除專案](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) 用於教學課程。\n",
        "\n",
        "否則，你可以取消註解剩餘的Cell，然後執行它們，以刪除你在此教學課程中建立的個別資源：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw7A461XLjvW"
      },
      "outputs": [],
      "source": [
        "# # Delete the BigQuery Connection\n",
        "# from google.cloud import bigquery_connection_v1 as bq_connection\n",
        "# client = bq_connection.ConnectionServiceClient()\n",
        "# CONNECTION_ID = f\"projects/{PROJECT_ID}/locations/{REGION}/connections/{CONN_NAME}\"\n",
        "# client.delete_connection(name=CONNECTION_ID)\n",
        "# print(f\"Deleted connection '{CONNECTION_ID}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx_vKniMq9ZX"
      },
      "outputs": [],
      "source": [
        "# # Delete the Cloud Function\n",
        "# ! gcloud functions delete {CLOUD_FUNCTION_NAME} --quiet\n",
        "# # Delete the Remote Function\n",
        "# REMOTE_FUNCTION_NAME = REMOTE_FUNCTION_NAME.replace(PROJECT_ID + \".\", \"\")\n",
        "# ! bq rm --routine --force=true {REMOTE_FUNCTION_NAME}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQFo6OUBLmi3"
      },
      "outputs": [],
      "source": [
        "# # Delete the Google Cloud Storage bucket and files\n",
        "# ! gsutil rm -r gs://{BUCKET_ID}\n",
        "# print(f\"Deleted bucket '{BUCKET_ID}'.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "bq_dataframes_llm_code_generation.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}