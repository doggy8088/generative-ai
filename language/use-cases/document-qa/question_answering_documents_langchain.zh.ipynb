{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# ä½¿ç”¨ LangChain åœ¨å¤§å‹æ–‡ä»¶ä¸­é€²è¡Œå•ç­” ğŸ¦œğŸ”—\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/doggy8088/generative-ai/blob/main/language/use-cases/document-qa/question_answering_documents_langchain.zh.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> åœ¨ Colab ä¸­åŸ·è¡Œ\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/doggy8088/generative-ai/blob/main/language/use-cases/document-qa/question_answering_documents_langchain.zh.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> æŸ¥çœ‹ GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/doggy8088/generative-ai/blob/main/language/use-cases/document-qa/question_answering_documents_langchain.zh.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> åœ¨ Vertex AI Workbench ä¸­é–‹å•Ÿ\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|ä½œè€…| [Lavi Nigam](https://github.com/lavinigam-gcp) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## æ¦‚è¿°\n",
        "\n",
        "é€™å€‹ç­†è¨˜æœ¬å±•ç¤ºå¦‚ä½•ä½¿ç”¨ Vertex AI PaLM APIï¼Œå»ºæ§‹ä¸€å€‹ä½¿ç”¨ LangChain çš„å•é¡Œè§£ç­” (Q&A) ç³»çµ±ï¼Œä»¥å¾å¤§å‹æ–‡ä»¶æå–è³‡è¨Šã€‚\n",
        "\n",
        "åœ¨å¤§å‹æ–‡ä»¶ä¸­å»ºæ§‹å•ç­”ç³»çµ±çš„æŒ‘æˆ°åœ¨æ–¼å¤§å‹èªè¨€æ¨¡å‹ (ç°¡ç¨± LLM)ï¼Œå…¶æ¬Šæ–é™åˆ¶äº†å¯ä»¥ä½¿ç”¨å¤šå°‘å…§å®¹ã€‚\n",
        "\n",
        "æœ‰å¹¾ç¨®æ–¹æ³•å¯ä»¥æä¾›æ–‡æœ¬ã€‚é€™äº›æ–¹æ³•å¯ä»¥ä½¿ç”¨ç›¸ä¼¼æ€§æœå°‹æˆ–ä¸ä½¿ç”¨ã€‚é‚„æœ‰ä¸åŒçš„æ–¹æ³•å¯ä»¥å°‡å…§å®¹å‚³éçµ¦ LLMã€‚é€™å€‹ç­†è¨˜æœ¬åŒ…å«ä¸‹åˆ—æ–¹æ³•æˆ–éˆï¼š\n",
        "\n",
        "- **çŒå…¥** : å°‡æ•´å€‹æ–‡ä»¶å…§å®¹ä½œç‚ºå…§å®¹ã€‚é€™æ˜¯æœ€ç°¡å–®çš„æ–¹æ³•ï¼Œä½†å°æ–¼å¤§å‹æ–‡ä»¶å¯èƒ½æœƒå¾ˆæ²’æ•ˆç‡ã€‚\n",
        "\n",
        "- **Map-Reduce** : å°‡æ–‡ä»¶åˆ†æˆè¼ƒå°çš„å€å¡Šï¼Œä¸¦å¹³è¡Œè™•ç†ã€‚é€™æ¯”çŒå…¥æ›´æœ‰æ•ˆç‡ï¼Œä½†å¯¦ä½œä¸Šæœƒæ¯”è¼ƒè¤‡é›œã€‚\n",
        "\n",
        "- **èª¿æ•´** : å°ä¸€å°éƒ¨åˆ†åŸ·è¡Œåˆå§‹æç¤ºï¼Œç”Ÿæˆè¼¸å‡ºï¼Œä¸¦é‡å°æ¯å€‹å¾ŒçºŒæ–‡ä»¶ï¼Œæ ¹æ“šè¼¸å‡ºå’Œæ–°æ–‡ä»¶èª¿æ•´è¼¸å‡ºã€‚é€™æ¯” Map-Reduce æ›´æº–ç¢ºï¼Œä¸éæ•ˆç‡è¼ƒä½ã€‚\n",
        "\n",
        "é€™å€‹ç­†è¨˜æœ¬ä¹Ÿå±•ç¤ºä½¿ç”¨å‘é‡ç›¸ä¼¼æ€§æœå°‹çš„ã€Œ**Map-Reduce èˆ‡é¡ä¼¼æ€§æœå°‹** ã€ï¼Œå…¶ä¸­ä½ å¯ä»¥å»ºç«‹è¼ƒå°å€å¡Šçš„åµŒå…¥ï¼Œä¸¦ä½¿ç”¨å‘é‡ç›¸ä¼¼æ€§æœå°‹æ‰¾åˆ°ç›¸é—œå…§å®¹ã€‚é€™æ˜¯æœ€æœ‰æ•ˆç‡çš„æ–¹æ³•ï¼Œä¸éå¯¦ä½œä¹Ÿå¯èƒ½æœ€è¤‡é›œã€‚\n",
        "\n",
        "ç­è§£æ›´å¤šé—œæ–¼ [LangChain](https://python.langchain.com/en/latest/use_cases/question_answering.html) å’Œ [Vertex Gen AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d975e698c9a4"
      },
      "source": [
        "### ç›®æ¨™\n",
        "\n",
        "åœ¨æ­¤æ•™å­¸èª²ç¨‹ä¸­ï¼Œä½ å°‡å­¸ç¿’å¦‚ä½•åŸ·è¡Œä»¥ä¸‹æ“ä½œï¼š\n",
        "\n",
        "- æ“·å–æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…æ‹¬ä¸‹è¼‰æ–‡ä»¶ã€‚\n",
        "- ä½¿ç”¨ LangChain `PyPDFLoader` å¾ PDF èƒå–æ–‡å­—ã€‚\n",
        "- é¸å–èªå¢ƒï¼Œç”¨æ–¼è¾¨è­˜æ–‡ä»¶ç›¸é—œéƒ¨åˆ†ï¼Œä»¥å›ç­”å•é¡Œã€‚\n",
        "- è¨­è¨ˆå•é¡Œå›ç­”æç¤º\n",
        "- é‡å°è™•ç†å¤§å‹èªå¢ƒï¼Œä½¿ç”¨å…·å‚™æˆ–ä¸å…·å‚™åµŒå…¥å¼çš„éˆ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aed92deeb4a0"
      },
      "source": [
        "### è²»ç”¨\n",
        "\n",
        "æœ¬æ•™å­¸æŒ‡å—ä½¿ç”¨ Google Cloud çš„è¨ˆè²»å…ƒä»¶ï¼š\n",
        "\n",
        "* Vertex AI ç”Ÿæˆå¼ AI Studio\n",
        "\n",
        "äº†è§£ [Vertex AI åƒ¹æ ¼](https://cloud.google.com/vertex-ai/pricing)ï¼Œ\n",
        "ä¸¦ä½¿ç”¨ [åƒ¹æ ¼è¨ˆç®—å™¨](https://cloud.google.com/products/calculator/)\n",
        "æ ¹æ“šé è¨ˆä½¿ç”¨æƒ…æ³ç”¢ç”Ÿè²»ç”¨ä¼°ç®—å€¼ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uSGoyR6RrTQ"
      },
      "source": [
        "## é–‹å§‹ä½¿ç”¨\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "### å®‰è£ Vertex AI SDKã€å…¶ä»–å¥—ä»¶åŠå…¶ç›¸ä¾æ€§\n",
        "\n",
        "å®‰è£åŸ·è¡Œæ­¤é›²ç«¯ç­†è¨˜æœ¬æ‰€éœ€çš„ä¸‹åˆ—å¥—ä»¶ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tvCecNMQpXk"
      },
      "outputs": [],
      "source": [
        "# Base system dependencies\n",
        "!sudo apt -y -qq install tesseract-ocr libtesseract-dev\n",
        "\n",
        "# required by PyPDF2 for page count and other pdf utilities\n",
        "!sudo apt-get -y -qq install poppler-utils python-dev libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesseract-ocr flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b4ef9b72d43"
      },
      "outputs": [],
      "source": [
        "# Install the packages\n",
        "import os\n",
        "\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    USER = \"--user\"\n",
        "else:\n",
        "    USER = \"\"\n",
        "# Install Vertex AI LLM SDK, langchain and dependencies\n",
        "! pip install google-cloud-aiplatform langchain==0.0.323 chromadb==0.3.26 pydantic==1.10.8 typing-inspect==0.8.0 typing_extensions==4.5.0 pandas datasets google-api-python-client transformers==4.33.1 pypdf faiss-cpu config --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58707a750154"
      },
      "source": [
        "### åƒ… Colabï¼šå–æ¶ˆä»¥ä¸‹Cellè¨»è§£ï¼Œé‡æ–°å•Ÿå‹•æ ¸å¿ƒã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yStiAHorWE3Q"
      },
      "source": [
        "***åƒ…é™ Colab** *ï¼šåŸ·è¡Œä¸‹åˆ—Cellé‡æ–°å•Ÿå‹•æ ¸å¿ƒï¼Œæˆ–ä½¿ç”¨æŒ‰éˆ•é‡æ–°å•Ÿå‹•æ ¸å¿ƒã€‚ä½ çš„ Vertex AI Workbench å¯ä»¥ä½¿ç”¨é ‚ç«¯çš„æŒ‰éˆ•é‡æ–°å•Ÿå‹•çµ‚ç«¯æ©Ÿã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f200f10a1da3"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opUxT_k5TdgP"
      },
      "source": [
        "### é©—è­‰ä½ çš„ç­†è¨˜æœ¬ç’°å¢ƒ\n",
        "\n",
        "- å¦‚æœä½ ä½¿ç”¨ **Colab** ä¾†åŸ·è¡Œé€™å€‹ç­†è¨˜æœ¬ï¼Œè«‹åŸ·è¡Œä»¥ä¸‹å–®å…ƒæ ¼ä¸¦ç¹¼çºŒã€‚\n",
        "- å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ **Vertex AI Workbench** ï¼Œåœ¨æ­¤è™•æŸ¥çœ‹è¨­å®šèªªæ˜ [link](https://github.com/doggy8088/generative-ai/tree/main/setup-env).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbNgv4q1T2Mi"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- å¦‚æœä½ æ˜¯åœ¨æœ¬æ©Ÿé–‹ç™¼ç’°å¢ƒä¸­åŸ·è¡Œé€™å€‹ç­†è¨˜æœ¬ï¼š\n",
        "  - å®‰è£ [Google Cloud SDK](https://cloud.google.com/sdk)ã€‚\n",
        "  - å–å¾—é©—è­‰æ†‘è­‰ã€‚é€éåŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤ä¸¦éµå¾ª oauth2 æµç¨‹ (åœ¨æ­¤è™•é€²ä¸€æ­¥äº†è§£æ­¤æŒ‡ä»¤ [here](https://cloud.google.com/sdk/gcloud/reference/beta/auth/application-default/login))ï¼Œä¾†å»ºç«‹æœ¬åœ°æ†‘è­‰ï¼š\n",
        "\n",
        "    ```bash\n",
        "    gcloud auth application-default login\n",
        "    ```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "### åŒ¯å…¥å‡½å¼åº«\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**åƒ…é™ Colabï¼š** åŸ·è¡Œä¸‹åˆ—Cellä»¥åˆå§‹åŒ– Vertex AI SDKã€‚å°æ–¼ Vertex AI Workbenchï¼Œä¸éœ€è¦åŸ·è¡Œæ­¤æ“ä½œã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjSsu6cmUdEx"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "REGION = \"us-central1\"\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "import warnings\n",
        "from pathlib import Path as p\n",
        "from pprint import pprint\n",
        "\n",
        "import pandas as pd\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# restart python kernel if issues with langchain import."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAGaTjPVTmhP"
      },
      "source": [
        "### åŒ¯å…¥æ¨¡å‹\n",
        "\n",
        "ä½ åˆ†åˆ¥è¼‰å…¥é å…ˆè¨“ç·´å¥½çš„æ–‡æœ¬å’Œå°è£ç”¢ç”Ÿæ¨¡å‹ï¼Œç¨±ç‚º `text-bison@001` å’Œ `textembedding-gecko@001`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITUmZiNZcMUW"
      },
      "outputs": [],
      "source": [
        "vertex_llm_text = VertexAI(model_name=\"text-bison@001\")\n",
        "vertex_embeddings = VertexAIEmbeddings(model_name=\"textembedding-gecko@001\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxgiio5qTSGG"
      },
      "source": [
        "## ä½¿ç”¨å¤§å‹æ–‡ä»¶é€²è¡Œå•ç­”\n",
        "\n",
        "å¤§å‹èªè¨€æ¨¡å‹ (LLM) æ˜¯ä¸€æ¬¾å¼·å¤§çš„å·¥å…·ï¼Œå¯ç”¨æ–¼å›ç­”èˆ‡å¤§å‹æ–‡ä»¶è³‡æ–™åº«ç¯„åœå»£æ³›ç›¸é—œçš„å•é¡Œã€‚ä½†æ˜¯ï¼Œä½¿ç”¨ LLM é€²è¡Œå•ç­”æœƒé‡åˆ°ä¸€äº›æŒ‘æˆ°ã€‚æŒ‘æˆ°ä¹‹ä¸€èˆ‡ LLM æ¨¡å‹å…·æœ‰çš„æœ‰é™çŸ¥è­˜æœ‰é—œï¼Œç‰¹åˆ¥æ˜¯åœ¨æ–‡ä»¶ç‚ºç‰¹å®šå…§å®¹æ™‚ã€‚\n",
        "\n",
        "è§£æ±ºæ­¤é™åˆ¶çš„æ–¹æ³•ä¹‹ä¸€æ˜¯ä½¿ç”¨æª¢ç´¢å¢å¼·ç”Ÿæˆä¾†æä¾›æœ‰é—œæ–‡ä»¶çš„è©³ç´°è³‡è¨Šã€‚æª¢ç´¢å¢å¼·ç”Ÿæˆæ˜¯ä¸€ç¨®åˆ©ç”¨ LLM ä¾†å›ç­”å…¶æœªæ¥å—éè¨“ç·´çš„æ–‡ä»¶å•é¡Œçš„æŠ€è¡“ã€‚åŸºæœ¬åŸç†æ˜¯å…ˆå¾èªæ–™åº«ä¸­æª¢ç´¢ä»»ä½•ç›¸é—œæ–‡ä»¶ï¼Œç¨±ç‚ºã€Œèªå¢ƒã€ï¼Œå†å°‡é€™äº›æ–‡ä»¶èˆ‡åŸå§‹å•é¡Œä¸€èµ·å‚³éçµ¦ LLMã€‚ç„¶å¾Œï¼ŒLLM å°‡æ ¹æ“šå·²æª¢ç´¢æ–‡ä»¶çš„è³‡è¨Šç”¢ç”Ÿå›æ‡‰ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZkLDRTjTcfm"
      },
      "source": [
        "### åŒ¯å…¥æ–‡ä»¶\n",
        "\n",
        "è¦é–‹å§‹ä¹‹å‰ï¼Œä½ å¿…é ˆä¸‹è¼‰ä¸‹åˆ—å¹¾å€‹æª”æ¡ˆï¼Œé€™äº›æª”æ¡ˆæ˜¯ä¸‹è¿°æ‘˜è¦ä»»å‹™æ‰€éœ€ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H0zINHpTaSu"
      },
      "outputs": [],
      "source": [
        "data_folder = p.cwd() / \"data\"\n",
        "p(data_folder).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "pdf_url = \"https://services.google.com/fh/files/misc/practitioners_guide_to_mlops_whitepaper.pdf\"\n",
        "pdf_file = str(p(data_folder, pdf_url.split(\"/\")[-1]))\n",
        "\n",
        "urllib.request.urlretrieve(pdf_url, pdf_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JELITHdBhnf0"
      },
      "source": [
        "### å¾ PDF ä¸­æ“·å–æ–‡å­—\n",
        "\n",
        "ä½¿ç”¨ `PdfReader` å¾æƒææ–‡ä»¶æ“·å–æ–‡å­—ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3INtovxreI_"
      },
      "outputs": [],
      "source": [
        "pdf_loader = PyPDFLoader(pdf_file)\n",
        "pages = pdf_loader.load_and_split()\n",
        "print(pages[3].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soNkAis3F3DT"
      },
      "source": [
        "### æç¤ºè¨­è¨ˆ\n",
        "\n",
        "åœ¨å•ç­”ç³»çµ±ä¸­ï¼Œä½ å®šç¾©ä¸€å€‹å•é¡Œå’Œç›¸é—œæç¤ºã€‚\n",
        "\n",
        "å•é¡Œåªæ˜¯ä¸€å€‹å­—ä¸²ï¼Œè¡¨ç¤ºæ‡‰ç”¨ç¨‹å¼å°‡è¢«è¦æ±‚å›ç­”çš„å•é¡Œã€‚åœ¨æ­¤æ¡ˆä¾‹ä¸­ï¼Œå•é¡Œæ˜¯ ```\"ä»€éº¼æ˜¯å¯¦é©—ï¼Ÿ\"```\n",
        "\n",
        "æç¤ºæ˜¯ä¸€å€‹å­—ä¸²ï¼ŒåŒ…å«æ‡‰ç”¨ç¨‹å¼å°‡ç”¨æ–¼ç”¢ç”Ÿå°å•é¡Œçš„å›ç­”ä¹‹æƒ…å¢ƒã€‚åœ¨æ­¤æ¡ˆä¾‹ä¸­ï¼Œæç¤ºæ˜¯\n",
        "\n",
        "```\n",
        "ä½¿ç”¨æä¾›çš„å…§å®¹ç›¡å¯èƒ½ç²¾ç¢ºåœ°å›ç­”å•é¡Œã€‚\n",
        "å¦‚æœç­”æ¡ˆæœªåŒ…å«åœ¨å…§å®¹ä¸­ï¼Œè«‹èªªã€Œç­”æ¡ˆåœ¨å…§å®¹ä¸­ä¸å¯ç”¨ã€ \\\\n\\\\n\n",
        "\n",
        "èªå¢ƒï¼š\\\\n {context}ï¼Ÿ\\\\n\n",
        "å•é¡Œï¼š\\\\n {question} \\\\n\n",
        "ç­”æ¡ˆï¼š\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EGBdXZWF3DT"
      },
      "outputs": [],
      "source": [
        "question = \"What is Experimentation?\"\n",
        "prompt_template = \"\"\"Answer the question as precise as possible using the provided context. If the answer is\n",
        "                    not contained in the context, say \"answer not available in context\" \\n\\n\n",
        "                    Context: \\n {context}?\\n\n",
        "                    Question: \\n {question} \\n\n",
        "                    Answer:\n",
        "                  \"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLVkm8LPNxNb"
      },
      "source": [
        "### ä¸å¸¶ç›¸ä¼¼æ€§æœå°‹çš„å•ç­”\n",
        "\n",
        "é—œæ–¼æä¾›ä¸Šä¸‹æ–‡ï¼Œä½ å¯ä»¥æä¾›å®ƒï¼Œæˆ–ä½ å¯ä»¥ä½¿ç”¨ä½ æ­£åœ¨å°‹æ‰¾ç­”æ¡ˆçš„æ–‡å­—éƒ¨åˆ†ã€‚\n",
        "\n",
        "åœ¨æ­¤ç¯„ä¾‹ä¸­ï¼Œä½ é¸å‡ºå‰å…«é åšç‚ºä½ å•ç­”ç³»çµ±çš„ä¸Šä¸‹æ–‡ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50nOEGm_F3DS"
      },
      "source": [
        "#### èƒŒæ™¯é¸æ“‡\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGKGGzcusLNP"
      },
      "outputs": [],
      "source": [
        "context = \"\\n\".join(str(p.page_content) for p in pages[:7])\n",
        "print(\"The total words in the context: \", len(context))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsSKyi0vVnjj"
      },
      "source": [
        "#### å•èˆ‡ç­”æ–¹æ³•æˆ–éˆæ¢\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDVwBFSjZ7ws"
      },
      "source": [
        "##### æ–¹æ³• 1ï¼šå¡å…¥\n",
        "\n",
        "`å¡å…¥` æ˜¯ä¸€ç¨®å°‡å¤§å‹èªè¨€æ¨¡å‹ (LLM) æ‡‰ç”¨åˆ°å•ç­”ä¸­çš„ç°¡å–®æ–¹æ³•ã€‚å…¶æ¶‰åŠåœ¨æç¤ºä¸­æä¾›æ‰€æœ‰ç›¸é—œè³‡æ–™ç‚ºèªå¢ƒï¼Œæä¾›çµ¦å¤§å‹èªè¨€æ¨¡å‹ã€‚\n",
        "\n",
        "åœ¨ LangChain ä¸­ï¼Œä½ å¯ä»¥å°‡ `StuffDocumentsChain` ç”¨ä½œ `load_qa_chain` æ–¹æ³•çš„ä¸€éƒ¨åˆ†ã€‚ä½ éœ€è¦çš„éƒ¨åˆ†æ˜¯å°‡ `chain_type` è¨­å®šç‚ºéˆçš„ `stuff`ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3baLTKgt7LU"
      },
      "outputs": [],
      "source": [
        "stuff_chain = load_qa_chain(vertex_llm_text, chain_type=\"stuff\", prompt=prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSLlVLsMa-Kq"
      },
      "source": [
        "åœ¨ä½ åˆå§‹åŒ–  `load_qa_chain` éˆå¾Œï¼Œä½ å¯ä»¥æ ¹æ“šè¼¸å…¥æ–‡ä»¶å›ç­”å•é¡Œã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHDja-L4bGFD"
      },
      "outputs": [],
      "source": [
        "stuff_answer = stuff_chain(\n",
        "    {\"input_documents\": pages[7:10], \"question\": question}, return_only_outputs=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FK1PO3Kzv_2v"
      },
      "outputs": [],
      "source": [
        "pprint(stuff_answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ4PJ96mX3kI"
      },
      "source": [
        "ã€Œå¡«å……ã€æ–¹æ³•çš„å„ªé»æ˜¯åªéœ€å‘¼å« LLM ä¸€æ¬¡ï¼Œä½†å—é™æ–¼ LLM çš„è„ˆçµ¡é•·åº¦ï¼Œå°æ–¼å¤§é‡çš„è³‡æ–™è€Œè¨€ä¸¦ä¸å¯è¡Œã€‚\n",
        "\n",
        "ä»¥ä¸‹æ˜¯ç•¶è„ˆçµ¡é”åˆ° LLM çš„é™åˆ¶æ™‚å‡ºç¾çš„ç•°å¸¸æƒ…æ³ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nYFv2Iyx9TD"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    print(\n",
        "        stuff_chain(\n",
        "            {\"input_documents\": pages[7:], \"question\": question},\n",
        "            return_only_outputs=True,\n",
        "        )\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(\n",
        "        \"The code failed since it won't be able to run inference on such a huge context and throws this exception: \",\n",
        "        e,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KDDYnK6yZOu"
      },
      "source": [
        "################### æ–¹æ³• 2ï¼šMapReduce\n",
        "\n",
        "é€éï¼Œä½ å¯ä»¥å…‹æœæ–‡å­—ä¸Šé™ã€‚å®ƒåŒ…å«å°‡æ–‡ä»¶åˆ†ç‚ºå¤šå€‹æ®µè½ã€ç‚ºæ¯å€‹æ®µè½åŸ·è¡Œåˆå§‹æç¤ºï¼Œç„¶å¾Œä½¿ç”¨ä¸åŒçš„æç¤ºåˆä½µåˆå§‹æç¤ºçµæœã€‚\n",
        "\n",
        "åœ¨ LangChain ä¸­ï¼Œä½ å¯ä»¥å°‡ç”¨æ–¼`load_qa_chain`æ–¹æ³•çš„ä¸€éƒ¨åˆ†ï¼Œä¸”éˆçš„`chain_type`ç‚º`map_reduce`ã€‚\n",
        "\n",
        "`load_qa_chain`ä½¿ç”¨`map_reduce`ä½œç‚º`chain_type`éœ€è¦å…©å€‹æç¤ºï¼šå•é¡Œå’Œåˆä½µæç¤ºã€‚\n",
        "\n",
        "å•é¡Œæç¤ºç”¨æ–¼è¦æ±‚ LLM æ ¹æ“šææ‹±çš„å…§å®¹å›ç­”å•é¡Œã€‚åœ¨æ­¤æƒ…æ³ä¸‹ï¼Œ`question_prompt`ç‚º\n",
        "\n",
        "```\n",
        "æ ¹æ“šæä¾›çš„å…§å®¹ç›¡å¯èƒ½ç²¾ç¢ºåœ°å›ç­”å•é¡Œã€‚ \\n\\n\n",
        "å…§å®¹ï¼š\\n {context} \\n\n",
        "å•é¡Œï¼š\\n {question} \\n\n",
        "ç­”æ¡ˆï¼š\n",
        "```\n",
        "\n",
        "åˆä½µæç¤ºç‰©ä»¶ç”¨æ–¼åˆä½µæå–çš„å…§å®¹å’Œå•é¡Œï¼Œä»¥å»ºç«‹æœ€çµ‚ç­”æ¡ˆã€‚åœ¨æ­¤æƒ…æ³ä¸‹ï¼Œ`combine_prompt`ç‚º\n",
        "\n",
        "```\n",
        "æ ¹æ“šæå–çš„å…§å®¹å’Œå•é¡Œå»ºç«‹æœ€çµ‚ç­”æ¡ˆã€‚\n",
        "å¦‚æœç­”æ¡ˆä¸åŒ…å«æ–¼å…§å®¹ä¸­ï¼Œè«‹è¡¨ç¤ºã€Œç­”æ¡ˆæœªå‡ºç¾åœ¨å…§å®¹ä¸­ã€ã€‚ \\n\\n\n",
        "æ‘˜è¦ï¼š\\n {summaries}?\\n\n",
        "å•é¡Œï¼š\\n {question} \\n\n",
        "ç­”æ¡ˆï¼š\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJeB8gG-3OIB"
      },
      "outputs": [],
      "source": [
        "question_prompt_template = \"\"\"\n",
        "                    Answer the question as precise as possible using the provided context. \\n\\n\n",
        "                    Context: \\n {context} \\n\n",
        "                    Question: \\n {question} \\n\n",
        "                    Answer:\n",
        "                    \"\"\"\n",
        "question_prompt = PromptTemplate(\n",
        "    template=question_prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "# summaries is required. a bit confusing.\n",
        "combine_prompt_template = \"\"\"Given the extracted content and the question, create a final answer.\n",
        "If the answer is not contained in the context, say \"answer not available in context. \\n\\n\n",
        "Summaries: \\n {summaries}?\\n\n",
        "Question: \\n {question} \\n\n",
        "Answer:\n",
        "\"\"\"\n",
        "combine_prompt = PromptTemplate(\n",
        "    template=combine_prompt_template, input_variables=[\"summaries\", \"question\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8IdKzmGade1"
      },
      "source": [
        "å®šç¾©é æœŸçš„æç¤ºç¬¦å¾Œï¼Œåˆå§‹åŒ–ä¸€å€‹ `load_qa_chain` éˆã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmkGiHXB2ID3"
      },
      "outputs": [],
      "source": [
        "map_reduce_chain = load_qa_chain(\n",
        "    vertex_llm_text,\n",
        "    chain_type=\"map_reduce\",\n",
        "    return_intermediate_steps=True,\n",
        "    question_prompt=question_prompt,\n",
        "    combine_prompt=combine_prompt,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EjeKpt6bIiC"
      },
      "source": [
        "ä½ æ ¹æ“šè¼¸å…¥æ–‡ä»¶å›ç­”ä½ çš„å•é¡Œã€‚è«‹æ³¨æ„ä½ å¦‚ä½•å‚³éæ•´å€‹æ–‡ä»¶æ•¸æ“šåº«ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glkyJqiZ49Fq"
      },
      "outputs": [],
      "source": [
        "map_reduce_outputs = map_reduce_chain({\"input_documents\": pages, \"question\": question})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiORwQpAbOAl"
      },
      "source": [
        "ä½ å¯ä»¥å°‡ç­”æ¡ˆå„²å­˜åœ¨ Pandas è³‡æ–™æ¡†ä¸­ä»¥æª¢æŸ¥ `MapReduce` ä¸­é–“æ­¥é©Ÿèˆ‡ LLM çš„å›ç­”ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6FRSR7xRLew"
      },
      "outputs": [],
      "source": [
        "final_mp_data = []\n",
        "\n",
        "# for each document, extract metadata and intermediate steps of the MapReduce process\n",
        "for doc, out in zip(\n",
        "    map_reduce_outputs[\"input_documents\"], map_reduce_outputs[\"intermediate_steps\"]\n",
        "):\n",
        "    output = {}\n",
        "    output[\"file_name\"] = p(doc.metadata[\"source\"]).stem\n",
        "    output[\"file_type\"] = p(doc.metadata[\"source\"]).suffix\n",
        "    output[\"page_number\"] = doc.metadata[\"page\"]\n",
        "    output[\"chunks\"] = doc.page_content\n",
        "    output[\"answer\"] = out\n",
        "    final_mp_data.append(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA9cnh8YaNbF"
      },
      "outputs": [],
      "source": [
        "# create a dataframe from a dictionary\n",
        "pdf_mp_answers = pd.DataFrame.from_dict(final_mp_data)\n",
        "# sorting the dataframe by filename and page_number\n",
        "pdf_mp_answers = pdf_mp_answers.sort_values(by=[\"file_name\", \"page_number\"])\n",
        "pdf_mp_answers.reset_index(inplace=True, drop=True)\n",
        "pdf_mp_answers.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yA0eM1K3cvH2"
      },
      "outputs": [],
      "source": [
        "index = 3\n",
        "print(\"[Context]\")\n",
        "print(pdf_mp_answers[\"chunks\"].iloc[index])\n",
        "print(\"\\n\\n [Answer]\")\n",
        "print(pdf_mp_answers[\"answer\"].iloc[index])\n",
        "print(\"\\n\\n [Page number]\")\n",
        "print(pdf_mp_answers[\"page_number\"].iloc[index])\n",
        "print(\"\\n\\n [Source: file_name]\")\n",
        "print(pdf_mp_answers[\"file_name\"].iloc[index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YEQl-dnCIMh"
      },
      "outputs": [],
      "source": [
        "index = 5\n",
        "print(\"[Context]\")\n",
        "print(pdf_mp_answers[\"chunks\"].iloc[index])\n",
        "print(\"\\n\\n [Answer]\")\n",
        "print(pdf_mp_answers[\"answer\"].iloc[index])\n",
        "print(\"\\n\\n [Page number]\")\n",
        "print(pdf_mp_answers[\"page_number\"].iloc[index])\n",
        "print(\"\\n\\n [Source: file_name]\")\n",
        "print(pdf_mp_answers[\"file_name\"].iloc[index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heqYTfSocXcZ"
      },
      "source": [
        "**è€ƒé‡ï¼š** `MapReduce` æ–¹æ³•æœ‰å„ªé»ï¼Œå°±æ˜¯èƒ½æ“´å……è‡³æ¯”å¡«å¡æ–¹æ³•æ›´å¤§é‡çš„è³‡æ–™ï¼Œä½†æœƒéœ€è¦æ›´å¤šå‘¼å« LLMï¼Œè€Œä¸”åœ¨æœ€å¾Œçµ„åˆå‘¼å«æ™‚å¯èƒ½æœƒéºå¤±éƒ¨åˆ†è³‡è¨Šã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzrghSSLC4Hr"
      },
      "source": [
        "##### æ–¹æ³• 3ï¼šRefine\n",
        "\n",
        "ä½¿ç”¨ `Refine` æ–¹æ³•å˜—è©¦å…‹æœ `MapReduce` æ–¹æ³•çš„ `è³‡è¨Š` éºå¤±ã€‚æ­¤æ–¹æ³•åŒ…å«å°ç¬¬ä¸€å¡Šè³‡æ–™åŸ·è¡Œåˆå§‹æç¤ºã€ç”¢ç”Ÿè¼¸å‡ºã€‚å°æ–¼å…¶é¤˜æ–‡ä»¶ï¼Œå°‡è©²è¼¸å‡ºèˆ‡ä¸‹ä¸€å€‹æ–‡ä»¶ä¸€åŒå‚³å…¥ï¼Œè¦æ±‚ LLM æ ¹æ“šæ–°æ–‡ä»¶ï¼Œå°è¼¸å‡ºé€²è¡Œå„ªåŒ–ã€‚\n",
        "\n",
        "åœ¨ LangChain ä¸­ï¼Œä½ å¯ä»¥ä½¿ç”¨ `MapReduceDocumentsChain` ä½œç‚º `load_qa_chain` æ–¹æ³•çš„ä¸€éƒ¨åˆ†ã€‚ä½ æ‰€éœ€è¦åšçš„æ˜¯å°‡ `refine` è¨­å®šç‚ºä½ çš„éˆçš„ `chain_type`ã€‚\n",
        "\n",
        "å°‡ `refine` è¨­å®šç‚º chain_type çš„ `load_qa_chain` éœ€è¦å…©å€‹æç¤ºï¼šå„ªåŒ–æç¤ºå’Œåˆå§‹å•é¡Œæç¤ºã€‚\n",
        "\n",
        "`å„ªåŒ–æç¤º` ç”¨æ–¼ç”¢ç”Ÿä¸€å€‹æç¤ºï¼Œè¦æ±‚ LLM æ ¹æ“šæä¾›çš„è„ˆçµ¡ä¾†å„ªåŒ–æ—¢æœ‰ç­”æ¡ˆã€‚åœ¨æ­¤ä¾‹ä¸­ï¼Œ`å„ªåŒ–æç¤º` æ˜¯ï¼š\n",
        "\n",
        "```\n",
        "åŸå§‹å•é¡Œç‚ºï¼š\\n {question} \\n\n",
        "æä¾›çš„ç­”æ¡ˆç‚ºï¼š\\n {existing_answer}\\n\n",
        "æ ¹æ“šä¸‹åˆ—è„ˆçµ¡ï¼Œå°æ—¢æœ‰ç­”æ¡ˆé€²è¡Œå„ªåŒ– (å¦‚æœéœ€è¦)ï¼š\\n {context_str} \\n\n",
        "æ ¹æ“šèƒå–çš„å…§å®¹å’Œå•é¡Œï¼Œç”¢ç”Ÿæœ€çµ‚ç­”æ¡ˆã€‚\n",
        "å¦‚æœç­”æ¡ˆæœªåŒ…å«åœ¨è„ˆçµ¡ä¸­ï¼Œè«‹å›ç­”ã€Œç­”æ¡ˆä¸åœ¨è„ˆçµ¡ä¸­ã€ã€‚ \\n\\n\n",
        "```\n",
        "\n",
        "`åˆå§‹å•é¡Œ` æç¤ºç”¨æ–¼ç”¢ç”Ÿä¸€å€‹æç¤ºï¼Œè¦æ±‚ LLM åƒ…æ ¹æ“šæä¾›çš„è„ˆçµ¡ä¾†å›ç­”å•é¡Œã€‚åœ¨æ­¤ä¾‹ä¸­ï¼Œ`åˆå§‹å•é¡Œæç¤º` æ˜¯ï¼š\n",
        "\n",
        "```\n",
        "æ ¹æ“šæä¾›çš„è„ˆçµ¡ç›¡å¯èƒ½ç²¾ç¢ºå›ç­”å•é¡Œã€‚\\n\\n\n",
        "è„ˆçµ¡ï¼š\\n {context_str} \\n\n",
        "å•é¡Œï¼š\\n {question} \\n\n",
        "ç­”æ¡ˆï¼š\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cG-9vfd3C99y"
      },
      "outputs": [],
      "source": [
        "refine_prompt_template = \"\"\"\n",
        "    The original question is: \\n {question} \\n\n",
        "    The provided answer is: \\n {existing_answer}\\n\n",
        "    Refine the existing answer if needed with the following context: \\n {context_str} \\n\n",
        "    Given the extracted content and the question, create a final answer.\n",
        "    If the answer is not contained in the context, say \"answer not available in context. \\n\\n\n",
        "\"\"\"\n",
        "refine_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"existing_answer\", \"context_str\"],\n",
        "    template=refine_prompt_template,\n",
        ")\n",
        "\n",
        "\n",
        "initial_question_prompt_template = \"\"\"\n",
        "    Answer the question as precise as possible using the provided context only. \\n\\n\n",
        "    Context: \\n {context_str} \\n\n",
        "    Question: \\n {question} \\n\n",
        "    Answer:\n",
        "\"\"\"\n",
        "\n",
        "initial_question_prompt = PromptTemplate(\n",
        "    input_variables=[\"context_str\", \"question\"],\n",
        "    template=initial_question_prompt_template,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4-NPHduDngj"
      },
      "source": [
        "å®šç¾©é æœŸçš„æç¤ºç¬¦å¾Œï¼Œåˆå§‹åŒ–ä¸€å€‹ `load_qa_chain` éˆã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97O6F_xAI-9-"
      },
      "outputs": [],
      "source": [
        "refine_chain = load_qa_chain(\n",
        "    vertex_llm_text,\n",
        "    chain_type=\"refine\",\n",
        "    return_intermediate_steps=True,\n",
        "    question_prompt=initial_question_prompt,\n",
        "    refine_prompt=refine_prompt,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddfy336FDs58"
      },
      "source": [
        "ä½ æ ¹æ“šè¼¸å…¥æ–‡ä»¶å›ç­”ä½ çš„å•é¡Œã€‚è«‹æ³¨æ„ä½ å¦‚ä½•å‚³éæ•´å€‹æ–‡ä»¶æ•¸æ“šåº«ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xK4afrbsKTlT"
      },
      "outputs": [],
      "source": [
        "refine_outputs = refine_chain({\"input_documents\": pages, \"question\": question})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvanB3fELHt"
      },
      "source": [
        "ä½ å¯ä»¥åœ¨ Pandas dataframe ä¸­å„²å­˜ç­”æ¡ˆï¼Œä»¥æª¢æŸ¥ã€ŒRefineã€ä¸­é–“æ­¥é©Ÿå’Œ LLM ç­”æ¡ˆã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhKyI5UAKzLY"
      },
      "outputs": [],
      "source": [
        "final_refine_data = []\n",
        "for doc, out in zip(\n",
        "    refine_outputs[\"input_documents\"], refine_outputs[\"intermediate_steps\"]\n",
        "):\n",
        "    output = {}\n",
        "    output[\"file_name\"] = p(doc.metadata[\"source\"]).stem\n",
        "    output[\"file_type\"] = p(doc.metadata[\"source\"]).suffix\n",
        "    output[\"page_number\"] = doc.metadata[\"page\"]\n",
        "    output[\"chunks\"] = doc.page_content\n",
        "    output[\"answer\"] = out\n",
        "    final_refine_data.append(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKBVwN7bKzLZ"
      },
      "outputs": [],
      "source": [
        "pdf_refine_answers = pd.DataFrame.from_dict(final_refine_data)\n",
        "pdf_refine_answers = pdf_refine_answers.sort_values(\n",
        "    by=[\"file_name\", \"page_number\"]\n",
        ")  # sorting the dataframe by filename and page_number\n",
        "pdf_refine_answers.reset_index(inplace=True, drop=True)\n",
        "pdf_refine_answers.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzBcke2DKzLZ"
      },
      "outputs": [],
      "source": [
        "index = 3\n",
        "print(\"[Context]\")\n",
        "print(pdf_refine_answers[\"chunks\"].iloc[index])\n",
        "print(\"\\n\\n [Answer]\")\n",
        "print(pdf_refine_answers[\"answer\"].iloc[index])\n",
        "print(\"\\n\\n [Page number]\")\n",
        "print(pdf_refine_answers[\"page_number\"].iloc[index])\n",
        "print(\"\\n\\n [Source: file_name]\")\n",
        "print(pdf_refine_answers[\"file_name\"].iloc[index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbDPwfu5LJV6"
      },
      "outputs": [],
      "source": [
        "index = 5\n",
        "print(\"[Context]\")\n",
        "print(pdf_refine_answers[\"chunks\"].iloc[index])\n",
        "print(\"\\n\\n [Answer]\")\n",
        "print(pdf_refine_answers[\"answer\"].iloc[index])\n",
        "print(\"\\n\\n [Page number]\")\n",
        "print(pdf_refine_answers[\"page_number\"].iloc[index])\n",
        "print(\"\\n\\n [Source: file_name]\")\n",
        "print(pdf_refine_answers[\"file_name\"].iloc[index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O30DdYUZEP6p"
      },
      "source": [
        "**è€ƒé‡** : åˆ°ç›®å‰ç‚ºæ­¢ï¼Œä½ ä½¿ç”¨æ–‡ä»¶çš„éƒ¨åˆ†æˆ–æ•´å€‹æ–‡ä»¶ä½œç‚ºèƒŒæ™¯ï¼Œä¾†å›ç­”ä½ çš„å…·é«”å•é¡Œã€‚é€™å…©ç¨®æƒ…æ³éƒ½æœ‰å¹¾å€‹é™åˆ¶ï¼ŒåŒ…æ‹¬èƒŒæ™¯ä¸å®Œæ•´ä¸”æŸ¥è©¢é€Ÿåº¦æ…¢ï¼Œå¤§å‹æ–‡ä»¶æƒ…æ³ç‰¹åˆ¥æ˜é¡¯ã€‚\n",
        "\n",
        "é€éå‘é‡è³‡æ–™åº«é€²è¡Œç›¸ä¼¼æ€§æœå°‹æ˜¯ä¸€ç¨®è¼ƒæ–°çš„æ–¹æ³•ï¼Œå¯ä»¥è§£æ±ºé€™äº›é™åˆ¶ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dw-aHBJN7DN"
      },
      "source": [
        "### èˆ‡ç›¸ä¼¼åº¦æœå°‹çš„å•ç­”\n",
        "\n",
        "åˆ©ç”¨å‘é‡è³‡æ–™åº«é€²è¡Œç›¸ä¼¼åº¦æœå°‹æ™‚ï¼Œæœƒå°‡æ¯å€‹å…§å®¹ç‰‡æ®µè¡¨ç¤ºç‚ºä¸€å€‹å‘é‡ã€‚é€™äº›å‘é‡æœƒå„²å­˜åœ¨è³‡æ–™åº«ä¸­ã€‚ç•¶ä½¿ç”¨è€…æå‡ºå•é¡Œæ™‚ï¼Œç³»çµ±é¦–å…ˆæœƒè¨ˆç®—å•é¡Œèˆ‡è³‡æ–™åº«ä¸­å„å‘é‡çš„ç›¸ä¼¼åº¦ã€‚ç›¸ä¼¼åº¦æœ€é«˜çš„é‚£å¹¾å€‹å‘é‡å°‡æœƒè¢«ç”¨æ–¼æ“·å–èˆ‡å•é¡Œç›¸é—œçš„å…§å®¹ã€‚\n",
        "\n",
        "é€™ç¨®æ–¹æ³•å…·å‚™æ•¸ç¨®å„ªé»ï¼ŒåŒ…æ‹¬å›æ‡‰æ›´ç¬¦åˆä½¿ç”¨è€…çš„å•é¡Œã€‚\n",
        "\n",
        "åœ¨é€™å€‹æ¡ˆä¾‹ä¸­ï¼Œä½ ä½¿ç”¨é–‹æºçš„å…§å»ºå¼åµŒå…¥è³‡æ–™åº«ã€ŒChromaã€ä¾†å»ºç«‹ç›¸ä¼¼åº¦æœå°‹ç´¢å¼•ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydX1I_P-ToEj"
      },
      "source": [
        "#### èƒŒæ™¯é¸æ“‡\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSNMYEZhKaZJ"
      },
      "source": [
        "ä½¿ç”¨ `Chroma` å»ºç«‹ç›¸ä¼¼åº¦æœå°‹ç´¢å¼•ã€‚\n",
        "\n",
        "`Chroma` èˆ‡åƒ `PyPDFLoader` çš„æ–‡ä»¶è¼‰å…¥å™¨æ­é…ä½¿ç”¨ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLAMaLkgNG5U"
      },
      "outputs": [],
      "source": [
        "vector_index = Chroma.from_documents(pages, vertex_embeddings).as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1c8Av35K_sl"
      },
      "source": [
        "æ¥è‘—ï¼Œä½¿ç”¨åŸå§‹å•é¡Œæ“·å–ç›¸é—œçš„å…§å®¹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgxD6ezEOAgL"
      },
      "outputs": [],
      "source": [
        "docs = vector_index.get_relevant_documents(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU4sV359LNTM"
      },
      "source": [
        "#### MapReduce æ–¹æ³•\n",
        "\n",
        "æœ€å¾Œæ ¹æ“šä½ å¾åµŒå…¥å¼è³‡æ–™åº«ä¸­æª¢ç´¢åˆ°çš„å…§å®¹ä»¥åŠè¼¸å…¥çš„å•é¡Œå›ç­”ä½ çš„å•é¡Œã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrO635SkPdkR"
      },
      "outputs": [],
      "source": [
        "map_reduce_embeddings_outputs = map_reduce_chain(\n",
        "    {\"input_documents\": docs, \"question\": question}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQozAWI3lkXp"
      },
      "outputs": [],
      "source": [
        "print(map_reduce_embeddings_outputs[\"output_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ä½ å¯ä»¥å°‡ç­”æ¡ˆå„²å­˜æ–¼ Pandas è³‡æ–™æ¡†ä¸­ï¼Œä»¥æª¢æŸ¥ `MapReduce with similarity search` çš„ä¸­é–“æ­¥é©ŸåŠ LLMs çš„ç­”æ¡ˆã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_mpe_data = []\n",
        "for doc, out in zip(\n",
        "    map_reduce_embeddings_outputs[\"input_documents\"],\n",
        "    map_reduce_embeddings_outputs[\"intermediate_steps\"],\n",
        "):\n",
        "    output = {}\n",
        "    output[\"file_name\"] = p(doc.metadata[\"source\"]).stem\n",
        "    output[\"file_type\"] = p(doc.metadata[\"source\"]).suffix\n",
        "    output[\"page_number\"] = doc.metadata[\"page\"]\n",
        "    output[\"chunks\"] = doc.page_content\n",
        "    output[\"answer\"] = out\n",
        "    final_mpe_data.append(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdf_mpe_answers = pd.DataFrame.from_dict(final_mpe_data)\n",
        "pdf_mpe_answers = pdf_mpe_answers.sort_values(\n",
        "    by=[\"file_name\", \"page_number\"]\n",
        ")  # sorting the dataframe by filename and page_number\n",
        "pdf_mpe_answers.reset_index(inplace=True, drop=True)\n",
        "pdf_mpe_answers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ä½ å¯ä»¥å°‡ç­”æ¡ˆå„²å­˜åœ¨ Pandas dataframe ä¸­ï¼Œä»¥æª¢æŸ¥ã€Œæ­é…ç›¸ä¼¼åº¦æœå°‹çš„ MapReduceã€ä¸­é–“æ­¥é©Ÿå’Œ LLM ç­”æ¡ˆã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_mpe_data = []\n",
        "for doc, out in zip(\n",
        "    map_reduce_embeddings_outputs[\"input_documents\"],\n",
        "    map_reduce_embeddings_outputs[\"intermediate_steps\"],\n",
        "):\n",
        "    output = {}\n",
        "    output[\"file_name\"] = p(doc.metadata[\"source\"]).stem\n",
        "    output[\"file_type\"] = p(doc.metadata[\"source\"]).suffix\n",
        "    output[\"page_number\"] = doc.metadata[\"page\"]\n",
        "    output[\"chunks\"] = doc.page_content\n",
        "    output[\"answer\"] = out\n",
        "    final_mpe_data.append(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdf_mpe_answers = pd.DataFrame.from_dict(final_mpe_data)\n",
        "pdf_mpe_answers = pdf_mpe_answers.sort_values(\n",
        "    by=[\"file_name\", \"page_number\"]\n",
        ")  # sorting the dataframe by filename and page_number\n",
        "pdf_mpe_answers.reset_index(inplace=True, drop=True)\n",
        "pdf_mpe_answers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## çµè«–\n",
        "\n",
        "é€™å€‹ç­†è¨˜æœ¬ç¤ºç¯„äº†å¦‚ä½•ä½¿ç”¨ LangChain èˆ‡ Vertex AI PaLM API å»ºç«‹ä¸€å€‹å•ç­” (QA) ç³»çµ±ï¼Œä»¥å¾å¤§å‹æ–‡ä»¶æå–è³‡è¨Šã€‚\n",
        "\n",
        "åœ¨æ­¤æ¡ˆä¾‹ä¸­ï¼Œä½ ä½¿ç”¨ Chroma (ä¸€å€‹è¨˜æ†¶é«”ä¸­é–‹æºåµŒå…¥å¼è³‡æ–™åº«) ä¾†å»ºç«‹ç›¸ä¼¼æ€§æœå°‹ç´¢å¼•ã€‚ä¸é [LangChain](https://python.langchain.com/docs/integrations/vectorstores/matchingengine) æ”¯æ´ Vertex AI Matching Engineï¼Œé€™æ˜¯ä¸€å€‹ Google Cloud çš„å¤§å‹ä½å»¶é²å‘é‡è³‡æ–™åº«ã€‚é€é Vertex AI Matching Engineï¼Œä½ æœ‰ä¸€å€‹å…¨å—æ§çš„æœå‹™ï¼Œå®ƒå¯ä»¥æ“´å……ï¼Œä»¥æ»¿è¶³æœ€åš´è‹›çš„æ‡‰ç”¨ç¨‹å¼éœ€æ±‚ã€‚å®ƒåœ¨è¨“ç·´å’Œæ¨è«–æ™‚æä¾›é«˜åŸ·è¡Œæ•ˆèƒ½ã€‚è€Œä¸”ï¼Œå®ƒæœ‰è¨±å¤šåŠŸèƒ½ï¼ŒåŒ…æ‹¬æ”¯æ´å¤šç¨®é¡ä¼¼æ€§æŒ‡æ¨™ã€æ‰¹æ¬¡æ¨è«–å’Œç·šä¸Šå­¸ç¿’ã€‚é€™äº›åŠŸèƒ½å°æ–¼éœ€è¦åŸ·è¡Œè¤‡é›œçš„åŒ¹é…ä½œæ¥­æˆ–éœ€è¦èƒ½å¤ é©æ‡‰è®Šæ›´è³‡æ–™çš„æ‡‰ç”¨ç¨‹å¼ä¾†èªªéå¸¸é‡è¦ã€‚\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "question_answering_large_documents_langchain.ipynb",
      "toc_visible": true
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-11.m111",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m111"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}