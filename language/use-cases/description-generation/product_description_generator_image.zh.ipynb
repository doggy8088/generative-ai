{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d9bbf86da5e"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bd716bf3e39"
      },
      "source": [
        "# 產品說明產生器來自影像\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/doggy8088/generative-ai/blob/main/language/use-cases/description-generation/product_description_generator_image.zh.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google 協作平台標誌\"><br>在協作平台運行\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/doggy8088/generative-ai/blob/main/language/use-cases/description-generation/product_description_generator_image.zh.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub 標誌\"><br>在 GitHub 上檢視\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/doggy8088/generative-ai/blob/main/language/use-cases/description-generation/product_description_generator_image.zh.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI 標誌\"><br>在 Vertex AI Workbench 中開啟\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|作者| [Lavi Nigam](https://github.com/lavinigam-gcp) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8cd12648da4"
      },
      "source": [
        "## 總覽\n",
        "\n",
        "此筆記本顯示如何根據圖片建立產品說明之使用案例。在此筆記本中，你會使用 [服裝圖片資料集](https://github.com/alexeygrigorev/clothing-dataset-small) 為服飾圖片建立產品說明。\n",
        "作為初始步驟，你會在 Vertex AI 中部署預先訓練好的 [BLIP 圖片字幕](https://huggingface.co/Salesforce/blip-image-captioning-base) 模型，以進行線上預測。然後你將使用模型加上圖片字幕。稍後，你會使用產品圖片的字幕，搭配 PaLM 模型產生行銷附件的說明。\n",
        "\n",
        "### 目標\n",
        "\n",
        "- 將模型上傳至 [模型登錄管理中心](https://cloud.google.com/vertex-ai/docs/model-registry/introduction)。\n",
        "- 在 [端點](https://cloud.google.com/vertex-ai/docs/predictions/using-private-endpoints) 上部署模型。\n",
        "- 執行圖片字幕的線上預測。\n",
        "- 搭配圖片字幕執行 PaLM 模型的線上預測，以產生產品說明。\n",
        "\n",
        "### 費用\n",
        "\n",
        "本教學課程使用 Google Cloud 的計費元件：\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "深入瞭解 [Vertex AI 定價](https://cloud.google.com/vertex-ai/pricing) 和 [Cloud Storage 定價](https://cloud.google.com/storage/pricing)，並使用 [定價計算器](https://cloud.google.com/products/calculator/) 根據預測使用量產生成本估算。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "988ce40b7407"
      },
      "source": [
        "## 開始使用\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4e98da3ac28"
      },
      "source": [
        "### 安裝 Vertex AI SDK\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf1e8556f27a"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-aiplatform --upgrade --quiet --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0248b091b6e"
      },
      "source": [
        "***Colab 獨有** *：取消以下Cell註解以重新啟動核心，或使用按鈕重新啟動核心。對於 Vertex AI Workbench，可以使用頂端的按鈕重新啟動終端機。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17a3adf1ce04"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d73ffa0c0b83"
      },
      "source": [
        "### 驗證筆記本環境\n",
        "* 如果你使用 **Colab** 執行此筆記本，取消註解下方的Cell並繼續。\n",
        "* 如果你使用 **Vertex AI 工作台** ，請查看[此處](https://github.com/doggy8088/generative-ai/tree/main/setup-env)的設定說明。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCxVCgQp4YgL"
      },
      "outputs": [],
      "source": [
        "# from google.colab import auth as google_auth\n",
        "# google_auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2a8dfbe5bfa"
      },
      "source": [
        "### 匯入函式庫\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13da1828cd44"
      },
      "source": [
        "**Colab 專用：** 取消下一個Cell註解，以初始化 Vertex AI SDK。對於 Vertex AI Workbench，你不需要執行這項作業。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32d3683b3260"
      },
      "outputs": [],
      "source": [
        "# import vertexai\n",
        "\n",
        "# PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "# vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fb2f1b3ce06"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import base64\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from datetime import datetime\n",
        "from google.cloud import storage\n",
        "from google.cloud import aiplatform\n",
        "from vertexai.language_models import TextGenerationModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac378ede6e22"
      },
      "source": [
        "### 載入模型\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dada301d0216"
      },
      "outputs": [],
      "source": [
        "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f826ff482a2"
      },
      "source": [
        "### 下列 GCS Bucket 包含一些時尚產品圖像資料集範例\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9db30f827a65"
      },
      "outputs": [],
      "source": [
        "GCS_BUCKET = \"github-repo\"\n",
        "!gsutil ls gs://$GCS_BUCKET/product_img/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ca48b699d17"
      },
      "source": [
        "### 定義常數\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de9882ea89ea"
      },
      "outputs": [],
      "source": [
        "# The pre-built serving docker image. It contains serving scripts and models.\n",
        "SERVE_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/pytorch-transformers-serve\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10188266a5cd"
      },
      "source": [
        "### 定義常見功能\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cac4478ae098"
      },
      "outputs": [],
      "source": [
        "def create_job_name(prefix):\n",
        "    user = os.environ.get(\"USER\")\n",
        "    now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    job_name = f\"{prefix}-{user}-{now}\"\n",
        "    return job_name\n",
        "\n",
        "\n",
        "def download_image(url):\n",
        "    response = requests.get(url)\n",
        "    return Image.open(BytesIO(response.content))\n",
        "\n",
        "\n",
        "def image_to_base64(image, format=\"JPEG\"):\n",
        "    buffer = BytesIO()\n",
        "    image.save(buffer, format=format)\n",
        "    image_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
        "    return image_str\n",
        "\n",
        "\n",
        "def base64_to_image(image_str):\n",
        "    image = Image.open(BytesIO(base64.b64decode(image_str)))\n",
        "    return image\n",
        "\n",
        "\n",
        "def image_grid(imgs, rows=2, cols=2):\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
        "    return grid\n",
        "\n",
        "\n",
        "def deploy_model(model_id, task):\n",
        "    model_name = \"blip-image-captioning\"\n",
        "    endpoint = aiplatform.Endpoint.create(display_name=f\"{model_name}-endpoint\")\n",
        "    serving_env = {\n",
        "        \"MODEL_ID\": model_id,\n",
        "        \"TASK\": task,\n",
        "    }\n",
        "    # If the model_id is a GCS path, use artifact_uri to pass it to serving docker.\n",
        "    artifact_uri = model_id if model_id.startswith(\"gs://\") else None\n",
        "    model = aiplatform.Model.upload(\n",
        "        display_name=model_name,\n",
        "        serving_container_image_uri=SERVE_DOCKER_URI,\n",
        "        serving_container_ports=[7080],\n",
        "        serving_container_predict_route=\"/predictions/transformers_serving\",\n",
        "        serving_container_health_route=\"/ping\",\n",
        "        serving_container_environment_variables=serving_env,\n",
        "        artifact_uri=artifact_uri,\n",
        "    )\n",
        "    model.deploy(\n",
        "        endpoint=endpoint,\n",
        "        machine_type=\"n1-standard-8\",\n",
        "        accelerator_type=\"NVIDIA_TESLA_T4\",\n",
        "        accelerator_count=1,\n",
        "        deploy_request_timeout=1800,\n",
        "    )\n",
        "    return model, endpoint\n",
        "\n",
        "\n",
        "def read_jpeg_image_from_gcs(bucket_name, image_name):\n",
        "    \"\"\"Reads a JPEG image from a Google Cloud Storage (GCS) bucket.\n",
        "\n",
        "    Args:\n",
        "    bucket_name: The name of the GCS bucket that contains the image file.\n",
        "    image_name: The name of the image file in the GCS bucket.\n",
        "\n",
        "    Returns:\n",
        "    The image file as a PIL Image object.\n",
        "    \"\"\"\n",
        "\n",
        "    # Import the Google Cloud Storage client library.\n",
        "\n",
        "    # Create a storage client.\n",
        "    client = storage.Client()\n",
        "\n",
        "    # Get the bucket object.\n",
        "    bucket = client.bucket(bucket_name)\n",
        "\n",
        "    # Get the blob object.\n",
        "    blob = bucket.blob(image_name)\n",
        "\n",
        "    # Read the blob to a bytestring.\n",
        "    image_data = blob.download_as_bytes()\n",
        "\n",
        "    # Decode the bytestring to a PIL Image object.\n",
        "    image = Image.open(io.BytesIO(image_data))\n",
        "\n",
        "    # Return the PIL Image object.\n",
        "    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2d72ecdb8c9"
      },
      "source": [
        "## 上傳並部署模型\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9448c5f545fa"
      },
      "source": [
        "此部分會將預訓練模型上傳到 Model Registry，並於端點中以 1 T4 GPU 部署。\n",
        "\n",
        "模型部署步驟將花費大約 15 分鐘。\n",
        "\n",
        "部署後，你可以傳送圖片以取得說明。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**備註：** **只執行這個Cell一次。** 由於這是私有端點，因此，最多只能將一個模型配署至每個私有端點。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4b46c28d8b1"
      },
      "outputs": [],
      "source": [
        "model, endpoint = deploy_model(\n",
        "    model_id=\"Salesforce/blip-image-captioning-base\", task=\"image-to-text\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c4be5a41cd7"
      },
      "source": [
        "現在你將撰寫一個函式，它會將 BLIP 模型產生的圖片標題傳送給我們的 PaLM 2 文字產生模型。透過你的提示，你希望它回傳可在行銷材料中使用的朗朗上口產品說明。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iam8Fc5tt-Q"
      },
      "outputs": [],
      "source": [
        "def generate_product_description(model, image_caption, temperature=0):\n",
        "    \"\"\"Ideation example with a Large Language Model\"\"\"\n",
        "    prompt_prefix = \"Imagine you are a digital marketer working for a retail organization. \\\n",
        "                    You are an expert in building detailed and catchy descriptions fro the retail fashion products on your website.\\\n",
        "                    Generate a product description using the following short caption that describes the apparel\"\n",
        "    prompt = prompt_prefix + image_caption\n",
        "    response = model.predict(\n",
        "        prompt,\n",
        "        temperature=temperature,\n",
        "        max_output_tokens=256,\n",
        "        top_k=40,\n",
        "        top_p=0.8,\n",
        "    )\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6066d4f2ef3"
      },
      "source": [
        "一旦定義模型，請測試圖片及其標題，以了解如何產生說明。你可以撰寫一個簡單的 for 迴圈，遍歷原始資料夾中的每張照片，並透過傳遞標題來呼叫我們的模型。你可以閱讀每張圖片的說明。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6be655247cb1"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "for i in range(1, 9):\n",
        "    image_data = read_jpeg_image_from_gcs(\n",
        "        GCS_BUCKET, \"product_img/fashion\" + str(i) + \".jpeg\"\n",
        "    )\n",
        "    # Display the image\n",
        "    plt.imshow(image_data)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    instances = [\n",
        "        {\"image\": image_to_base64(image_data)},\n",
        "    ]\n",
        "    preds = endpoint.predict(instances=instances).predictions\n",
        "    print(preds)\n",
        "    product_description = generate_product_description(\n",
        "        model=generation_model, image_caption=preds[0]\n",
        "    )\n",
        "    print(product_description)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "product_description_generator.ipynb",
      "toc_visible": true
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-11.m108",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}