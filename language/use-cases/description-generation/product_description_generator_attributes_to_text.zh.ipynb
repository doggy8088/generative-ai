{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUZfht_yNsbz"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm9QleQMtnKh",
        "tags": []
      },
      "source": [
        "# 說明：使用 LangChain 🦜🔗 進行零售業的 SEO 優化產品說明產生\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/doggy8088/generative-ai/blob/main/language/use-cases/description-generation/product_description_generator_attributes_to_text.zh.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory 標誌\"><br>在 Colab 中執行\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/doggy8088/generative-ai/blob/main/language/use-cases/description-generation/product_description_generator_attributes_to_text.zh.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub 標誌\"><br>在 GitHub 上查看\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/doggy8088/generative-ai/blob/main/language/use-cases/description-generation/product_description_generator_attributes_to_text.zh.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI 標誌\"><br>在 Vertex AI Workbench 中開啟\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|作者(們) | [Anant Nawalgaria](https://github.com/anantnawal) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrJ2HPRW1cpA"
      },
      "source": [
        "## 簡介\n",
        "\n",
        "本筆記本示範如何使用 [LangChain](https://python.langchain.com/docs/get_started/introduction.html) 與 Vertex AI LLM 一同解決許多大型零售商面臨的問題：根據產品屬性或規格 (通常由供應商提供)，自動產生資訊豐富、符合 SEO 且具有創意潛能的產品說明和標題。此自動產生說明流程能顯著節省成本與時間。\n",
        "\n",
        "本教學課程示範如何從原始產品屬性和元資料開始，使用 LLM 產生完整、準確、符合 SEO 且安全的說明。你還將學習如何使用 LLM 驗證說明。此外，你將學習如何使用檢索擴充式產生功能，藉由 k-NN (k 近鄰) 嵌入式搜尋進一步改善提示內容。最後，示範如何根據品牌的寫作風格調整說明，即使各產品的風格不盡相同。\n",
        "\n",
        "執行本教學課程的注意事項：\n",
        "\n",
        "可在此處下載用於此示範的免費公開資料集範例 (授權個人或商業使用)：[請按一下此處](https://data.world/promptcloud/product-details-on-flipkart-com)。\n",
        "\n",
        "### 目標\n",
        "\n",
        "在本教學課程中，你將學習如何使用 LangChain 與 PaLM API 從現有產品屬性產生產品說明。你將演練以下範例：\n",
        "\n",
        "* 基礎模型的零次提示以產生說明\n",
        "* 在自訂語料庫上針對參數效益已調整最佳化之基礎模型的零次提示\n",
        "* 利用 Vertex AI 嵌入式找出類似的範例以納入提示中，進行少次提示未調整最佳化 (以及已調整最佳化) 處理。本教學課程在本地端記憶體中完成此作業，但日後可擴大使用 [Vertex AI Matching Engine](https://cloud.google.com/vertex-ai/docs/matching-engine/overview)(一種受控的擴充式向量資料庫) \n",
        "* 使用提示設計的 LLM 零次提示來檢查所產生產品說明的安全性、真實性和品質，並針對其評估結果提出理由說明\n",
        "* 使用 n-gram 重疊指標 (例如 BLEU 和 ROUGE) 評估大量提示的品質，以及使用 PaLM API 與可能的範例和負面範例進行語意相似度檢查 (使用嵌入式) \n",
        "* 使用基本和進階 LangChain 結構，例如提示範本、LLM 鏈、順序 LLM 鏈 (用於多個輸入和輸出順序提示，其中一項輸出的結果作為輸入提供給另一項輸出)、k-NN 檢索器以及自訂 LLM 類別以使用 Vertex AI 和 LangChain。\n",
        "\n",
        "你還將看到使用基於 k-NN 的 Vertex AI LLM 嵌入式語意相似度計算的少次提示，可以在 BLEU/ROUGE 和語意相似度中提升效能指標。此外，你可以利用 Vertex Generative AI 圖片標題描述服務加入額外的產品屬性，進而豐富產品說明內容。\n",
        "\n",
        "### 成本\n",
        "\n",
        "本教學課程使用 Google Cloud 的可開立帳單元件：\n",
        "- Vertex AI Generative AI Studio\n",
        "\n",
        "瞭解 [Vertex AI 價格](https://cloud.google.com/vertex-ai/pricing)，並使用 [價格計算器](https://cloud.google.com/products/calculator/) 依照預期使用量來產生成本估計。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdA2YcuDBxZA"
      },
      "source": [
        "## 開始使用\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdPW7vEf0BRg"
      },
      "source": [
        "### 安裝 Vertex AI SDK 和其他依賴項\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dea30abfe6e"
      },
      "outputs": [],
      "source": [
        "!pip3 install --user --upgrade  pydantic==1.10.9 \\\n",
        "                                keras-nlp==0.5.2 \\\n",
        "                                tensorflow==2.12.0 \\\n",
        "                                scikit-learn==1.2.2 \\\n",
        "                                lark==1.1.5 \\\n",
        "                                langchain==0.0.323 \\\n",
        "                                google-cloud-aiplatform==1.35.0 \\\n",
        "                                rouge-score==0.1.2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvbNy16vvxLZ"
      },
      "source": [
        "重新啟動核心以重新載入你剛安裝的套件。你可能會看到一則快顯式警告，你可以選擇關閉它。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8TaouAbvkAg"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "165a1dc0e619"
      },
      "source": [
        "### 驗證你的筆記本環境\n",
        "* 如果你使用 **Colab** 來執行這個筆記本，取消註解下面的Cell，然後繼續。\n",
        "* 如果你使用 **Vertex AI Workbench** ，請查看設定說明 [在此](https://github.com/doggy8088/generative-ai/tree/main/setup-env)。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXUiRL2lvqE3"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "REGION = \"us-central1\"\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agy6vPA3vrKl"
      },
      "source": [
        "### 匯入函式庫\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55VVrU1rMIGD"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pprint\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import keras_nlp\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain.embeddings.base import Embeddings\n",
        "from langchain.llms.base import LLM\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.retrievers import KNNRetriever\n",
        "from sklearn.model_selection import train_test_split\n",
        "from vertexai.language_models import TextEmbeddingModel, TextGenerationModel\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDqy9zKb-fxm"
      },
      "source": [
        "### 供程式碼其他部分使用的輔助函式/類別\n",
        "這些函式和類別會示範如何使用基本的 langchain 建構，在需要時建立你自訂的 LLM 模型與嵌入 (例如來自 tfhub) 。LangChain 同時本機支援頂點 LLM (用於產生和嵌入)。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXc97lrn-YgM"
      },
      "outputs": [],
      "source": [
        "REQUESTS_PER_MINUTE = 16\n",
        "pp = pprint.PrettyPrinter(width=200)\n",
        "\n",
        "\n",
        "# for creating dynamic fewshot based on embedding based kNN approach\n",
        "def compute_fewshot(\n",
        "    query,\n",
        "    retriever,\n",
        "    ixed_df,\n",
        "    delimiter=\"\\n\",\n",
        "    input_label=\"input:\",\n",
        "    output_label=\"output:\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Takes in a query, a langchain retriever object and\n",
        "    a dataframe indexed on the product attributes, computes K nearest\n",
        "    neighbours based on embedding semantic similarity of product descriptions.\n",
        "    Then returns output as new-line delimited string of format key:value for\n",
        "    product attributes: product description of semantically similar products\n",
        "    to the original query.\n",
        "\n",
        "    E.g. Query = Color:White\n",
        "         Brand = Adidas\n",
        "\n",
        "       Output of function:\n",
        "       Input: Color:White \\n Brand= Nike\n",
        "       Output: These Nike sport shoes help you with your everyday run!\n",
        "\n",
        "       Input: Color:Grey \\n Brand= Adidas,\n",
        "       Output: Helps you protect your heels while running!\n",
        "    \"\"\"\n",
        "    results = list()\n",
        "    for spec in retriever.get_relevant_documents(query)[:3]:\n",
        "        results.append(\"{}{}{}\".format(input_label, delimiter, spec.page_content))\n",
        "        results.append(\n",
        "            \"%s%s%s\"\n",
        "            % (output_label, delimiter, ixed_df.loc[spec.page_content][\"description\"])\n",
        "        )\n",
        "    return \"\\n\".join(results)\n",
        "\n",
        "\n",
        "# to & extract parse the various fields in a clean and uniform key:value format\n",
        "def extract_tags(x, delimiter=\":\"):\n",
        "    \"\"\"\n",
        "    Takes in a row of a dataframe, & extracts/ parses the various fields to\n",
        "    create a newline delimited array of key:value pairs where key is the\n",
        "    name of the product attribute: and value is the value of the attribute itself\n",
        "\n",
        "    E.g. output\n",
        "       Color: White\n",
        "       Discounted_price: 200\n",
        "    \"\"\"\n",
        "    results = list()\n",
        "    name = x[\"product_name\"]\n",
        "    brand = x[\"brand\"]\n",
        "    price = x[\"discounted_price\"]\n",
        "    category = x[\"product_category_tree\"]\n",
        "    for sym in [\"[\", \"]\", '\"']:\n",
        "        category = category.replace(sym, \"\")\n",
        "\n",
        "    results.append(\"{}{}{}\".format(\"Product name\", delimiter, name))\n",
        "    results.append(\"{}{}{}\".format(\"brand\", delimiter, brand))\n",
        "    results.append(\"{}{}{}\".format(\"discounted price\", delimiter, price))\n",
        "    results.append(\"{}{}{}\".format(\"Product category\", delimiter, category))\n",
        "    x = x[\"product_specifications\"]\n",
        "\n",
        "    if \"nil\" in x:\n",
        "        return \"\"\n",
        "    x = json.loads(x.replace(\"=>\", \":\"))[\"product_specification\"]\n",
        "\n",
        "    if type(x) is not list:\n",
        "        results.append(\n",
        "            \"{}{}{}\".format(x.get(\"key\", \"other detail\"), delimiter, x.get(\"value\", \"\"))\n",
        "        )\n",
        "    else:\n",
        "        for attr in x:\n",
        "            results.append(\n",
        "                \"%s%s%s\"\n",
        "                % (attr.get(\"key\", \"other detail\"), delimiter, attr.get(\"value\", \"\"))\n",
        "            )\n",
        "\n",
        "    return \"\\n\".join(results)\n",
        "\n",
        "\n",
        "# to compute the quality metrics of the generated text w.r.t reference text using Bleu, Rouge\n",
        "# and semantic similarity scores\n",
        "def compute_quality_metrics_batch(\n",
        "    references, predictions, rouge_n_order=2, embedding=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Takes a batch of generated text and corresponding reference texts,\n",
        "    computes and prints their corresponding\n",
        "    Bleu, Rouge and semantic similarity(using embeddings) scores.\n",
        "    \"\"\"\n",
        "    rouge_n = keras_nlp.metrics.RougeN(order=rouge_n_order)\n",
        "    bleu_n = keras_nlp.metrics.Bleu()\n",
        "    rouge_scr = rouge_n(references, predictions)[\"f1_score\"]\n",
        "    bleu_scr = bleu_n(references, predictions)\n",
        "    pp.pprint(\"Bleu:%s\" % (bleu_scr.numpy()))\n",
        "    pp.pprint(\"Rouge:%s\" % (rouge_scr.numpy()))\n",
        "    if embedding:\n",
        "        embed_predictions = embedding.embed_documents(predictions)\n",
        "        embed_references = embedding.embed_documents(references)\n",
        "        m = tf.keras.metrics.CosineSimilarity(axis=1)\n",
        "        m.update_state(embed_predictions, embed_references)\n",
        "        pp.pprint(\"Semantic Similarity:%s\" % (m.result().numpy()))\n",
        "\n",
        "\n",
        "class VertexLLM(LLM):\n",
        "    \"\"\"\n",
        "    Class to use Vertex AI LLMs to generate text throttled by specified\n",
        "    rate to avoid quota errors.\n",
        "    \"\"\"\n",
        "\n",
        "    model: TextGenerationModel\n",
        "    predict_kwargs: dict\n",
        "\n",
        "    def __init__(self, model, verbose, **predict_kwargs):\n",
        "        super().__init__(model=model, verbose=verbose, predict_kwargs=predict_kwargs)\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self):\n",
        "        return \"vertex\"\n",
        "\n",
        "    def _call(self, prompt, stop=None):\n",
        "        result = self.model.predict(prompt, **self.predict_kwargs)\n",
        "        return str(result)\n",
        "\n",
        "    @property\n",
        "    def _identifying_params(self):\n",
        "        return {}\n",
        "\n",
        "\n",
        "def rate_limit(max_per_minute):\n",
        "    period = 60 / max_per_minute\n",
        "    while True:\n",
        "        before = time.time()\n",
        "        yield\n",
        "        after = time.time()\n",
        "        elapsed = after - before\n",
        "        sleep_time = max(0, period - elapsed)\n",
        "        if sleep_time > 0:\n",
        "            # print(f'Sleeping {sleep_time:.1f} seconds')\n",
        "            time.sleep(sleep_time)\n",
        "\n",
        "\n",
        "class VertexEmbeddings(Embeddings):\n",
        "    \"\"\"\n",
        "    Class to use Vertex AI LLMs to generate embeddings by specified\n",
        "    rate to avoid quota errors.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, *, requests_per_minute=20):\n",
        "        self.model = model\n",
        "        self.requests_per_minute = requests_per_minute\n",
        "\n",
        "    def embed_documents(self, texts):\n",
        "        limiter = rate_limit(self.requests_per_minute)\n",
        "        results = []\n",
        "        docs = list(texts)\n",
        "\n",
        "        while docs:\n",
        "            # Working in batches of 5 to stay below the quota limit\n",
        "            head, docs = docs[:5], docs[5:]\n",
        "            chunk = self.model.get_embeddings(head)\n",
        "            results.extend(chunk)\n",
        "            next(limiter)\n",
        "\n",
        "        return [r.values for r in results]\n",
        "\n",
        "    def embed_query(self, text):\n",
        "        single_result = self.embed_documents([text])\n",
        "        return single_result[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sJCUeALAFh6"
      },
      "source": [
        "## 數據準備\n",
        "在本部分中，你將對完整資料集進行清洗、剖析、準備和切分。作為清洗流程的一部分，你還將確保篩選出包含空值或重複說明的欄位。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQNfBDFe_mKM"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\n",
        "    \"gs://github-repo/use-cases/product_description_generation_retail/dataset_sample.csv\"\n",
        ")\n",
        "df = (\n",
        "    df[~(df[\"product_specifications\"].str.contains(\"nil\", na=False))]\n",
        "    .dropna()\n",
        "    .drop_duplicates(subset=[\"description\"])\n",
        ")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dmi2y4-IAmKT"
      },
      "outputs": [],
      "source": [
        "df[\"parsed_product_specs\"] = df.apply(lambda x: extract_tags(x), axis=1)\n",
        "df_processed = df[[\"parsed_product_specs\", \"description\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgxoBGMcAmTo"
      },
      "outputs": [],
      "source": [
        "# train/test split\n",
        "train, test = train_test_split(df_processed, test_size=0.05, random_state=42)\n",
        "print(len(train), len(test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTrFHTqrAD-K"
      },
      "source": [
        "## 使用 LLM 進行說明產生\n",
        "此部分展示了你可以如何使用零次、少量次以及參數有效微調的方式持續改善 BLEU、Rouge 和語意相似性指標。它也展示了如何使用 LLM 標記文字的毒性，並使用 BLEU、Rouge 和語意相似性得分評估其結果。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f406fd09480"
      },
      "source": [
        "### 載入模型\n",
        "\n",
        "你載入的名為 `text-bison@001` 的預訓練文字生成模型。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Si4OL7qjvufA"
      },
      "outputs": [],
      "source": [
        "# You need to provide a GCP project here\n",
        "embedding = VertexEmbeddings(\n",
        "    TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\"),\n",
        "    requests_per_minute=REQUESTS_PER_MINUTE,\n",
        ")\n",
        "\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "llm = VertexLLM(\n",
        "    model, max_output_tokens=512, temperature=0.1, top_p=0.8, top_k=40, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0Gxr8rdNkBO"
      },
      "source": [
        "從 LangChain 中定義可再使用的提示範本，並建立一個按順序鏈接的鏈，首先使用第一個提示產生描述，然後使用第二個提示對其安全進行評估。輸入變數會在執行時填寫。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvXKoqpy4gKy"
      },
      "outputs": [],
      "source": [
        "template_descgen = \"\"\"\n",
        "Imagine you are a copywriter for the online ecommerce platform {platform_name}. You have been given a series of information about a product and are asked to write a short and truthful product description based on that information, that can be put on the website.\n",
        "At the same time the description should be optimised for search engines, and look like a realistic description in freeform text for that product which could appear on the {platform_name}.com website. The information you have been given are the following:\n",
        "{product_attributes}\n",
        "\"\"\"\n",
        "template_evaluate = \"\"\"\n",
        "Does this text look like a real human written description for a product which could be found on\n",
        "{platform_name} and is also not toxic? Answer with one of the following options, along with a short explanation\n",
        "Options:\n",
        "- Yes\n",
        "- No\n",
        "\n",
        "text: {generated_description}\n",
        "Option:\n",
        "\"\"\"\n",
        "\n",
        "prompt_descgen = PromptTemplate(\n",
        "    input_variables=[\"platform_name\", \"product_attributes\"],\n",
        "    template=template_descgen,\n",
        ")\n",
        "prompt_eval = PromptTemplate(\n",
        "    input_variables=[\"platform_name\", \"generated_description\"],\n",
        "    template=template_evaluate,\n",
        ")\n",
        "eval_chain = LLMChain(llm=llm, prompt=prompt_eval, output_key=\"is_safe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgSmOWlWilji"
      },
      "source": [
        "### 方法 1：零次描述生成、驗證和評估\n",
        "\n",
        "要建立產品說明，你首先需要建立一個提示，其中包含產品屬性的預留位置變數。這些變數會在執行時填入實際的產品屬性。接下來，你需要將相對應的大語言模型 (LLM) 附加到說明生成和評估模型。最後，你需要將模型鏈結在一起，好讓第一個模型生成的產品說明作為輸入傳送給第二個模型。然後，執行「順序鏈結」時便會提供兩個模型的輸出。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5AMPaHps7aw"
      },
      "outputs": [],
      "source": [
        "descgen_chain = LLMChain(\n",
        "    llm=llm, prompt=prompt_descgen, output_key=\"generated_description\"\n",
        ")\n",
        "\n",
        "overall_chain = SequentialChain(\n",
        "    chains=[descgen_chain, eval_chain],\n",
        "    input_variables=[\"platform_name\", \"product_attributes\"],\n",
        "    # Here you return multiple variables\n",
        "    output_variables=[\"generated_description\", \"is_safe\"],\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYF6VPej8L98"
      },
      "outputs": [],
      "source": [
        "attrs = test[\"parsed_product_specs\"].iloc[4]\n",
        "orig_descr = test[\"description\"].iloc[4]\n",
        "pp.pprint(\"The original description:\\n\" + orig_descr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2UpEwRJ8S4s"
      },
      "outputs": [],
      "source": [
        "result_0shot_untuned = overall_chain(\n",
        "    {\"platform_name\": \"Flipkart\", \"product_attributes\": attrs}\n",
        ")\n",
        "pp.pprint(result_0shot_untuned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpKqe219mdqL"
      },
      "source": [
        "你會發現生成的描述看起來經過 SEO 優化，且令人信服，加入了許多產品屬性。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00857f4a8f49"
      },
      "source": [
        "現在你可以評估上面所產生的描述結果和原本的描述：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "031aee588484"
      },
      "outputs": [],
      "source": [
        "compute_quality_metrics_batch(\n",
        "    [result_0shot_untuned[\"generated_description\"]], [orig_descr], embedding=embedding\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-lpxRIWFV35"
      },
      "source": [
        "現在你可以對 10 個產品規格的隨機抽樣批次執行相同的評估，並評估他們的 LLM 生成的說明，並根據他們的原始說明進行評估。輸出將是 10 對評估指標的平均值。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77676f6e9086"
      },
      "outputs": [],
      "source": [
        "sample_test = test[[\"parsed_product_specs\", \"description\"]].sample(10, random_state=42)\n",
        "sample_test[\"generated_description_0shot\"] = sample_test[\"parsed_product_specs\"].apply(\n",
        "    lambda x: overall_chain({\"platform_name\": \"Flipkart\", \"product_attributes\": x})[\n",
        "        \"generated_description\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "sample_attrs = sample_test[\"parsed_product_specs\"].values.tolist()\n",
        "sample_descriptions = sample_test[\"description\"].values.tolist()\n",
        "sample_generated_descriptions_0shot = sample_test[\n",
        "    \"generated_description_0shot\"\n",
        "].values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcBNP1DSFV35"
      },
      "source": [
        "現在檢視評估指標的平均輸出：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a93f469e7f1"
      },
      "outputs": [],
      "source": [
        "compute_quality_metrics_batch(\n",
        "    sample_generated_descriptions_0shot, sample_descriptions, embedding=embedding\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JsYHvEJHADm"
      },
      "source": [
        "現在你可以快速瀏覽原始和生成的描述，然後將資料框儲存為 .CSV 格式的磁碟\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6EDUrC6YyuZ"
      },
      "outputs": [],
      "source": [
        "sample_test[[\"description\", \"generated_description_0shot\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJbwkmIjYli9"
      },
      "outputs": [],
      "source": [
        "sample_test.to_csv(\"./augmented_dataset.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXHR8mWhHehI"
      },
      "source": [
        "### 方法 2：使用動態 k 近鄰，生成小樣本描述\n",
        "在這一部分，你將使用小樣本提示，嘗試改善 LLM 生成的描述，用以比較你先前使用的零樣本提示技巧。\n",
        "\n",
        "在此，非硬編碼或隨機選擇小樣本範例，而是先嵌入查詢和文件語料庫的範例，然後計算查詢嵌入的 k 個最近鄰居。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOSWKpzGHcuT"
      },
      "outputs": [],
      "source": [
        "template_descgen_fewshot = \"\"\"\n",
        "Imagine you are a copywriter for the online ecommerce platform {platform_name}. You have been given a series of information about a product as input and are asked to write a short and truthful product description based on that information as output, that can be put on the website.\n",
        "At the same time the description should also be optimised for search engines and look like a realistic description for that product which could appear on the {platform_name}.com website.\n",
        "{examples}\n",
        "input:\n",
        "{product_attributes}\n",
        "output:\n",
        "\"\"\"\n",
        "\n",
        "prompt_descgen_fewshot = PromptTemplate(\n",
        "    input_variables=[\"platform_name\", \"product_attributes\", \"examples\"],\n",
        "    template=template_descgen_fewshot,\n",
        ")\n",
        "\n",
        "descgen_chain_fewshot_untuned = LLMChain(\n",
        "    llm=llm, prompt=prompt_descgen_fewshot, output_key=\"generated_description\"\n",
        ")\n",
        "\n",
        "overall_chain_fewshot_untuned = SequentialChain(\n",
        "    chains=[descgen_chain_fewshot_untuned, eval_chain],\n",
        "    input_variables=[\"platform_name\", \"product_attributes\", \"examples\"],\n",
        "    # Here we return multiple variables\n",
        "    output_variables=[\"generated_description\", \"is_safe\"],\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58ojQA3MPVLN"
      },
      "source": [
        "若要建立輸入/輸出範例來引導模型，你可在訓練組中根據輸入產品規格使用 Vertex LLM 植入式 k 近鄰運算。接著根據訓練組中的產品規格/屬性進行最近鄰運算，並擷取相符描述，以透過少數輸入/輸出範例來引導模型。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkqPD9UQHc2u"
      },
      "outputs": [],
      "source": [
        "train_spec_ix = train.copy().set_index(\"parsed_product_specs\")\n",
        "retriever = KNNRetriever.from_texts(\n",
        "    train[\"parsed_product_specs\"].values.tolist()[:500], embedding\n",
        ")\n",
        "examples = compute_fewshot(attrs, retriever, train_spec_ix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy-byE3SHc__"
      },
      "outputs": [],
      "source": [
        "result_fewshot_untuned = overall_chain_fewshot_untuned(\n",
        "    {\"platform_name\": \"Flipkart\", \"product_attributes\": attrs, \"examples\": examples}\n",
        ")\n",
        "pp.pprint(result_fewshot_untuned[\"generated_description\"])\n",
        "pp.pprint(result_fewshot_untuned[\"is_safe\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zn3v1_JaHdI9"
      },
      "outputs": [],
      "source": [
        "sample_test[\"generated_description_fewshot\"] = sample_test[\n",
        "    \"parsed_product_specs\"\n",
        "].apply(\n",
        "    lambda x: overall_chain_fewshot_untuned(\n",
        "        {\n",
        "            \"platform_name\": \"Flipkart\",\n",
        "            \"product_attributes\": x,\n",
        "            \"examples\": compute_fewshot(x, retriever, train_spec_ix),\n",
        "        }\n",
        "    )[\"generated_description\"]\n",
        ")\n",
        "sample_generated_descriptions_fewshot = sample_test[\n",
        "    \"generated_description_fewshot\"\n",
        "].values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR2cxH9hFV3-"
      },
      "source": [
        "你現在應該看到所有指標 (Bleu、Rouge 和語義相似性) 應全部都有所提升，且在某些情況下大幅改善：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1lzZACsHdS9"
      },
      "outputs": [],
      "source": [
        "compute_quality_metrics_batch(\n",
        "    sample_generated_descriptions_fewshot, sample_descriptions, embedding=embedding\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwqWdEZdZC3b"
      },
      "source": [
        "現在你可以快速瀏覽原始和生成的描述，然後將資料框儲存為 .CSV 格式的磁碟\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPAwQsHOaMtI"
      },
      "outputs": [],
      "source": [
        "sample_test[\n",
        "    [\"parsed_product_specs\", \"description\", \"generated_description_fewshot\"]\n",
        "].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1M7zRR1aSh4"
      },
      "outputs": [],
      "source": [
        "sample_test.to_csv(\"./augmented_dataset.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct4xYbLW4Jvw"
      },
      "source": [
        "### 方法 3：微調零次描述產生驗證和評估\n",
        "\n",
        "在此部分，你會在 500 對訓練資料集中隨機取樣的 (提示、描述) 中執行模型的參數有效微調，以調整模型至描述和書寫風格。然後你將為一批資料產生描述，並根據前面各部分所示範的三項指標，評估相對於原始資料的結果。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY1gie8ZFV3-"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ 此區塊需要 TPU：請注意微調會使用 TPU，因此你需要確保專案中可供使用。</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddd51ced-40ed-40fc-9b34-beaf314aa88d"
      },
      "outputs": [],
      "source": [
        "tuned_model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "\n",
        "train_tuning = train.copy()\n",
        "\n",
        "train_tuning[\"prompt_product_specs\"] = train_tuning[\"parsed_product_specs\"].apply(\n",
        "    lambda x: prompt_descgen.format(platform_name=\"Flipkart\", product_attributes=x)\n",
        ")\n",
        "\n",
        "train_tuning.rename(\n",
        "    columns={\"prompt_product_specs\": \"input_text\", \"description\": \"output_text\"},\n",
        "    inplace=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bMWIVc8wpqr"
      },
      "source": [
        "請注意，以下程式碼將啟動調整管道，可能需花一、兩小時才能完成：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swIEdRtn4neB",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tuned_model.tune_model(\n",
        "    training_data=train_tuning.sample(10, random_state=42),\n",
        "    train_steps=1,\n",
        "    tuning_job_location=\"europe-west4\",\n",
        "    tuned_model_location=\"us-central1\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omVSG-X4BP6E"
      },
      "source": [
        "**在這裡** 你載入最新訓練的模型，並在與先前相同的測試句子上評估它。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rw38HJHC5hJ"
      },
      "outputs": [],
      "source": [
        "model_id = tuned_model.list_tuned_model_names()[0]\n",
        "tuned_model = TextGenerationModel.get_tuned_model(tuned_model_name=model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYB8si7PFV3_"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "print(datetime.datetime.now())  # started at 11:20am BST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbATrTBkiMbI"
      },
      "outputs": [],
      "source": [
        "llm_tuned = VertexLLM(\n",
        "    tuned_model,\n",
        "    max_output_tokens=512,\n",
        "    temperature=0.1,\n",
        "    top_p=0.8,\n",
        "    top_k=40,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oyxQQLZhLFj"
      },
      "source": [
        "使用與之前相同的提示範本建立新的 LLM 鏈，只需隨附新調整的模型即可。然後像對零發射模型一樣將其包含在順序鏈中，然後為測試集中的產品屬性批次生成新的描述。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6iMPQxzbUGz"
      },
      "outputs": [],
      "source": [
        "descgen_chain_tuned = LLMChain(\n",
        "    llm=llm_tuned, prompt=prompt_descgen, output_key=\"generated_description\"\n",
        ")\n",
        "\n",
        "overall_chain_tuned = SequentialChain(\n",
        "    chains=[descgen_chain_tuned, eval_chain],\n",
        "    input_variables=[\"platform_name\", \"product_attributes\"],\n",
        "    # Here you return multiple variables\n",
        "    output_variables=[\"generated_description\", \"is_safe\"],\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07e33ee8-d1db-4482-b32f-651dab737459"
      },
      "outputs": [],
      "source": [
        "result_0shot_tuned = overall_chain_tuned(\n",
        "    {\"platform_name\": \"Flipkart\", \"product_attributes\": attrs}\n",
        ")\n",
        "pp.pprint(result_0shot_tuned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S18taNiPxDhL"
      },
      "outputs": [],
      "source": [
        "sample_test[\"generated_description_tuned_0shot\"] = sample_test[\n",
        "    \"parsed_product_specs\"\n",
        "].apply(\n",
        "    lambda x: overall_chain_tuned(\n",
        "        {\"platform_name\": \"Flipkart\", \"product_attributes\": x}\n",
        "    )[\"generated_description\"]\n",
        ")\n",
        "sample_generated_descriptions_tuned_0shot = sample_test[\n",
        "    \"generated_description_tuned_0shot\"\n",
        "].values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaMUC1rphYzq"
      },
      "source": [
        "像以前一樣計算批次 Bleu、rouge 和語義相似度分數\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "660d0c4c81b3"
      },
      "outputs": [],
      "source": [
        "compute_quality_metrics_batch(\n",
        "    sample_generated_descriptions_tuned_0shot, sample_descriptions, embedding=embedding\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6-A4bq7a_7D"
      },
      "source": [
        "現在你可以快速瀏覽原始和生成的描述，然後將資料框儲存為 .CSV 格式的磁碟\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WOlWldsa_aQ"
      },
      "outputs": [],
      "source": [
        "sample_test[\n",
        "    [\"parsed_product_specs\", \"description\", \"generated_description_tuned_0shot\"]\n",
        "].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5KaCQnJbIKi"
      },
      "outputs": [],
      "source": [
        "sample_test.to_csv(\"./augmented_dataset.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1QWLiM6RLQg"
      },
      "source": [
        "### 方法 4：少樣本描述生成驗證與評估，使用微調的模型\n",
        "\n",
        "在此區段，你對模型執行參數有效率的微調，透過 500 對從訓練組中隨機抽樣的 (提示、描述)，以便進一步與描述和寫作風格相符。接著，你為一批次生成描述，並根據這三個指標針對原始描述評估它們，如前所述。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96d871810b88"
      },
      "source": [
        "注意：由於你並未以少量方式訓練調整模型，因此它有時可能會產生混淆並生成不自然的文字。在這種情況下，你可以依賴確認模型，它可以評估並重複提示直到生成有效的回覆。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29EXGCYKFV4A"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ 此區塊需要 TPU：請注意微調會使用 TPU，因此你需要確保專案中可供使用。</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyJVc_ieVeCI"
      },
      "outputs": [],
      "source": [
        "descgen_chain_fewshot_tuned = LLMChain(\n",
        "    llm=llm_tuned, prompt=prompt_descgen_fewshot, output_key=\"generated_description\"\n",
        ")\n",
        "overall_chain_fewshot_tuned = SequentialChain(\n",
        "    chains=[descgen_chain_fewshot_tuned, eval_chain],\n",
        "    input_variables=[\"platform_name\", \"product_attributes\", \"examples\"],\n",
        "    # Here you return multiple variables\n",
        "    output_variables=[\"generated_description\", \"is_safe\"],\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hL5_cW_wwQFx"
      },
      "outputs": [],
      "source": [
        "result_fewshot_tuned = overall_chain_fewshot_tuned(\n",
        "    {\"platform_name\": \"Flipkart\", \"product_attributes\": attrs, \"examples\": examples}\n",
        ")\n",
        "pp.pprint(result_fewshot_tuned[\"generated_description\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWKSrJBTWHfq"
      },
      "source": [
        "有時可能會發生由於上述原因，微調模型會產生不正確的回應：這就是為什麼驗證器模型的回應可被用於過濾它的原因\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36e0c8413df6"
      },
      "outputs": [],
      "source": [
        "pp.pprint(result_fewshot_tuned[\"is_safe\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQrziA-hwo3S"
      },
      "outputs": [],
      "source": [
        "sample_test[\"generated_description_tuned_fewshot\"] = sample_test[\n",
        "    \"parsed_product_specs\"\n",
        "].apply(\n",
        "    lambda x: overall_chain_fewshot_tuned(\n",
        "        {\n",
        "            \"platform_name\": \"Flipkart\",\n",
        "            \"product_attributes\": x,\n",
        "            \"examples\": compute_fewshot(x, retriever, train_spec_ix),\n",
        "        }\n",
        "    )[\"generated_description\"]\n",
        ")\n",
        "sample_generated_descriptions_tuned_fewshot = sample_test[\n",
        "    \"generated_description_tuned_fewshot\"\n",
        "].values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fddc6bdf06c4"
      },
      "source": [
        "這種情況下，由於微調模型降低了質量，特別是對於具有長度懲罰的 Bleu 分數。因此監控所有 3 項指標非常重要\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a70495bdd673"
      },
      "outputs": [],
      "source": [
        "compute_quality_metrics_batch(\n",
        "    sample_generated_descriptions_tuned_fewshot,\n",
        "    sample_descriptions,\n",
        "    embedding=embedding,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxpRRhQmbeSi"
      },
      "source": [
        "現在你可以快速瀏覽原始和生成的描述，然後將資料框儲存為 .CSV 格式的磁碟\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQmoG-_lbcmu"
      },
      "outputs": [],
      "source": [
        "sample_test[\n",
        "    [\"parsed_product_specs\", \"description\", \"generated_description_tuned_fewshot\"]\n",
        "].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LPRzlT1bkKT"
      },
      "outputs": [],
      "source": [
        "sample_test.to_csv(\"./augmented_dataset.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk_k-2AEVxZe"
      },
      "source": [
        "## 結語\n",
        "\n",
        "本筆記本說明如何使用 Vertex AI 生成式 AI 模型和 LangChain 建立 SEO 最佳化、真實且有創意的產品說明。\n",
        "\n",
        "在本筆記本中，你將會學習如何：\n",
        "\n",
        "* 利用少數範例來建立 LLM 和避免產生幻覺，以及根據類似產品調整產生的說明，使其更接近現有產品說明。\n",
        "* 使用 Vertex AI textembeddings 模型來評估語義相似度\n",
        "* 建立 LangChain 提示、檢索器、鏈條和順序鏈條以產生更多有創意且引人入勝的產品說明。\n",
        "* 使用 BLEU、ROUGE 和語義相似度 (基於餘弦距離) 分數針對原始文字批次評估生成文字的品質。\n",
        "* 使用驗證器 LLM 模型保護代理，以確保產生的文字準確、真實且有創意。\n",
        "\n",
        "### 可能的後續步驟：\n",
        "\n",
        "* 你可以透過使用 [Vertex AI 圖像標題服務](https://cloud.google.com/vertex-ai/docs/generative-ai/image/image-captioning) 來新增更多產品屬性，這也有助於豐富產品說明。\n",
        "* 你可以嘗試使用 RLHF (透過人類回饋進行強化學習) 來執行多個生成說明之間的偏好最佳化。\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-11.m108",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}