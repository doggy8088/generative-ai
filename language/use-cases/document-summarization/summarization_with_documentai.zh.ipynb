{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e",
        "tags": []
      },
      "source": [
        "# 使用 Document AI 和 PaLM API 摘要大型文件\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/doggy8088/generative-ai/blob/main/language/use-cases/document-summarization/summarization_with_documentai.zh.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory 圖標\"><br> 在 Colab 中執行\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/doggy8088/generative-ai/blob/main/language/use-cases/document-summarization/summarization_with_documentai.zh.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub 圖標\"><br> 在 GitHub 上查看\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/doggy8088/generative-ai/blob/main/language/use-cases/document-summarization/summarization_with_documentai.zh.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI 圖標\"><br> 在 Vertex AI Workbench 中開啟\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|作者| [Holt Skinner](https://github.com/holtskinner), [Mona Mona](https://github.com/Mona19) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## 概述\n",
        "\n",
        "文字摘要是指在仍保留最重要訊息的情況下，建立文字文件較短版本的程序。這對於各種用途都很有用，例如快速略讀長文件、掌握文章大意或與他人分享摘要。\n",
        "\n",
        "儘管摘要簡短段落是一項非瑣碎任務，但如果你想要摘要一份大型文件，例如包含多頁的 PDF 文件，那麼有幾個挑戰需要克服。\n",
        "\n",
        "[Document AI](https://cloud.google.com/document-ai) 提供一種可擴充且受管理的方法，可以利用 AI 從文件中提取資料。在本筆記本中，你將使用 [Document OCR 處理器](https://cloud.google.com/document-ai/docs/document-ocr)，這是一個預先訓練好的模型，將從文件檔中提取文字和版面資訊。Document AI 提供一個 API 端點來存取這些模型，讓開發人員不必建置和維護自己的模型和服務基礎架構。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d975e698c9a4"
      },
      "source": [
        "### 目標\n",
        "\n",
        "在此筆記本中，我們將展示你如何執行以下工作：\n",
        "\n",
        "1. 使用 Document AI OCR 處理器從 PDF 文件中擷取文字。\n",
        "1. 使用 MapReduce 方法對文件文字進行分段。\n",
        "1. 使用 PaLM `text-bison@001` 模型為擷取的文字產生摘要。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j1gvi3jqG6U"
      },
      "source": [
        "### 成本\n",
        "\n",
        "本教學使用 Google Cloud 的計費元件：\n",
        "\n",
        "- Generative AI 工作室提供的 Vertex AI PaLM API\n",
        "- Document AI\n",
        "\n",
        "了解 [Vertex AI 定價](https://cloud.google.com/vertex-ai/pricing)，\n",
        "了解 [Document AI 定價](https://cloud.google.com/document-ai/pricing)，\n",
        "並使用 [定價計算器](https://cloud.google.com/products/calculator/)\n",
        "根據你的預測使用量來估算成本。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDU0XJ1xRDlL"
      },
      "source": [
        "## 開始使用\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a5AEr0lkLKD"
      },
      "source": [
        "### 安裝 Vertex AI SDK 和其他相依性\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYACuZHAF3DQ",
        "outputId": "fe7c7dd2-3736-40cc-a279-7e335e0b0a2c"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade google-cloud-aiplatform==1.35.0 google-cloud-documentai==2.20.1 google-cloud-documentai-toolbox==0.11.1a backoff==2.2.1 --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG3WsMySF3DQ"
      },
      "source": [
        "**Colab 只限** ：執行以下Cell以重新啟動核心。對於 Vertex AI Workbench，你可以使用最上方的按鈕重新啟動終端機。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Hsqwn4hkLKE",
        "outputId": "85ae3d9f-cd86-4eef-febd-1d26a721fb4b"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-yyDsflbCc0"
      },
      "source": [
        "### 在專案中啟用 APIs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai62J2sLPDFX",
        "outputId": "2b00d861-384d-4312-cbb8-0710269654ff"
      },
      "outputs": [],
      "source": [
        "!gcloud config set project \"YOUR_PROJECT_ID\"\n",
        "!gcloud services enable documentai.googleapis.com storage.googleapis.com aiplatform.googleapis.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP76a2la7O-a"
      },
      "source": [
        "## Document AI\n",
        "\n",
        "以下 [限制](https://cloud.google.com/document-ai/quotas) 適用於 Document OCR 處理器的線上處理。\n",
        "\n",
        "| 限制                      | 值 |\n",
        "| :------------------------ | ----: |\n",
        "| 最大檔案大小           | 20 MB |\n",
        "| 最大頁數               |    15 |\n",
        "\n",
        "對於不符合這些限制的文件，你可以使用 [批次處理](https://cloud.google.com/document-ai/docs/send-request#batch-process) 提取文件文字。(未在本筆記中作介紹。)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZkLDRTjTcfm"
      },
      "source": [
        "### 準備資料檔\n",
        "\n",
        "首先，你需要下載以下摘要任務的 PDF。\n",
        "使用此筆記本電腦時，你將使用儲存在公開的 Google Cloud Storage 儲存空間中的 Alphabet 收益報告 PDF。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-IWo-lb-gbn",
        "outputId": "b12cd23e-633b-42fa-c872-b9c7ab96f945"
      },
      "outputs": [],
      "source": [
        "# Copying the files from the GCS bucket to local storage\n",
        "!gsutil -m cp -r gs://github-repo/documents/docai ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxmWYA05o4jj"
      },
      "source": [
        "### 建立 Document AI OCR 處理器\n",
        "\n",
        "[Document AI 處理器](https://cloud.google.com/document-ai/docs/overview#dai-processors) 在文件與執行文件處理動作的機器學習模型之間形成介面。這些處理器可為文件進行分類、拆分、語法剖析或分析。每個 Google Cloud 專案都需要建立自己的處理器執行個體。\n",
        "\n",
        "Document AI 處理器有兩個類型：\n",
        "\n",
        "- 預先訓練的處理器：這些處理器預先在大量文件資料集上進行訓練，可用於執行常見的文件處理工作，例如光學字元辨識 (OCR)、表單語法剖析，和實體萃取。\n",
        "- 自訂處理器：這些處理器可在你自己的文件資料集上進行訓練，藉以執行預先訓練的處理器未涵蓋的特定工作。\n",
        "\n",
        "請參閱 [完整處理器及詳細清單](https://cloud.google.com/document-ai/docs/processors-list) 以取得所有支援的處理器。\n",
        "\n",
        "處理器會將 PDF 或影像檔案作為輸入，並以 [`Document`](https://cloud.google.com/document-ai/docs/reference/rest/v1/Document) 格式輸出資料。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9URyhLDo4jk"
      },
      "source": [
        "### 建立處理器\n",
        "\n",
        "僅執行此程式碼一次以建立處理器。你無法使用相同的顯示名稱建立多個處理器。如果你收到錯誤訊息，請變更處理器名稱並重新執行。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7isig7e07O-a"
      },
      "outputs": [],
      "source": [
        "from google.api_core.client_options import ClientOptions\n",
        "from google.api_core.exceptions import AlreadyExists\n",
        "from google.cloud import documentai\n",
        "from google.cloud.documentai_toolbox.wrappers.document import Document\n",
        "\n",
        "# TODO(developer): Edit these variables before running the code.\n",
        "project_id = \"YOUR_PROJECT_ID\"\n",
        "\n",
        "# See https://cloud.google.com/document-ai/docs/regions for all options.\n",
        "location = \"us\"\n",
        "\n",
        "# Must be unique per project, e.g.: \"My Processor\"\n",
        "processor_display_name = \"YOUR_PROCESSOR_DISPLAY_NAME\"\n",
        "\n",
        "# You must set the `api_endpoint` if you use a location other than \"us\".\n",
        "client_options = ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
        "\n",
        "\n",
        "def create_processor(\n",
        "    project_id: str, location: str, processor_display_name: str\n",
        ") -> documentai.Processor:\n",
        "    client = documentai.DocumentProcessorServiceClient(client_options=client_options)\n",
        "\n",
        "    # The full resource name of the location\n",
        "    # e.g.: projects/project_id/locations/location\n",
        "    parent = client.common_location_path(project_id, location)\n",
        "\n",
        "    # Create a processor\n",
        "    return client.create_processor(\n",
        "        parent=parent,\n",
        "        processor=documentai.Processor(\n",
        "            display_name=processor_display_name, type_=\"OCR_PROCESSOR\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "\n",
        "try:\n",
        "    processor = create_processor(project_id, location, processor_display_name)\n",
        "    print(f\"Created Processor {processor.name}\")\n",
        "except AlreadyExists as e:\n",
        "    print(\n",
        "        f\"Processor already exits, change the processor name and rerun this code. {e.message}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkK74RRio4jk",
        "tags": []
      },
      "source": [
        "### 處理文件\n",
        "\n",
        "處理文件會取得處理器名稱和文件的檔案路徑，並從文件中萃取文字。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7bE7ZGtlcxv"
      },
      "outputs": [],
      "source": [
        "def process_document(\n",
        "    processor_name: str,\n",
        "    file_path: str,\n",
        ") -> documentai.Document:\n",
        "    client = documentai.DocumentProcessorServiceClient(client_options=client_options)\n",
        "\n",
        "    # Read the file into memory\n",
        "    with open(file_path, \"rb\") as image:\n",
        "        image_content = image.read()\n",
        "\n",
        "    # Load Binary Data into Document AI RawDocument Object\n",
        "    raw_document = documentai.RawDocument(\n",
        "        content=image_content, mime_type=\"application/pdf\"\n",
        "    )\n",
        "\n",
        "    # Configure the process request\n",
        "    request = documentai.ProcessRequest(name=processor_name, raw_document=raw_document)\n",
        "\n",
        "    result = client.process_document(request=request)\n",
        "\n",
        "    return result.document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usKPLAna5mLd"
      },
      "source": [
        "#### 建立資料區塊\n",
        "\n",
        "若於加入提示之前，將輸入資料分割成小「區塊」，LLM 在文件摘要處理上能產出最佳結果。\n",
        "\n",
        "最佳區塊大小會取決於文件大小。建議使用不同區塊大小進行實驗，以了解對特定資料集和應用程式的最佳做法。\n",
        "\n",
        "對於提供的文件，我們使用 Document AI 偵測的段落來區分區塊。\n",
        "\n",
        "你也應該嘗試其他值，並了解其對摘要的影響。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDf7Zw3SGuyW",
        "outputId": "d39f587e-d416-488d-8c44-e93cd186f926"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "from typing import Dict, List\n",
        "\n",
        "# If you already have a Document AI Processor in your project, assign the full processor resource name here.\n",
        "processor_name = processor.name\n",
        "extracted_data: List[Dict] = []\n",
        "\n",
        "# Loop through each PDF file in the \"docai\" directory.\n",
        "for path in glob.glob(\"docai/*.pdf\"):\n",
        "    # Extract the file name and type from the path.\n",
        "    file_name, file_type = os.path.splitext(path)\n",
        "\n",
        "    print(f\"Processing {file_name}\")\n",
        "\n",
        "    # Process the document.\n",
        "    document = process_document(processor_name, file_path=path)\n",
        "\n",
        "    if not document:\n",
        "        continue\n",
        "\n",
        "    # Using Document AI Toolbox to handle post-processing\n",
        "    wrapped_document = Document.from_documentai_document(document)\n",
        "\n",
        "    # Split the text into chunks based on paragraphs.\n",
        "    document_chunks = [\n",
        "        paragraph.text\n",
        "        for page in wrapped_document.pages\n",
        "        for paragraph in page.paragraphs\n",
        "    ]\n",
        "\n",
        "    # Can also split into chunks by page or blocks.\n",
        "    # document_chunks = [page.text for page in wrapped_document.pages]\n",
        "    # document_chunks = [block.text for page in wrapped_document.pages for block in page.blocks]\n",
        "\n",
        "    # Loop through each chunk and create a dictionary with metadata and content.\n",
        "    for chunk_number, chunk_content in enumerate(document_chunks, start=1):\n",
        "        # Append the chunk information to the extracted_data list.\n",
        "        extracted_data.append(\n",
        "            {\n",
        "                \"file_name\": file_name,\n",
        "                \"file_type\": file_type,\n",
        "                \"chunk_number\": chunk_number,\n",
        "                \"content\": chunk_content,\n",
        "            }\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj7KMupOPUX-"
      },
      "source": [
        "## 使用 [PaLM] (https://ai.google/discover/palm2/) 模型進行摘要\n",
        "\n",
        "你剛剛使用 Document AI 從 PDF 檔案中萃取文字。\n",
        "\n",
        "在下一節中，你將使用 Vertex AI 中的 PaLM 模型對萃取的文字進行摘要。\n",
        "為了對文字進行摘要，你可以使用 MapReduce 將文字分塊以符合提示大小。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe7OuYuGkLKF"
      },
      "source": [
        "### 驗證你的筆記本環境\n",
        "\n",
        "-如果你使用 **Colab** 執行此筆記本，執行下列Cell並繼續。\n",
        "-如果你使用 **Vertex AI Workbench** ，請查看 [這裡](https://github.com/doggy8088/generative-ai/tree/main/setup-env) 的設定說明。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YRKSFYOqSH4"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "PROJECT_ID = \"YOUR_PROJECT_ID\"  # @param {type:\"string\"}\n",
        "vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3edk4BiDkQ4"
      },
      "source": [
        "### 匯入模型\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKzpNLuzDeC4"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import backoff\n",
        "\n",
        "from google.api_core.exceptions import ResourceExhausted\n",
        "\n",
        "from vertexai.preview.language_models import TextGenerationModel\n",
        "\n",
        "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "\n",
        "\n",
        "# This decorator is used to handle exceptions and apply exponential backoff in case of ResourceExhausted errors.\n",
        "# It means the function will be retried with increasing time intervals in case of this specific exception.\n",
        "@backoff.on_exception(backoff.expo, ResourceExhausted, max_time=10)\n",
        "def text_generation_model_with_backoff(**kwargs):\n",
        "    \"\"\"\n",
        "    :param **kwargs: Keyword arguments for the prediction.\n",
        "    :return: The generated text.\n",
        "    \"\"\"\n",
        "    # Calls the generation_model's 'predict' method with the provided keyword arguments (**kwargs)\n",
        "    # and then accesses the 'text' attribute to get the generated text.\n",
        "    return generation_model.predict(**kwargs).text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM3V1JARZ9-k",
        "tags": []
      },
      "source": [
        "## MapReduce\n",
        "\n",
        "MapReduce 是一種非常有效的方法來處理大型資料集，原因在於它具備可擴充性和效率。它可以用於處理過大而無法在單一機器上處理的資料集。\n",
        "\n",
        "使用這個方法時，我們會先將大量資料分割成區塊，然後在每個文字區塊上執行提示。對於摘要任務而言，初始提示的輸出將會是該區塊的摘要。在產生所有初始輸出後，再執行不同的提示來結合它們。這對於大型資料集來說會更有效率。\n",
        "\n",
        "它包含兩個主要步驟，映射與歸約：\n",
        "\n",
        "- 映射步驟會將資料集分割成區塊，並在每個文字區塊上執行提示。提示的輸出是該區塊的摘要。\n",
        "\n",
        "- 歸約步驟會將所有區塊的摘要結合為一個摘要。\n",
        "\n",
        "以下是使用 MapReduce 方法進行摘要的優缺點：\n",
        "\n",
        "優點：\n",
        "\n",
        "- 可以摘要大型文件\n",
        "- 可以與平行處理搭配使用，因為摘要頁面的程序彼此獨立。\n",
        "\n",
        "缺點：\n",
        "\n",
        "- 需要多次呼叫模型\n",
        "- 由於各個頁面都個別摘要，因此各頁面之間的文脈可能會遺失。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo5NkotOJs3Y"
      },
      "source": [
        "#### 對照步驟\n",
        "\n",
        "在本部分，你將使用模型，透過初始提示範本，個別為每個段落文字摘要。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oT6brl-VCd8l"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"\n",
        "    Write a concise summary of the following text delimited by triple backquotes.\n",
        "\n",
        "    ```{text}```\n",
        "\n",
        "    CONCISE SUMMARY:\n",
        "\"\"\"\n",
        "\n",
        "# Create an empty list to store the summaries\n",
        "initial_summary: List[str] = []\n",
        "\n",
        "# Iterate over the pages and generate a summary for each page\n",
        "for individual_chunk in extracted_data:\n",
        "    # Create a prompt for the model using the extracted text and a prompt template\n",
        "    prompt = prompt_template.format(text=individual_chunk[\"content\"].strip())\n",
        "\n",
        "    # Generate a summary using the model and the prompt\n",
        "    summary = text_generation_model_with_backoff(prompt=prompt, max_output_tokens=1024)\n",
        "\n",
        "    # Append the summary to the list of summaries\n",
        "    initial_summary.append(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ3cOxWOJs3d"
      },
      "source": [
        "看看來自初始 Map 階段的前幾個摘要。這些摘要是每個個別文本段落的摘要。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-YHPaQbDH5t",
        "outputId": "f40d98e5-02cf-4278-8b6f-597cc3721f52"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\\n\".join(initial_summary[:5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HczirNnJs3d"
      },
      "source": [
        "#### 縮減步驟\n",
        "\n",
        "在這裡，你將建立一個縮減功能，它會串接來自初始摘要步驟 (對應步驟) 的摘要，並使用最終提示範本來建立初級摘要的摘要。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MF4JryiDTIK",
        "outputId": "7c3ccd01-5da8-4001-985f-153d7100aaac"
      },
      "outputs": [],
      "source": [
        "# Concatenate the summaries from the inital step\n",
        "concat_summary = \"\\n\".join(initial_summary)\n",
        "\n",
        "# Create a prompt for the model using the concatenated text and a prompt template\n",
        "prompt = prompt_template.format(text=concat_summary)\n",
        "\n",
        "# Generate a summary using the model and the prompt\n",
        "summary = text_generation_model_with_backoff(prompt=prompt, max_output_tokens=34)\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLFuRGrtN-9l"
      },
      "source": [
        "# 結論\n",
        "\n",
        "在此筆記本中，你了解了：\n",
        "\n",
        "1. 如何使用 Document AI 從這些 PDF 中提取文字。\n",
        "2. 如何使用 MapReduce 有效地處理大量文字資料。\n",
        "3. 如何使用 PaLM `text-bison@001` 模型來整理從 PDF 中提取出的文字。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR1vTtpXj1q"
      },
      "source": [
        "## 清除垃圾\n",
        "\n",
        "如果你不再需要 Document AI 處理器，可以使用以下程式碼將其刪除。\n",
        "\n",
        "或者，你可以使用 Cloud Console 來刪除處理器，如 [建立並管理處理器 > 刪除處理器](https://cloud.google.com/document-ai/docs/create-processor#documentai_delete_processor-web) 中所述。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "EuTdzGhbe9C3",
        "outputId": "4d1a1fa6-d638-4f76-a114-6463e1fa1938"
      },
      "outputs": [],
      "source": [
        "def delete_processor(processor_name: str) -> None:\n",
        "    client = documentai.DocumentProcessorServiceClient(client_options=client_options)\n",
        "\n",
        "    # Delete a processor\n",
        "    operation = client.delete_processor(name=processor_name)\n",
        "    # Print operation details\n",
        "    print(operation.operation.name)\n",
        "    # Wait for operation to complete\n",
        "    operation.result()\n",
        "\n",
        "\n",
        "delete_processor(delete_processor, processor_name)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-11.m108",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}