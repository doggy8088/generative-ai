{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "# å¾®èª¿ä¸¦éƒ¨ç½²åŸºç¤æ¨¡å‹\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/doggy8088/generative-ai/blob/main/language/tuning/tuning_text_bison.zh.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> åœ¨ Colab ä¸­åŸ·è¡Œ\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/doggy8088/generative-ai/blob/main/language/tuning/tuning_text_bison.zh.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> åœ¨ GitHub ä¸Šæª¢è¦–\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/doggy8088/generative-ai/blob/main/language/tuning/tuning_text_bison.zh.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> åœ¨ Vertex AI Workbench ä¸­é–‹å•Ÿ\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|ä½œè€… | [Erwin Huizenga](https://github.com/erwinh85) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "å»ºç«‹å¤§å‹èªè¨€æ¨¡å‹éœ€è¦å¤§é‡çš„è³‡æ–™ã€å¤§é‡çš„é‹ç®—è³‡æºä»¥åŠå°ˆé–€çš„æŠ€è¡“ã€‚åœ¨ Vertex AI ä¸Šï¼Œå¾®èª¿å¯è®“ä½ è‡ªè¨‚åŸºç¤æ¨¡å‹ä»¥æ‡‰ä»˜æ›´ç‰¹å®šçš„ä»»å‹™æˆ–çŸ¥è­˜é ˜åŸŸã€‚\n",
        "\n",
        "æç¤ºè¨­è¨ˆé›–ç„¶éå¸¸é©åˆå¿«é€Ÿå¯¦é©—ï¼Œä½†è‹¥æœ‰è¨“ç·´è³‡æ–™ï¼Œä½ å¯ä»¥é€éå¾®èª¿æ¨¡å‹ä¾†æå‡å“è³ªã€‚å¾®èª¿æ¨¡å‹å¯è®“ä½ æ ¹æ“šä½ å¸Œæœ›æ¨¡å‹åŸ·è¡Œçš„ä»»å‹™ç¯„ä¾‹ï¼Œä¾†è‡ªè¨‚æ¨¡å‹å›æ‡‰ã€‚\n",
        "\n",
        "å¦‚éœ€äº†è§£å¾®èª¿çš„æ›´å¤šè©³ç´°è³‡è¨Šï¼Œè«‹åƒé–± [å®˜æ–¹æ–‡ä»¶](https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-models)ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d975e698c9a4"
      },
      "source": [
        "### ç›®æ¨™\n",
        "\n",
        "æœ¬æ•™å­¸èª²ç¨‹å°‡æ•™ä½ å¦‚ä½•é‡å°æ–°çš„æœªè¦‹éè³‡æ–™å¾®èª¿åŸºç¤æ¨¡å‹ï¼Œè€Œä¸”ä½ å°‡æœƒä½¿ç”¨ä¸‹åˆ— Google Cloud ç”¢å“ï¼š\n",
        "\n",
        "- Vertex AI Generative AI Studio\n",
        "- Vertex AI Pipelines\n",
        "- Vertex AI Model Registry\n",
        "- Vertex AI Endpoints\n",
        "\n",
        "åŸ·è¡Œçš„æ­¥é©ŸåŒ…æ‹¬ï¼š\n",
        "\n",
        "- å¾ BQ å–å¾—è¨“ç·´è³‡æ–™ä¸¦ç”¢ç”Ÿä¸€å€‹ JSONL æª”æ¡ˆ\n",
        "- ä¸Šå‚³è¨“ç·´è³‡æ–™\n",
        "- å»ºç«‹ä¸€å€‹ç®¡é“ä½œæ¥­\n",
        "- åœ¨ Vertex AI Model Registry ä¸­æª¢æŸ¥ä½ çš„æ¨¡å‹\n",
        "- å¾ä½ çš„å¾®èª¿æ¨¡å‹å–å¾—é æ¸¬\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CZvFRbIaalF"
      },
      "source": [
        "### é…é¡\n",
        "**é‡è¦äº‹é …** : èª¿æ•´ text-bison@001 æ¨¡å‹æœƒä½¿ç”¨ tpu-v3-8 è¨“ç·´è³‡æºä»¥åŠä½  Google Cloud å°ˆæ¡ˆéš¨é™„çš„é…é¡ã€‚æ¯å€‹å°ˆæ¡ˆæœ‰å…«å€‹ v3-8 æ ¸å¿ƒé…é¡ï¼Œå¯å®¹è¨±åŸ·è¡ŒåŒæ™‚åŸ·è¡Œä¸€è‡³å…©å€‹èª¿æ•´å·¥ä½œã€‚å¦‚æœä½ æƒ³åŸ·è¡Œæ›´å¤šåŒæ™‚åŸ·è¡Œå·¥ä½œï¼Œéœ€è¦é€é [é…é¡é é¢](https://console.cloud.google.com/iam-admin/quotas) è¦æ±‚é¡å¤–é…é¡ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q2bKpVjaalF"
      },
      "source": [
        "### è²»ç”¨\n",
        "æœ¬æ•™å­¸æŒ‡å—ä½¿ç”¨ Google\n",
        "Cloud çš„è¨ˆè²»å…ƒä»¶ï¼š\n",
        "\n",
        "* Vertex AI Generative AI Studio\n",
        "\n",
        "äº†è§£ [Vertex AI å®šåƒ¹](https://cloud.google.com/vertex-ai/pricing)\n",
        "ï¼Œä¸¦ä½¿ç”¨ [å®šåƒ¹è¨ˆç®—å™¨](https://cloud.google.com/products/calculator/)\n",
        "ï¼Œæ ¹æ“šé è¨ˆç”¨é‡ç”¢ç”Ÿæˆæœ¬ä¼°ç®—ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acBlvcGFaalF"
      },
      "source": [
        "### å®‰è£ Vertex AI SDK\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEtR1xyRaalG"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-aiplatform google-cloud-bigquery sequence-evaluate sentence-transformers rouge --upgrade --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAMVnZC9aalG"
      },
      "source": [
        "**åƒ… Colabï¼š** å–æ¶ˆä»¥ä¸‹å–®å…ƒçš„è¨»è§£ä»¥é‡æ–°å•Ÿå‹•Kernelæˆ–ä½¿ç”¨é‡æ–°å•Ÿå‹•æŒ‰éˆ•ã€‚å°æ–¼ Vertex AI Workbenchï¼Œä½ å¯ä»¥ä½¿ç”¨é ‚ç«¯çš„æŒ‰éˆ•é‡æ–°å•Ÿå‹•çµ‚ç«¯æ©Ÿã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdQC6wcuaalG"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LlxsZrWaalG"
      },
      "source": [
        "### é©—è­‰ç­†è¨˜æœ¬ç’°å¢ƒ\n",
        "* å¦‚æœä½ ä½¿ç”¨ **Colab** åŸ·è¡Œæ­¤ç­†è¨˜æœ¬ï¼Œå–æ¶ˆè¨»è§£ä¸‹æ–¹çš„Cellä¸¦ç¹¼çºŒã€‚\n",
        "* å¦‚æœä½ ä½¿ç”¨ **Vertex AI å·¥ä½œå°** ï¼Œè«‹æŸ¥çœ‹[æ­¤è™•](https://github.com/doggy8088/generative-ai/tree/main/setup-env)çš„è¨­å®šèªªæ˜ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oh-QANoIaalG"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW8qtGsmaalG"
      },
      "source": [
        "### BigQuery IAM\n",
        "ç¾åœ¨ä½ éœ€è¦åŠ å…¥æœå‹™å¸³æˆ¶çš„æ¬Šé™ï¼š\n",
        "- å‰å¾€ä¸»æ§å°çš„ [IAM é é¢](https://console.cloud.google.com/iam-admin/)\n",
        "- å°‹æ‰¾é è¨­çš„é‹ç®—æœå‹™å¸³æˆ¶ã€‚å®ƒæ‡‰è©²çœ‹èµ·ä¾†åƒé€™æ¨£ï¼š`<project-number>-compute@developer.gserviceaccount.com`\n",
        "- åˆ†é… `bigquery.user` çµ¦é è¨­çš„é‹ç®—æœå‹™å¸³æˆ¶\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmhnHOjlaalH"
      },
      "source": [
        "### è¨­å®šä½ çš„å°ˆæ¡ˆä»£è™Ÿ\n",
        "\n",
        "**å¦‚æœä½ ä¸çŸ¥é“ä½ çš„å°ˆæ¡ˆä»£è™Ÿ** , ä½ å¯èƒ½æœƒä½¿ç”¨ `gcloud` ä¾†å–å¾—ä½ çš„å°ˆæ¡ˆä»£è™Ÿã€‚å¦å‰‡ï¼Œè«‹æŸ¥çœ‹æ”¯æ´ç¶²é ï¼š[æ‰¾å‡ºå°ˆæ¡ˆä»£è™Ÿ](https://support.google.com/googleapi/answer/7014113)ã€‚è«‹åœ¨åº•ä¸‹æ›´æ–° `PROJECT_ID`ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8nXkkYxaalH"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"<your_project_id>\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrsmSjICaalH"
      },
      "source": [
        "### å»ºç«‹å„²å­˜å€\n",
        "ç¾åœ¨ä½ å¿…é ˆå»ºç«‹ä¸€å€‹å„²å­˜å€ï¼Œæˆ‘å€‘å°‡ä½¿ç”¨å®ƒä¾†å„²å­˜èª¿æ•´è³‡æ–™ã€‚å¦‚éœ€é¿å…ä½¿ç”¨è€…åœ¨è³‡æºå»ºç«‹æ™‚ç™¼ç”Ÿé‡è¤‡ï¼Œè«‹ç‚ºæ¯å€‹åŸ·è¡Œéšæ®µç”¢ç”Ÿä¸€å€‹ UUIDï¼Œä¸¦å°‡å…¶é™„åŠ åˆ°æ­¤æ•™å­¸èª²ç¨‹ä¸­å»ºç«‹çš„è³‡æºåç¨±ä¸Šã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LiKRZOgqaalH"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "\n",
        "# Generate a uuid of a specifed length(default=8)\n",
        "def generate_uuid(length: int = 8) -> str:\n",
        "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
        "\n",
        "\n",
        "UUID = generate_uuid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D28-KrtaalH"
      },
      "source": [
        "é¸æ“‡å„²å­˜ç©ºé–“åç¨±ä¸¦æ›´æ–° `BUCKET_NAME` åƒæ•¸ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pxRSNVCYaalH"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"<your_bucket_uri>\"  # @param {type:\"string\"}\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
        "REGION = \"us-central1\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZpjqMRc-aalH"
      },
      "outputs": [],
      "source": [
        "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"<your-bucket-name>\":\n",
        "    BUCKET_NAME = \"vertex-\" + UUID\n",
        "    BUCKET_URI = f\"gs://{BUCKET_NAME}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtJg8ILPaalH"
      },
      "source": [
        "åƒ…åœ¨ä½ çš„å„²å­˜ç©ºé–“å°šä¸å­˜åœ¨æ™‚ï¼šåŸ·è¡Œä¸‹åˆ—Cellä¾†å»ºç«‹ä½ çš„é›²ç«¯å„²å­˜ç©ºé–“å„²å­˜ç©ºé–“ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSRiXkavaalH"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNL0oqUJaalH"
      },
      "source": [
        "æœ€å¾Œï¼Œé€éæª¢æŸ¥é›²ç«¯å„²å­˜ç©ºé–“ä¸­çš„å…§å®¹ï¼Œé©—è­‰å­˜å–æ¬Šé™ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leJFL5oIaalH"
      },
      "outputs": [],
      "source": [
        "! gsutil ls -al $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoEqT2Y4DJmf"
      },
      "source": [
        "### åŒ¯å…¥å‡½å¼åº«\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E7pfl6sjzh_"
      },
      "source": [
        "**Colab åªé™** : åŸ·è¡Œä¸‹åˆ—Cellä»¥åˆå§‹åŒ– Vertex AI SDKã€‚å°æ–¼ Vertex AI Workbenchï¼Œä½ ä¸å¿…åŸ·è¡Œé€™å€‹å‹•ä½œã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JXlNPFmGjzh_"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pRUOFELefqf1"
      },
      "outputs": [],
      "source": [
        "from typing import Union\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud import bigquery\n",
        "from vertexai.language_models import TextGenerationModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdtNETYxaalH"
      },
      "source": [
        "## èª¿æ•´ä½ çš„æ¨¡å‹\n",
        "\n",
        "ç¾åœ¨ä½ å¯ä»¥å»ºç«‹èª¿æ•´å·¥ä½œã€‚é€éä½¿ç”¨ Generative AI Studioã€cURL æˆ– Python SDK å»ºç«‹ç®¡ç·šå·¥ä½œä¾†èª¿æ•´åŸºç¤æ¨¡å‹ã€‚åœ¨æœ¬ç­†è¨˜æœ¬ä¸­ï¼Œæˆ‘å€‘å°‡ä½¿ç”¨ Python SDKã€‚ä½ å°‡ä½¿ç”¨ Q&A èˆ‡ JSON æ ¼å¼çš„è„ˆçµ¡è³‡æ–™é›†ã€‚\n",
        "\n",
        "### è¨“ç·´è³‡æ–™\n",
        "ğŸ’¾ ä½ çš„æ¨¡å‹èª¿æ•´è³‡æ–™é›†å¿…é ˆæ¡ç”¨ JSONL æ ¼å¼ï¼Œå…¶ä¸­æ¯ä¸€è¡ŒåŒ…å«ä¸€å€‹å–®ä¸€çš„è¨“ç·´ç¯„ä¾‹ã€‚ä½ å¿…é ˆç¢ºä¿åŒ…å«èªªæ˜ã€‚\n",
        "\n",
        "ä½ å°‡ä½¿ç”¨ BigQuery å…¬å…±è³‡æ–™é›†ä¸­çš„ StackOverflow è³‡æ–™ï¼Œé™åˆ¶ç‚ºæ¨™ç±¤ç‚º `python` çš„å•é¡Œï¼Œä¸¦è‡ª 2020-01-01 ä»¥ä¾†æ¥å—å›è¦†çš„ç­”æ¡ˆã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Puc3jl8QaalI"
      },
      "source": [
        "é¦–å…ˆå»ºç«‹ä¸€å€‹è¼”åŠ©å‡½å¼ï¼Œè®“ä½ å¯ä»¥è¼•é¬†çš„æŸ¥è©¢ BigQuery ä¸¦ä¸”å›å‚³çµæœä½œç‚º Pandas DataFrameã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Eg60aUgvaalI"
      },
      "outputs": [],
      "source": [
        "def run_bq_query(sql: str) -> Union[str, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Run a BigQuery query and return the job ID or result as a DataFrame\n",
        "    Args:\n",
        "        sql: SQL query, as a string, to execute in BigQuery\n",
        "    Returns:\n",
        "        df: DataFrame of results from query,  or error, if any\n",
        "    \"\"\"\n",
        "\n",
        "    bq_client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "    # Try dry run before executing query to catch any errors\n",
        "    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
        "    bq_client.query(sql, job_config=job_config)\n",
        "\n",
        "    # If dry run succeeds without errors, proceed to run query\n",
        "    job_config = bigquery.QueryJobConfig()\n",
        "    client_result = bq_client.query(sql, job_config=job_config)\n",
        "\n",
        "    job_id = client_result.job_id\n",
        "\n",
        "    # Wait for query/job to finish running. then get & return data frame\n",
        "    df = client_result.result().to_arrow().to_pandas()\n",
        "    print(f\"Finished job_id: {job_id}\")\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BydoFfTaalI"
      },
      "source": [
        "æ¥ä¸‹ä¾†å®šç¾©æŸ¥è©¢å…§å®¹ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VTaovLtaalI"
      },
      "outputs": [],
      "source": [
        "df = run_bq_query(\n",
        "    \"\"\"SELECT\n",
        "    CONCAT(q.title, q.body) as input_text,\n",
        "    a.body AS output_text\n",
        "FROM\n",
        "    `bigquery-public-data.stackoverflow.posts_questions` q\n",
        "JOIN\n",
        "    `bigquery-public-data.stackoverflow.posts_answers` a\n",
        "ON\n",
        "    q.accepted_answer_id = a.id\n",
        "WHERE\n",
        "    q.accepted_answer_id IS NOT NULL AND\n",
        "    REGEXP_CONTAINS(q.tags, \"python\") AND\n",
        "    a.creation_date >= \"2020-01-01\"\n",
        "LIMIT\n",
        "    10000\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYUg8cBbaalJ"
      },
      "source": [
        "æ‡‰è©²æœ‰ 10k çš„å•ç­”è³‡æ–™ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FqbVHoeaalJ"
      },
      "outputs": [],
      "source": [
        "print(len(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OftmoPZ6aalJ"
      },
      "source": [
        "è®“æˆ‘å€‘å°‡è³‡æ–™åˆ†æˆè¨“ç·´å’Œè©•ä¼°ã€‚å°æ–¼æŠ½å–å¼å•ç­”ä»»å‹™æˆ‘å€‘å»ºè­°ä½¿ç”¨ 100+ è¨“ç·´ç¯„ä¾‹ã€‚åœ¨é€™å€‹æƒ…æ³ä¸­ä½ å°‡ä½¿ç”¨ 800ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXqBwSwaaalJ"
      },
      "outputs": [],
      "source": [
        "# split is set to 80/20\n",
        "train, evaluation = train_test_split(df, test_size=0.2)\n",
        "evaluation = evaluation.sample(n=250, random_state=1)\n",
        "print(len(train))\n",
        "print(len(evaluation))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf-q8TpnaalJ"
      },
      "source": [
        "é€²è¡Œèª¿æ ¡æ™‚ï¼Œå¿…é ˆå…ˆå°‡è¨“ç·´è³‡æ–™è½‰æ›ç‚º JSONL æ ¼å¼ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqRbOwzEaalJ"
      },
      "outputs": [],
      "source": [
        "tune_jsonl = train.to_json(orient=\"records\", lines=True)\n",
        "\n",
        "print(f\"Length: {len(tune_jsonl)}\")\n",
        "print(tune_jsonl[0:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r04PWISCaalJ"
      },
      "source": [
        "æ¥è‘—ï¼Œä½ å¯ä»¥åœ¨å‚³é€è‡³ Google Cloud Storage (GCS) ä¹‹å‰ï¼Œå…ˆå°‡å®ƒå¯«å…¥æœ¬æ©Ÿ JSONLã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vXVV9c0HaalJ"
      },
      "outputs": [],
      "source": [
        "training_data_filename = \"tune_data_stack_overflow_python_qa.jsonl\"\n",
        "\n",
        "with open(training_data_filename, \"w\") as f:\n",
        "    f.write(tune_jsonl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHS1lDIrrfQH"
      },
      "outputs": [],
      "source": [
        "tune_jsonl = evaluation.to_json(orient=\"records\", lines=True)\n",
        "\n",
        "print(f\"Length: {len(tune_jsonl)}\")\n",
        "print(tune_jsonl[0:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4eULfrv2rTjO"
      },
      "outputs": [],
      "source": [
        "evaluation_data_filename = \"tune_eval_data_stack_overflow_python_qa.jsonl\"\n",
        "\n",
        "with open(evaluation_data_filename, \"w\") as f:\n",
        "    f.write(tune_jsonl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV8Wxz7JaalN"
      },
      "source": [
        "ä½ æ¥è‘—å¯ä»¥å°‡æœ¬æ©Ÿæª”æ¡ˆåŒ¯å‡ºåˆ° GCSï¼ŒVertex AI ä¾¿å¯æ–¼èª¿æ•´ä½œæ¥­ä¸­ä½¿ç”¨è©²æª”æ¡ˆã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDDLHac5aalN"
      },
      "outputs": [],
      "source": [
        "! gsutil cp $training_data_filename $evaluation_data_filename $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff68wmzoaalN"
      },
      "source": [
        "ä½ å¯ä»¥æª¢æŸ¥æª”æ¡ˆæ˜¯å¦é †åˆ©å‚³è¼¸åˆ°ä½ çš„ Google Cloud Storage å„²å­˜ç©ºé–“ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-DnKpYlaalN"
      },
      "outputs": [],
      "source": [
        "! gsutil ls -al $BUCKET_URI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8wE9P7OFaalN"
      },
      "outputs": [],
      "source": [
        "TRAINING_DATA_URI = f\"{BUCKET_URI}/{training_data_filename}\"\n",
        "EVAUATION_DATA_URI = f\"{BUCKET_URI}/{evaluation_data_filename}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mW7K57BaalN",
        "tags": []
      },
      "source": [
        "### æ¨¡å‹å¾®èª¿\n",
        "ç¾åœ¨æ˜¯é–‹å§‹å¾®èª¿æ¨¡å‹çš„æ™‚å€™äº†ã€‚ä½ å°‡ä½¿ç”¨ Vertex AI SDK æäº¤å¾®èª¿å·¥ä½œã€‚\n",
        "\n",
        "#### å»ºè­°çš„å¾®èª¿è¨­å®š\n",
        "âœ… ä»¥ä¸‹æ˜¯æ ¹æ“šä»»å‹™å¾®èª¿åŸºç¤æ¨¡å‹çš„ä¸€äº›å»ºè­°è¨­å®šï¼Œä¾‹å¦‚æ­¤ç¯„ä¾‹ä¸­çš„å•ç­”ã€‚ä½ å¯ä»¥åœ¨ [æ–‡ä»¶](https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-models) ä¸­æ‰¾åˆ°æ›´å¤šè³‡è¨Šã€‚\n",
        "\n",
        "èƒå–å¼å•ç­”ï¼š\n",
        "- ç¢ºä¿è¨“ç·´è³‡æ–™é›†å¤§å°è¶…é 100 ç­†\n",
        "- è¨“ç·´æ­¥é©Ÿ [100-500]ã€‚ä½ å¯ä»¥å˜—è©¦å¤šå€‹å€¼ä»¥å–å¾—ç‰¹å®šè³‡æ–™é›†çš„æœ€ä½³æ•ˆèƒ½ (ä¾‹å¦‚ 100ã€200ã€500)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vP_jeATTnbK"
      },
      "outputs": [],
      "source": [
        "# create tensorboard\n",
        "display_name = \"Adapter tuning - \"\n",
        "\n",
        "tensorboard = aiplatform.Tensorboard.create(\n",
        "    display_name=display_name,\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        ")\n",
        "\n",
        "print(tensorboard.display_name)\n",
        "print(tensorboard.resource_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CFVBoFu5Cnx"
      },
      "outputs": [],
      "source": [
        "# Get tensorboard_id thats used in the pipeline\n",
        "tensorboard_id = tensorboard.resource_name.split(\"tensorboards/\")[-1]\n",
        "print(tensorboard_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "26HRfld3aalN"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = f\"genai-workshop-tuned-model-{UUID}\"\n",
        "TRAINING_STEPS = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "DvG1Rp3-iAG_"
      },
      "outputs": [],
      "source": [
        "pipeline_arguments = {\n",
        "    \"model_display_name\": MODEL_NAME,\n",
        "    \"location\": REGION,\n",
        "    \"large_model_reference\": \"text-bison@001\",\n",
        "    \"project\": PROJECT_ID,\n",
        "    \"train_steps\": TRAINING_STEPS,\n",
        "    \"dataset_uri\": TRAINING_DATA_URI,\n",
        "    \"evaluation_interval\": 20,\n",
        "    \"evaluation_data_uri\": EVAUATION_DATA_URI,\n",
        "    \"tensorboard_resource_id\": tensorboard_id,\n",
        "}\n",
        "\n",
        "pipeline_root = f\"{BUCKET_URI}/{MODEL_NAME}\"\n",
        "template_path = \"https://us-kfp.pkg.dev/ml-pipeline/large-language-model-pipelines/tune-large-model/v2.0.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "on4baTh5aalN"
      },
      "outputs": [],
      "source": [
        "# Function that starts the tuning job\n",
        "def tuned_model(\n",
        "    project_id: str,\n",
        "    location: str,\n",
        "    template_path: str,\n",
        "    model_display_name: str,\n",
        "    pipeline_arguments: str,\n",
        "):\n",
        "    \"\"\"Prompt-tune a new model, based on a prompt-response data.\n",
        "\n",
        "    \"training_data\" can be either the GCS URI of a file formatted in JSONL format\n",
        "    (for example: training_data=f'gs://{bucket}/{filename}.jsonl'), or a pandas\n",
        "    DataFrame. Each training example should be JSONL record with two keys, for\n",
        "    example:\n",
        "      {\n",
        "        \"input_text\": <input prompt>,\n",
        "        \"output_text\": <associated output>\n",
        "      },\n",
        "\n",
        "    Args:\n",
        "      project_id: GCP Project ID, used to initialize aiplatform\n",
        "      location: GCP Region, used to initialize aiplatform\n",
        "      template_path: path to the template\n",
        "      model_display_name: Name for your model.\n",
        "      pipeline_arguments: arguments used during pipeline runtime\n",
        "    \"\"\"\n",
        "\n",
        "    aiplatform.init(project=project_id, location=location)\n",
        "\n",
        "    from google.cloud.aiplatform import PipelineJob\n",
        "\n",
        "    job = PipelineJob(\n",
        "        template_path=template_path,\n",
        "        display_name=model_display_name,\n",
        "        parameter_values=pipeline_arguments,\n",
        "        location=REGION,\n",
        "        pipeline_root=pipeline_root,\n",
        "        enable_caching=True,\n",
        "    )\n",
        "\n",
        "    return job"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0XNL9ojaalN"
      },
      "source": [
        "æ¥ä¸‹ä¾†ï¼Œæ˜¯æ™‚å€™é–‹å§‹ä½ çš„å¾®èª¿å·¥ä½œäº†ã€‚\n",
        "\n",
        "**å…è²¬è²æ˜ï¼š** å¾®èª¿å’Œéƒ¨ç½²æ¨¡å‹éœ€è¦æ™‚é–“ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0m86z20zFgl"
      },
      "outputs": [],
      "source": [
        "job = tuned_model(PROJECT_ID, REGION, template_path, MODEL_NAME, pipeline_arguments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPHoXo8UIhlz"
      },
      "outputs": [],
      "source": [
        "job.submit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRCkdxXvaalO"
      },
      "source": [
        "æŒ‰ä¸Šè¿°é€£çµï¼Œä½ å¯ä»¥æŸ¥çœ‹ä½ çš„ä¸²æ¥åŸ·è¡Œã€‚å¦‚ä»¥ä¸‹æˆªåœ–æ‰€ç¤ºï¼Œå®ƒæœƒåŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š\n",
        "\n",
        "- é©—è­‰\n",
        "- åŒ¯å‡ºç®¡ç†çš„è³‡æ–™é›†\n",
        "- å°‡ JSONL è½‰æ›ç‚º TFRecord\n",
        "- å¤§å‹èªè¨€æ¨¡å‹å¾®èª¿\n",
        "- ä¸Šå‚³ LLM æ¨¡å‹\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq9rL5o32EXs"
      },
      "source": [
        "`job.state` è®“ä½ å¯ä»¥æŸ¥çœ‹ç®¡ç·šçš„ç‹€æ…‹ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8l8o3z30WO4"
      },
      "outputs": [],
      "source": [
        "job.state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6JC8XplaalO"
      },
      "source": [
        "## åœ¨ Vertex AI Model Registry ä¸Šæª¢è¦–ä½ èª¿æ•´å®Œæˆçš„åŸºç¤æ¨¡å‹\n",
        "èª¿æ•´å·¥ä½œå®Œæˆå¾Œï¼Œä½ çš„æ¨¡å‹æœƒé¡¯ç¤ºåœ¨ Vertex AI Model Registry ä¸Šã€‚ä»¥ä¸‹ Python SDK ç¯„ä¾‹æœƒé¡¯ç¤ºå¦‚ä½•åˆ—å‡ºç¶“éèª¿æ•´çš„æ¨¡å‹ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPWX0ITCaalO"
      },
      "outputs": [],
      "source": [
        "def list_tuned_models(project_id, location):\n",
        "    aiplatform.init(project=project_id, location=location)\n",
        "    model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "    tuned_model_names = model.list_tuned_model_names()\n",
        "    print(tuned_model_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAIwCGYJaalO"
      },
      "outputs": [],
      "source": [
        "list_tuned_models(PROJECT_ID, REGION)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZriyF0V-aalO"
      },
      "source": [
        "ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ Google Cloud Console UI æª¢è¦– [Vertex AI Model Registry](https://console.cloud.google.com/vertex-ai/models) ä¸­çš„æ‰€æœ‰æ¨¡å‹ã€‚ä¸‹é¢ä½ å¯ä»¥çœ‹åˆ° Vertex AI Model Registry ä¸­å¯ç”¨çš„å·²èª¿æ•´åŸºç¤æ¨¡å‹ç¯„ä¾‹ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFftY6-EaalO"
      },
      "source": [
        "## ä½¿ç”¨å·²èª¿æ ¡æ¨¡å‹å–å¾—é æ¸¬\n",
        "ç¾åœ¨æ˜¯å–å¾—é æ¸¬çš„æ™‚å€™äº†ã€‚é¦–å…ˆï¼Œä½ éœ€è¦å¾ Vertex AI æ¨¡å‹è¨»å†Šå–å¾—æœ€æ–°çš„èª¿æ ¡æ¨¡å‹ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vU-K3EIkaalO"
      },
      "outputs": [],
      "source": [
        "def fetch_model(project_id, location):\n",
        "    aiplatform.init(project=project_id, location=location)\n",
        "    model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "    list_tuned_models = model.list_tuned_model_names()\n",
        "    tuned_model = list_tuned_models[0]\n",
        "\n",
        "    return tuned_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j66dr12taalO"
      },
      "outputs": [],
      "source": [
        "deployed_model = fetch_model(PROJECT_ID, REGION)\n",
        "deployed_model = TextGenerationModel.get_tuned_model(deployed_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDOueoptaalO"
      },
      "source": [
        "ç¾åœ¨ä½ å¯ä»¥é–‹å§‹å‚³é€æç¤ºåˆ° APIã€‚è«‹éš¨æ™‚æ›´æ–°ä»¥ä¸‹æç¤ºã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ERbfPJPaalO"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"\"\"\n",
        "How can I store my TensorFlow checkpoint on Google Cloud Storage?\n",
        "\n",
        "Python example:\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trzon4EyaalO"
      },
      "outputs": [],
      "source": [
        "print(deployed_model.predict(PROMPT))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtYr_KNPaalO"
      },
      "source": [
        "## è©•ä¼°\n",
        "å°æ¨¡å‹åŸ·è¡Œè©•ä¼°ä¾†äº†è§£å…¶æ•ˆèƒ½è‡³é—œé‡è¦ã€‚è©•ä¼°å¯ä½¿ç”¨ F1 æˆ– Rouge ç­‰è©•ä¼°æŒ‡æ¨™ä»¥è‡ªå‹•åŒ–æ–¹å¼é€²è¡Œã€‚ä½ ä¹Ÿå¯ä»¥é‹ç”¨äººå·¥è©•ä¼°æ–¹æ³•ã€‚äººå·¥è©•ä¼°æ–¹æ³•æ¶‰åŠè¦æ±‚äººå“¡è©•åˆ† LLM å›ç­”çš„å“è³ªã€‚é€™å¯é€éç¾¤çœ¾å¤–åŒ…æˆ–ç”±å°ˆå®¶è©•ä¼°å›æ‡‰ä¾†åŸ·è¡Œã€‚ä¸€äº›æ¨™æº–çš„äººå·¥è©•ä¼°æŒ‡æ¨™åŒ…æ‹¬æµæš¢åº¦ã€é€£è²«æ€§ã€ç›¸é—œæ€§ï¼Œå’Œè³‡è¨Šæ€§ã€‚ä½ é€šå¸¸æœƒæƒ³è¦é¸æ“‡å¤šç¨®è©•ä¼°æŒ‡æ¨™ï¼Œä»¥ä¾¿å……åˆ†äº†è§£æ¨¡å‹æ•ˆèƒ½ã€‚ä»¥ä¸‹æœƒæä¾›è©•ä¼°åŸ·è¡Œçš„ç¯„ä¾‹ã€‚\n",
        "\n",
        "åœ¨æ­¤ç¯„ä¾‹ä¸­ï¼Œä½ å°‡ä½¿ç”¨ [sequence-evaluate](https://pypi.org/project/sequence-evaluate/) ä¾†è©•ä¼°èª¿æ•´å¾Œçš„æ¨¡å‹ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9856CuicaalO"
      },
      "outputs": [],
      "source": [
        "from seq_eval import SeqEval\n",
        "\n",
        "evaluator = SeqEval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS10ybdraalO"
      },
      "source": [
        "åœ¨ç­†è¨˜æœ¬å‰é¢ï¼Œä½ å»ºç«‹äº†ä¸€å€‹è¨“ç·´å’Œè©•é‡è³‡æ–™é›†ã€‚ç¾åœ¨æ˜¯å–å¾—éƒ¨åˆ†è©•é‡è³‡æ–™çš„æ™‚å€™äº†ã€‚ä½ å°‡ä½¿ç”¨é€™äº›å•é¡Œå¾æˆ‘å€‘å¾®èª¿çš„æ¨¡å‹å–å¾—å›æ‡‰ï¼Œè€Œæˆ‘å€‘æœƒä½¿ç”¨ç­”æ¡ˆä½œç‚ºåƒè€ƒï¼š\n",
        "\n",
        "- **å€™é¸é …ç›®ï¼š** å¾®èª¿æ¨¡å‹ç”¢ç”Ÿçš„ç­”æ¡ˆã€‚\n",
        "- **åƒè€ƒï¼š** æˆ‘å€‘å°‡ç”¨æ–¼æ¯”è¼ƒçš„åŸå§‹ç­”æ¡ˆã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKMmIH0XaalO"
      },
      "outputs": [],
      "source": [
        "evaluation = evaluation.head(10)  # you can change the number of rows you want to use\n",
        "evaluation_question = evaluation[\"input_text\"]\n",
        "evaluation_answer = evaluation[\"output_text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx-g2molaalP"
      },
      "source": [
        "ç¾åœ¨ä½ å¯ä»¥ä½¿ç”¨æ ¹æ“šä½ å¾è©•ä¼°è³‡æ–™é›†ä¸­æå‡ºçš„å•é¡Œèª¿æ•´çš„æ¨¡å‹ç¹¼çºŒç”Ÿæˆå€™é¸äººã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5DqVXvEaalP"
      },
      "outputs": [],
      "source": [
        "candidates = []\n",
        "\n",
        "for i in evaluation_question:\n",
        "    response = deployed_model.predict(i)\n",
        "    candidates.append(response.text)\n",
        "\n",
        "len(candidates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oftLTb0maalP"
      },
      "source": [
        "ä½ é‚„éœ€å»ºç«‹æˆ‘å€‘çš„åƒè€ƒæ¸…å–®ã€‚é€™äº›å°‡æœƒç”¨æ–¼è©•ä¼°æ¨¡å‹çš„ç¸¾æ•ˆã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7zN70CJaalP"
      },
      "outputs": [],
      "source": [
        "references = evaluation_answer.tolist()\n",
        "\n",
        "len(references)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwKcyIDdjziD"
      },
      "source": [
        "æ¥ä¸‹ä¾†ä½ æœƒç”¢ç”Ÿè©•ä¼°æŒ‡æ¨™ã€‚ `evaluator.evaluate` å°‡æœƒå‚³å›å¹¾å€‹è©•ä¼°æŒ‡æ¨™ã€‚å…¶ä¸­ä¸€äº›é‡è¦çš„æŒ‡æ¨™æœ‰ï¼š\n",
        "- [Blue](https://en.wikipedia.org/wiki/BLEU)ï¼šBLEU è©•ä¼°æŒ‡æ¨™æ˜¯æ©Ÿå™¨ç”¢ç”Ÿçš„æ–‡å­—å’Œäººå·¥æ’°å¯«çš„åƒè€ƒæ–‡å­—çš„ç›¸ä¼¼åº¦æŒ‡æ¨™ã€‚\n",
        "- [Rouge](https://en.wikipedia.org/wiki/ROUGE_(metric))ï¼šROUGE è©•ä¼°æŒ‡æ¨™æ˜¯æ©Ÿå™¨ç”¢ç”Ÿçš„æ–‡å­—å’Œäººå·¥æ’°å¯«çš„åƒè€ƒæ–‡å­—çš„é‡ç–Šåº¦æŒ‡æ¨™ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B828sNxUaalP"
      },
      "outputs": [],
      "source": [
        "scores = evaluator.evaluate(candidates, references, verbose=False)\n",
        "print(scores)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-11.m108",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}